{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ea9ce8-4cc1-4935-a74d-f15ca00c762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59fa8b-b56c-4922-aa73-d4d08402b364",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2af9a7-f5ba-4b4a-b0ab-0cccac4f1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"batch_size\": 8,\n",
    "    \"input_dim\": 5,\n",
    "    \"hidden_dims\": [32, 16],\n",
    "    \"output_dim\": 1,\n",
    "    \"activation\": \"Tanh\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"dropout\": 0.1,\n",
    "    \"shuffle\": True,\n",
    "    \"val_rate\": 0.3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"patience\": 5,\n",
    "    \"save_path\": r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_2\\best_model_trial_2_3_12.pth\",\n",
    "    \"metrics_excel_path\": r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_2\\metrics_trial_2_3_12.xlsx\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a544680-5d70-43cc-85e1-73f8163d23cd",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7483a3-cb4b-4f48-a6bd-5c392fc0cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのパス指定\n",
    "data_folder = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_FFNN_Data\\Trial_1\"\n",
    "# data_folder = r\"C:\\Users\\RYOYA\\OneDrive\\ドキュメント\\データ整理\\美和（修論）\\Miwa_FFNN\\Trial_1\"\n",
    "data_file_name = r\"Miwa_data_for_FFNN.xlsx\"\n",
    "idx_file_name = r\"Miwa_flood_idx_for_FFNN.xlsx\"\n",
    "\n",
    "\n",
    "data_path = os.path.join(data_folder, data_file_name)\n",
    "idx_path = os.path.join(data_folder, idx_file_name)\n",
    "\n",
    "\n",
    "# input, output変数の列番号を指定（0始まり）\n",
    "# タイムラグもここで指定\n",
    "input_cols = [2, 2, 1, 1, 26]\n",
    "input_lags = [0, 1, 1, 2, 0]\n",
    "output_cols = [1]\n",
    "output_lags = [0]\n",
    "\n",
    "# ファイルの読み込み\n",
    "d_all = pd.read_excel(data_path, header=0)\n",
    "idx_list = pd.read_excel(idx_path, header=0)\n",
    "col_trial = 10 # 【要変更】どの列がtrain, testを指定する列か\n",
    "\n",
    "train_idx = idx_list[idx_list.iloc[:, col_trial] == 'train']\n",
    "test_idx = idx_list[idx_list.iloc[:, col_trial] == 'test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08be4857-ce35-45e5-b14c-d3d2e3622c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なデータの取り出し（train）\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# inputの取り出し\n",
    "for i in range(train_idx.shape[0]):\n",
    "    s = int(train_idx.iloc[i, 0]) - 1\n",
    "    e = int(train_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(input_cols, input_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        x_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(x_part)\n",
    "\n",
    "    X_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    x_train.append(X_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "x_train = np.vstack(x_train)\n",
    "\n",
    "\n",
    "# outputの取り出し\n",
    "for i in range(train_idx.shape[0]):\n",
    "    s = int(train_idx.iloc[i, 0]) - 1\n",
    "    e = int(train_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(output_cols, output_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        y_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(y_part)\n",
    "\n",
    "    Y_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    y_train.append(Y_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "y_train = np.vstack(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20373308-5acb-4efa-bfe4-8512099689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの標準化関数\n",
    "def standardize_by_column(X):\n",
    "    \"\"\"列ごとに標準化し、平均と標準偏差を返す\"\"\"\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std  = np.std(X, axis=0, ddof=0)\n",
    "\n",
    "    # 標準偏差が0の列は0除算を防ぐ\n",
    "    std[std == 0] = 1.0\n",
    "\n",
    "    X_std = (X - mean) / std\n",
    "    return X_std, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f577664-6822-4fe6-bb49-c20b631699fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mean          std\n",
      "0    96.992753    73.664817\n",
      "1    96.641515    73.883039\n",
      "2  1130.457090  1725.251261\n",
      "3  1127.694644  1726.527855\n",
      "4    39.008712    42.079069\n",
      "          mean          std\n",
      "0  1132.640482  1724.254377\n"
     ]
    }
   ],
   "source": [
    "# データの標準化\n",
    "x_train_std, x_mean, x_std = standardize_by_column(x_train)\n",
    "y_train_std, y_mean, y_std = standardize_by_column(y_train)\n",
    "\n",
    "x_train_params = pd.DataFrame({'mean': x_mean, 'std': x_std})\n",
    "y_train_params = pd.DataFrame({'mean': y_mean, 'std': y_std})\n",
    "\n",
    "print(x_train_params)\n",
    "print(y_train_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124c6f3-c9fc-4f7b-96d0-957d657ef9fa",
   "metadata": {},
   "source": [
    "## 初期値の定義関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaee0d0-0de4-440a-b39c-228bd5f6a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シード値のセット関数\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aac7042-b05d-435c-94d4-a6c1baf162f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みの初期値の定義\n",
    "\n",
    "def init_weights(model, activation=\"ReLU\"):\n",
    "    \"\"\"\n",
    "    活性化関数に応じて初期値を設定する関数\n",
    "    ReLU → He初期化、 Sigmoid/Tanh → Xavier初期化\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            if activation in [\"ReLU\", \"LeakyReLU\", \"ELU\"]:\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            elif activation in [\"Sigmoid\", \"Tanh\"]:\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            else:\n",
    "                # その他の活性化関数用（デフォルト）\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f17864-6c5c-4047-877a-01ea4c9d31c6",
   "metadata": {},
   "source": [
    "## モデル構造の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301c7f0a-6bc1-40cf-b360-b56ea644228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "def build_ffnn(cfg: dict) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Feed Forward Neural Network (FFNN) を構築する関数。\n",
    "    cfg（辞書）でネットワーク構造・活性化関数・ドロップアウト率などを指定。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : dict\n",
    "        モデル設定を含む辞書。例：\n",
    "        {\n",
    "            \"input_dim\": 10,\n",
    "            \"hidden_dims\": [256, 128, 64],\n",
    "            \"output_dim\": 1,\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"dropout\": 0.2\n",
    "        }\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        指定条件に基づくFFNNモデル\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 活性化関数マッピング ---\n",
    "    activation_funcs = {\n",
    "        \"ReLU\": nn.ReLU(),\n",
    "        \"LeakyReLU\": nn.LeakyReLU(),\n",
    "        \"ELU\": nn.ELU(),\n",
    "        \"Sigmoid\": nn.Sigmoid(),\n",
    "        \"Tanh\": nn.Tanh(),\n",
    "        \"GELU\": nn.GELU()\n",
    "    }\n",
    "\n",
    "    act = activation_funcs.get(cfg.get(\"activation\", \"ReLU\"), nn.ReLU())\n",
    "    dropout_rate = cfg.get(\"dropout\", 0.0)\n",
    "    hidden_dims = cfg.get(\"hidden_dims\", [])\n",
    "    input_dim = cfg[\"input_dim\"]\n",
    "    output_dim = cfg[\"output_dim\"]\n",
    "\n",
    "    layers = []\n",
    "    in_dim = input_dim\n",
    "\n",
    "    # --- 隠れ層を順に構築 ---\n",
    "    for h in hidden_dims:\n",
    "        layers.append(nn.Linear(in_dim, h))\n",
    "        layers.append(act)\n",
    "        if dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        in_dim = h\n",
    "\n",
    "    # --- 出力層（活性化関数なし） ---\n",
    "    layers.append(nn.Linear(in_dim, output_dim))\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8113f52-cf1e-4b7a-809d-2998cbcb4d1e",
   "metadata": {},
   "source": [
    "## 学習ループ関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0dda40-b775-431d-8dfb-ddcc273fb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_with_early_stopping(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=100,\n",
    "    patience=5,\n",
    "    device=None,            # ← デフォルトは None に\n",
    "    verbose=True,\n",
    "    min_delta=0.0,\n",
    "    save_path=\"best_model.pth\",\n",
    "    meta: dict | None = None,  # ← 保存したい付随情報（cfg, x_mean 等）をまとめて渡す\n",
    "):\n",
    "    \"\"\"\n",
    "    Early Stopping 付き学習ループ（回帰: MSE想定）。\n",
    "    - 検証損失が最良のときの state_dict を保存\n",
    "    - 学習後にベスト重みを復元\n",
    "    - meta に渡された dict は torch.save の payload に同梱\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        running_train, n_train = 0.0, 0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            bs = xb.size(0)\n",
    "            running_train += loss.item() * bs\n",
    "            n_train += bs\n",
    "\n",
    "        train_loss = running_train / max(n_train, 1)\n",
    "\n",
    "        # ----- Validate -----\n",
    "        model.eval()\n",
    "        running_val, n_val = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "\n",
    "                bs = xb.size(0)\n",
    "                running_val += loss.item() * bs\n",
    "                n_val += bs\n",
    "\n",
    "        val_loss = running_val / max(n_val, 1)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | val {val_loss:.6f}\")\n",
    "\n",
    "        # ----- Early Stopping 判定 -----\n",
    "        if (best_val_loss - val_loss) > min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "\n",
    "            payload = {\"model_state_dict\": best_state}\n",
    "            if meta is not None:\n",
    "                payload.update(meta)  # 例: {\"cfg\": cfg, \"x_mean\": ..., ...}\n",
    "            torch.save(payload, save_path)\n",
    "\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best val {best_val_loss:.6f})\")\n",
    "                break\n",
    "\n",
    "    # ベスト重みを復元\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    else:\n",
    "        # 念のため保存済みファイルからの復元も試す\n",
    "        try:\n",
    "            ckpt = torch.load(save_path, map_location=device)\n",
    "            model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913509f-4375-4649-9d44-8e3c403cdff8",
   "metadata": {},
   "source": [
    "## 評価関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac32ea13-5c99-4509-aa90-30d13dd8f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価関数\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    RMSE と 決定係数 R² を計算する関数\n",
    "    -----------------------------------\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like or torch.Tensor\n",
    "        正解値\n",
    "    y_pred : array-like or torch.Tensor\n",
    "        予測値\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        {\"RMSE\": ..., \"R2\": ...}\n",
    "    \"\"\"\n",
    "\n",
    "    # Tensor の場合は NumPy 配列に変換\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "    # 平均二乗誤差 (MSE)\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # 決定係数 R²\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\"RMSE\": rmse, \"R2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e8f37c-f267-432b-ad1b-82b8ce7b7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_loader_original_scale(model, loader, device, y_mean=None, y_std=None, y_scaler=None):\n",
    "    model.eval()\n",
    "    preds_std, trues_std = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(xb)  # 標準化後スケールでの予測\n",
    "            preds_std.append(out.cpu())\n",
    "            trues_std.append(yb.cpu())\n",
    "\n",
    "    y_pred_std = torch.cat(preds_std, dim=0).numpy()\n",
    "    y_true_std = torch.cat(trues_std, dim=0).numpy()\n",
    "\n",
    "    # ---- 元スケールへ逆変換 ----\n",
    "    if y_scaler is not None:\n",
    "        # scikit-learnのStandardScalerを使っている場合\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_std)\n",
    "        y_true = y_scaler.inverse_transform(y_true_std)\n",
    "    else:\n",
    "        # 手元の平均・標準偏差で逆変換する場合\n",
    "        y_mean = np.asarray(y_mean).reshape(1, -1)\n",
    "        y_std  = np.asarray(y_std).reshape(1, -1)\n",
    "        y_pred = y_pred_std * y_std + y_mean\n",
    "        y_true = y_true_std * y_std + y_mean\n",
    "\n",
    "    return evaluate_regression(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80537d1-e5a5-42c5-a4f9-3d1da676cad2",
   "metadata": {},
   "source": [
    "## シード値ごとのループ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b2ee5e-71d1-44eb-8cbd-6603760e4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 回のシード実行で Dataset 作成 → split → DataLoader → モデル初期化 → 学習（early stopping）→ 評価（元スケール）\n",
    "\n",
    "def run_one_seed(\n",
    "    seed: int,\n",
    "    cfg: dict,\n",
    "    x_train_std: np.ndarray,\n",
    "    y_train_std: np.ndarray,\n",
    "    x_mean: np.ndarray,\n",
    "    x_std: np.ndarray,\n",
    "    y_mean: np.ndarray,\n",
    "    y_std: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    1つのseedについて、学習→評価（train/val）を実行してメトリクスを返す。\n",
    "    戻り値: metrics_train(dict), metrics_val(dict), model, history(dict)\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # ---- データ準備（テンソル化）\n",
    "    # y を (N, 1) にそろえる（必要な場合のみ）\n",
    "    y_arr = y_train_std if y_train_std.ndim == 2 else y_train_std[:, None]\n",
    "    X = torch.from_numpy(np.ascontiguousarray(x_train_std)).float()\n",
    "    Y = torch.from_numpy(np.ascontiguousarray(y_arr)).float()\n",
    "\n",
    "    assert X.shape[0] == Y.shape[0], \"x と y のサンプル数が一致しません\"\n",
    "\n",
    "    full_ds = TensorDataset(X, Y)\n",
    "\n",
    "    # ---- split（seedごとに再現性を持たせる）\n",
    "    N = len(full_ds)\n",
    "    n_val = int(cfg.get(\"val_rate\", 0.2) * N)\n",
    "    n_train = N - n_val\n",
    "    train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=g)\n",
    "\n",
    "    # ---- DataLoader\n",
    "    batch_size = cfg.get(\"batch_size\", 128)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=0, pin_memory=True, generator=g)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0, pin_memory=True)\n",
    "\n",
    "    # ---- モデル & 初期化\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_ffnn(cfg).to(device)\n",
    "    init_weights(model, activation=cfg.get(\"activation\", \"ReLU\"))\n",
    "\n",
    "    # ---- 損失 & Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=cfg.get(\"learning_rate\", 1e-3),\n",
    "                           weight_decay=cfg.get(\"weight_decay\", 0.0))\n",
    "\n",
    "    # ---- 学習（early stopping）\n",
    "    save_path = cfg.get(\"save_path\", f\"best_model_seed{seed}.pth\")\n",
    "    meta = {\"cfg\": cfg, \"x_mean\": x_mean, \"x_std\": x_std, \"y_mean\": y_mean, \"y_std\": y_std}\n",
    "    model, history = train_with_early_stopping(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=cfg.get(\"num_epochs\", 100),\n",
    "        patience=cfg.get(\"patience\", 5),\n",
    "        device=device,\n",
    "        verbose=cfg.get(\"verbose\", True),\n",
    "        min_delta=cfg.get(\"min_delta\", 1e-5),\n",
    "        save_path=save_path,\n",
    "        meta=meta,\n",
    "    )\n",
    "\n",
    "    # ---- 評価（標準化前スケールへ戻す）\n",
    "    metrics_train = eval_on_loader_original_scale(\n",
    "        model, train_loader, device, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "    metrics_val = eval_on_loader_original_scale(\n",
    "        model, val_loader, device, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "\n",
    "    return metrics_train, metrics_val, model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d34b7-a4d5-4afd-8895-6feef495f4f5",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96679da3-a93e-496b-bb6a-605802824dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 0.623513 | val 0.154779\n",
      "Epoch 002 | train 0.228129 | val 0.107470\n",
      "Epoch 003 | train 0.213173 | val 0.102869\n",
      "Epoch 004 | train 0.161070 | val 0.085944\n",
      "Epoch 005 | train 0.140684 | val 0.061588\n",
      "Epoch 006 | train 0.158255 | val 0.057099\n",
      "Epoch 007 | train 0.128544 | val 0.053397\n",
      "Epoch 008 | train 0.111204 | val 0.053300\n",
      "Epoch 009 | train 0.108616 | val 0.047374\n",
      "Epoch 010 | train 0.126336 | val 0.046444\n",
      "Epoch 011 | train 0.137475 | val 0.058911\n",
      "Epoch 012 | train 0.127553 | val 0.045373\n",
      "Epoch 013 | train 0.100552 | val 0.044031\n",
      "Epoch 014 | train 0.110752 | val 0.043805\n",
      "Epoch 015 | train 0.097790 | val 0.049492\n",
      "Epoch 016 | train 0.095830 | val 0.045038\n",
      "Epoch 017 | train 0.105212 | val 0.042840\n",
      "Epoch 018 | train 0.104582 | val 0.047734\n",
      "Epoch 019 | train 0.110949 | val 0.046288\n",
      "Epoch 020 | train 0.099620 | val 0.043149\n",
      "Epoch 021 | train 0.109662 | val 0.044616\n",
      "Epoch 022 | train 0.108634 | val 0.050545\n",
      "Early stopping at epoch 22 (best val 0.042840)\n",
      "[seed 0] train={'RMSE': 459.135852143082, 'R2': 0.9322678546230381}, val={'RMSE': 356.88516275255245, 'R2': 0.9518727969039574}\n",
      "seed値0での学習が終了しました\n",
      "Epoch 001 | train 0.539531 | val 0.348940\n",
      "Epoch 002 | train 0.309191 | val 0.227090\n",
      "Epoch 003 | train 0.212731 | val 0.171560\n",
      "Epoch 004 | train 0.183556 | val 0.141690\n",
      "Epoch 005 | train 0.150228 | val 0.119650\n",
      "Epoch 006 | train 0.138060 | val 0.106871\n",
      "Epoch 007 | train 0.133054 | val 0.099388\n",
      "Epoch 008 | train 0.127752 | val 0.099094\n",
      "Epoch 009 | train 0.123606 | val 0.083750\n",
      "Epoch 010 | train 0.111899 | val 0.076520\n",
      "Epoch 011 | train 0.101285 | val 0.074289\n",
      "Epoch 012 | train 0.090815 | val 0.070212\n",
      "Epoch 013 | train 0.100184 | val 0.068747\n",
      "Epoch 014 | train 0.100965 | val 0.069321\n",
      "Epoch 015 | train 0.087361 | val 0.070858\n",
      "Epoch 016 | train 0.095313 | val 0.070633\n",
      "Epoch 017 | train 0.087344 | val 0.067927\n",
      "Epoch 018 | train 0.105999 | val 0.066531\n",
      "Epoch 019 | train 0.079948 | val 0.062920\n",
      "Epoch 020 | train 0.112235 | val 0.067593\n",
      "Epoch 021 | train 0.098135 | val 0.065170\n",
      "Epoch 022 | train 0.094049 | val 0.068788\n",
      "Epoch 023 | train 0.091003 | val 0.067826\n",
      "Epoch 024 | train 0.110018 | val 0.067266\n",
      "Early stopping at epoch 24 (best val 0.062920)\n",
      "[seed 1] train={'RMSE': 441.1992199810492, 'R2': 0.9295966822721424}, val={'RMSE': 432.5088094152368, 'R2': 0.9458720350411536}\n",
      "seed値1での学習が終了しました\n",
      "Epoch 001 | train 0.481386 | val 0.155091\n",
      "Epoch 002 | train 0.275097 | val 0.109541\n",
      "Epoch 003 | train 0.208401 | val 0.079805\n",
      "Epoch 004 | train 0.176349 | val 0.073145\n",
      "Epoch 005 | train 0.153374 | val 0.060150\n",
      "Epoch 006 | train 0.124834 | val 0.054472\n",
      "Epoch 007 | train 0.132271 | val 0.046831\n",
      "Epoch 008 | train 0.123386 | val 0.052839\n",
      "Epoch 009 | train 0.123140 | val 0.045250\n",
      "Epoch 010 | train 0.126359 | val 0.038261\n",
      "Epoch 011 | train 0.130004 | val 0.040622\n",
      "Epoch 012 | train 0.127866 | val 0.040412\n",
      "Epoch 013 | train 0.117139 | val 0.041462\n",
      "Epoch 014 | train 0.122886 | val 0.037192\n",
      "Epoch 015 | train 0.108472 | val 0.036101\n",
      "Epoch 016 | train 0.120728 | val 0.036829\n",
      "Epoch 017 | train 0.124162 | val 0.035601\n",
      "Epoch 018 | train 0.122263 | val 0.036269\n",
      "Epoch 019 | train 0.118534 | val 0.033178\n",
      "Epoch 020 | train 0.099705 | val 0.037238\n",
      "Epoch 021 | train 0.107162 | val 0.043087\n",
      "Epoch 022 | train 0.129158 | val 0.040695\n",
      "Epoch 023 | train 0.104109 | val 0.036218\n",
      "Epoch 024 | train 0.095761 | val 0.037100\n",
      "Early stopping at epoch 24 (best val 0.033178)\n",
      "[seed 2] train={'RMSE': 469.04395306622, 'R2': 0.933307804777037}, val={'RMSE': 314.0710285507702, 'R2': 0.9551872544081306}\n",
      "seed値2での学習が終了しました\n",
      "Epoch 001 | train 0.336492 | val 0.132075\n",
      "Epoch 002 | train 0.223095 | val 0.101365\n",
      "Epoch 003 | train 0.178209 | val 0.077967\n",
      "Epoch 004 | train 0.173267 | val 0.068797\n",
      "Epoch 005 | train 0.156156 | val 0.059589\n",
      "Epoch 006 | train 0.154936 | val 0.055237\n",
      "Epoch 007 | train 0.154809 | val 0.047884\n",
      "Epoch 008 | train 0.149241 | val 0.048569\n",
      "Epoch 009 | train 0.137585 | val 0.049758\n",
      "Epoch 010 | train 0.136277 | val 0.044747\n",
      "Epoch 011 | train 0.127157 | val 0.043824\n",
      "Epoch 012 | train 0.123715 | val 0.041656\n",
      "Epoch 013 | train 0.129651 | val 0.047497\n",
      "Epoch 014 | train 0.118091 | val 0.040696\n",
      "Epoch 015 | train 0.115851 | val 0.062861\n",
      "Epoch 016 | train 0.111780 | val 0.039497\n",
      "Epoch 017 | train 0.126754 | val 0.050151\n",
      "Epoch 018 | train 0.120954 | val 0.036035\n",
      "Epoch 019 | train 0.117247 | val 0.036974\n",
      "Epoch 020 | train 0.102327 | val 0.037153\n",
      "Epoch 021 | train 0.101049 | val 0.038944\n",
      "Epoch 022 | train 0.144282 | val 0.037099\n",
      "Epoch 023 | train 0.108509 | val 0.044076\n",
      "Early stopping at epoch 23 (best val 0.036035)\n",
      "[seed 3] train={'RMSE': 486.8140489607731, 'R2': 0.9236608954052167}, val={'RMSE': 327.3152820144223, 'R2': 0.9597329683012732}\n",
      "seed値3での学習が終了しました\n",
      "Epoch 001 | train 0.414054 | val 0.447187\n",
      "Epoch 002 | train 0.220979 | val 0.343772\n",
      "Epoch 003 | train 0.176389 | val 0.282376\n",
      "Epoch 004 | train 0.147797 | val 0.259553\n",
      "Epoch 005 | train 0.135738 | val 0.234508\n",
      "Epoch 006 | train 0.093072 | val 0.203392\n",
      "Epoch 007 | train 0.079601 | val 0.187951\n",
      "Epoch 008 | train 0.092534 | val 0.176046\n",
      "Epoch 009 | train 0.067374 | val 0.171991\n",
      "Epoch 010 | train 0.070132 | val 0.169690\n",
      "Epoch 011 | train 0.072625 | val 0.174681\n",
      "Epoch 012 | train 0.072140 | val 0.160761\n",
      "Epoch 013 | train 0.059125 | val 0.151921\n",
      "Epoch 014 | train 0.069186 | val 0.145700\n",
      "Epoch 015 | train 0.089368 | val 0.144148\n",
      "Epoch 016 | train 0.069370 | val 0.144545\n",
      "Epoch 017 | train 0.069848 | val 0.144209\n",
      "Epoch 018 | train 0.065471 | val 0.141864\n",
      "Epoch 019 | train 0.066292 | val 0.149916\n",
      "Epoch 020 | train 0.060796 | val 0.140166\n",
      "Epoch 021 | train 0.071024 | val 0.140606\n",
      "Epoch 022 | train 0.064158 | val 0.136965\n",
      "Epoch 023 | train 0.068485 | val 0.135146\n",
      "Epoch 024 | train 0.057782 | val 0.137914\n",
      "Epoch 025 | train 0.060509 | val 0.140857\n",
      "Epoch 026 | train 0.066968 | val 0.154002\n",
      "Epoch 027 | train 0.067659 | val 0.132886\n",
      "Epoch 028 | train 0.061216 | val 0.134088\n",
      "Epoch 029 | train 0.057853 | val 0.134640\n",
      "Epoch 030 | train 0.072497 | val 0.142013\n",
      "Epoch 031 | train 0.053257 | val 0.137141\n",
      "Epoch 032 | train 0.060885 | val 0.145685\n",
      "Early stopping at epoch 32 (best val 0.132886)\n",
      "[seed 4] train={'RMSE': 329.05208493157295, 'R2': 0.9570313814341914}, val={'RMSE': 628.5517766646365, 'R2': 0.901536674680134}\n",
      "seed値4での学習が終了しました\n"
     ]
    }
   ],
   "source": [
    "seeds = [0, 1, 2, 3, 4]\n",
    "metrics_train_list = []\n",
    "metrics_val_list = []\n",
    "\n",
    "\n",
    "for s in seeds:\n",
    "    mt, mv, model_s, hist_s = run_one_seed(\n",
    "        seed=s,\n",
    "        cfg=cfg,\n",
    "        x_train_std=x_train_std,\n",
    "        y_train_std=y_train_std,\n",
    "        x_mean = x_mean,\n",
    "        x_std = x_std,\n",
    "        y_mean=y_mean,\n",
    "        y_std=y_std,\n",
    "    )\n",
    "    print(f\"[seed {s}] train={mt}, val={mv}\")\n",
    "    metrics_train_list.append(mt)\n",
    "    metrics_val_list.append(mv)\n",
    "\n",
    "    print(f\"seed値{s}での学習が終了しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb26518-7900-49d6-bc64-d2101996e135",
   "metadata": {},
   "source": [
    "## 結果の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f16e881-0356-433f-a0ed-aed56f60ebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存完了: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_2\\metrics_trial_2_3_12.xlsx\n",
      "   seed  train_RMSE  train_R2    val_RMSE    val_R2\n",
      "0     0  459.135852  0.932268  356.885163  0.951873\n",
      "1     1  441.199220  0.929597  432.508809  0.945872\n",
      "2     2  469.043953  0.933308  314.071029  0.955187\n",
      "3     3  486.814049  0.923661  327.315282  0.959733\n",
      "4     4  329.052085  0.957031  628.551777  0.901537\n",
      "5  mean  437.049032  0.935173  411.866412  0.942840\n"
     ]
    }
   ],
   "source": [
    "# ---- 行列（seed × 指標）を作る\n",
    "train_mat = np.array([[m['RMSE'], m['R2']] for m in metrics_train_list], dtype=float)\n",
    "val_mat   = np.array([[m['RMSE'], m['R2']] for m in metrics_val_list],   dtype=float)\n",
    "\n",
    "# ---- サマリーDF（seedごとのRMSE/R2）\n",
    "df = pd.DataFrame({\n",
    "    \"seed\": seeds,\n",
    "    \"train_RMSE\": train_mat[:, 0],\n",
    "    \"train_R2\":   train_mat[:, 1],\n",
    "    \"val_RMSE\":   val_mat[:, 0],\n",
    "    \"val_R2\":     val_mat[:, 1],\n",
    "})\n",
    "\n",
    "# ---- 平均行を追加\n",
    "mean_row = {\n",
    "    \"seed\": \"mean\",\n",
    "    \"train_RMSE\": train_mat[:, 0].mean(),\n",
    "    \"train_R2\":   train_mat[:, 1].mean(),\n",
    "    \"val_RMSE\":   val_mat[:, 0].mean(),\n",
    "    \"val_R2\":     val_mat[:, 1].mean(),\n",
    "}\n",
    "df = pd.concat([df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "\n",
    "# ---- Excel に保存（summary + 生行列）\n",
    "out_xlsx = cfg.get(\"metrics_excel_path\", \"metrics_by_seed.xlsx\")\n",
    "os.makedirs(os.path.dirname(out_xlsx) or \".\", exist_ok=True)\n",
    "\n",
    "with pd.ExcelWriter(out_xlsx) as w:\n",
    "    df.to_excel(w, sheet_name=\"summary\", index=False)\n",
    "    pd.DataFrame(train_mat, columns=[\"RMSE\", \"R2\"]).to_excel(\n",
    "        w, sheet_name=\"train_matrix\", index_label=\"seed_idx\"\n",
    "    )\n",
    "    pd.DataFrame(val_mat, columns=[\"RMSE\", \"R2\"]).to_excel(\n",
    "        w, sheet_name=\"val_matrix\", index_label=\"seed_idx\"\n",
    "    )\n",
    "\n",
    "print(\"✅ 保存完了:\", out_xlsx)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d50bb9-9400-440d-b0b0-3f82b2503863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
