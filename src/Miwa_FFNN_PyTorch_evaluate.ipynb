{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc78763d-75e4-49c1-9d49-c01461511892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miwa_FFNN_Pytorchにより決めた最適なハイパーパラメータにおいて、モデルの精度をtestデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c632e0-c359-4247-85a7-3fbf386d6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed08b92-8d18-471c-b667-963bb20812bd",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe688ca-6d39-4890-88ee-f76bd4ac557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"batch_size\": 8,\n",
    "    \"input_dim\": 4,\n",
    "    \"hidden_dims\": [16],\n",
    "    \"output_dim\": 1,\n",
    "    \"activation\": \"Tanh\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"dropout\": 0.1,\n",
    "    \"shuffle\": True,\n",
    "    \"val_rate\": 0.3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"patience\": 5,\n",
    "    \"save_path\": r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_1\\best_model_trial_1.pth\",\n",
    "    \"metrics_excel_path\": r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_1\\metrics_trial_1_test.xlsx\"\n",
    "}\n",
    "\n",
    "\n",
    "best_seed = [2] # 【要変更】学習時に最も精度が高かったシード値を入力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee772a7-fec1-4a5b-a4d2-4065a678e05e",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2793474-4503-44cd-9922-71ef3762ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのパス指定\n",
    "data_folder = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_FFNN_Data\\Trial_1\"\n",
    "# data_folder = r\"C:\\Users\\RYOYA\\OneDrive\\ドキュメント\\データ整理\\美和（修論）\\Miwa_FFNN\\Trial_1\"\n",
    "data_file_name = r\"Miwa_data_for_FFNN.xlsx\"\n",
    "idx_file_name = r\"Miwa_flood_idx_for_FFNN.xlsx\"\n",
    "\n",
    "\n",
    "data_path = os.path.join(data_folder, data_file_name)\n",
    "idx_path = os.path.join(data_folder, idx_file_name)\n",
    "\n",
    "\n",
    "# input, output変数の列番号を指定（0始まり）\n",
    "# タイムラグもここで指定\n",
    "input_cols = [2, 2, 1, 1]\n",
    "input_lags = [0, 1, 1, 2]\n",
    "output_cols = [1]\n",
    "output_lags = [0]\n",
    "\n",
    "# ファイルの読み込み\n",
    "d_all = pd.read_excel(data_path, header=0)\n",
    "idx_list = pd.read_excel(idx_path, header=0)\n",
    "col_trial = 10 # 【要変更】どの列がtrain, testを指定する列か\n",
    "\n",
    "train_idx = idx_list[idx_list.iloc[:, col_trial] == 'train']\n",
    "test_idx = idx_list[idx_list.iloc[:, col_trial] == 'test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011e3b31-69b6-4625-8df2-362c80c7886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なデータの取り出し（train）\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# inputの取り出し\n",
    "for i in range(train_idx.shape[0]):\n",
    "    s = int(train_idx.iloc[i, 0]) - 1\n",
    "    e = int(train_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(input_cols, input_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        x_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(x_part)\n",
    "\n",
    "    X_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    x_train.append(X_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "x_train = np.vstack(x_train)\n",
    "\n",
    "\n",
    "# outputの取り出し\n",
    "for i in range(train_idx.shape[0]):\n",
    "    s = int(train_idx.iloc[i, 0]) - 1\n",
    "    e = int(train_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(output_cols, output_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        y_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(y_part)\n",
    "\n",
    "    Y_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    y_train.append(Y_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "y_train = np.vstack(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337c051f-7653-420c-a48b-081ea681a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの標準化関数\n",
    "def standardize_by_column(X):\n",
    "    \"\"\"列ごとに標準化し、平均と標準偏差を返す\"\"\"\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std  = np.std(X, axis=0, ddof=0)\n",
    "\n",
    "    # 標準偏差が0の列は0除算を防ぐ\n",
    "    std[std == 0] = 1.0\n",
    "\n",
    "    X_std = (X - mean) / std\n",
    "    return X_std, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4a91c9-c16d-4b7e-a5f4-5937f6013537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mean          std\n",
      "0    96.444256    73.266471\n",
      "1    96.127643    73.476861\n",
      "2  1116.827281  1713.956495\n",
      "3  1114.675681  1714.918607\n",
      "          mean          std\n",
      "0  1118.495558  1713.148239\n"
     ]
    }
   ],
   "source": [
    "# データの標準化\n",
    "x_train_std, x_mean, x_std = standardize_by_column(x_train)\n",
    "y_train_std, y_mean, y_std = standardize_by_column(y_train)\n",
    "\n",
    "x_train_params = pd.DataFrame({'mean': x_mean, 'std': x_std})\n",
    "y_train_params = pd.DataFrame({'mean': y_mean, 'std': y_std})\n",
    "\n",
    "print(x_train_params)\n",
    "print(y_train_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea28e7-25fe-4974-b096-f56709f05b6a",
   "metadata": {},
   "source": [
    "## 初期値の定義関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4134421e-d73d-4a19-af42-f71ad4bacf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シード値のセット関数\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b10e9c-b0eb-4b61-b61a-0c8627ac0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みの初期値の定義\n",
    "\n",
    "def init_weights(model, activation=\"ReLU\"):\n",
    "    \"\"\"\n",
    "    活性化関数に応じて初期値を設定する関数\n",
    "    ReLU → He初期化、 Sigmoid/Tanh → Xavier初期化\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            if activation in [\"ReLU\", \"LeakyReLU\", \"ELU\"]:\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            elif activation in [\"Sigmoid\", \"Tanh\"]:\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            else:\n",
    "                # その他の活性化関数用（デフォルト）\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8464f82-43e5-4487-bc23-73246870baac",
   "metadata": {},
   "source": [
    "## モデル構造の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81a0abf-df7c-411a-aba9-0e0979f8668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "def build_ffnn(cfg: dict) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Feed Forward Neural Network (FFNN) を構築する関数。\n",
    "    cfg（辞書）でネットワーク構造・活性化関数・ドロップアウト率などを指定。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : dict\n",
    "        モデル設定を含む辞書。例：\n",
    "        {\n",
    "            \"input_dim\": 10,\n",
    "            \"hidden_dims\": [256, 128, 64],\n",
    "            \"output_dim\": 1,\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"dropout\": 0.2\n",
    "        }\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        指定条件に基づくFFNNモデル\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 活性化関数マッピング ---\n",
    "    activation_funcs = {\n",
    "        \"ReLU\": nn.ReLU(),\n",
    "        \"LeakyReLU\": nn.LeakyReLU(),\n",
    "        \"ELU\": nn.ELU(),\n",
    "        \"Sigmoid\": nn.Sigmoid(),\n",
    "        \"Tanh\": nn.Tanh(),\n",
    "        \"GELU\": nn.GELU()\n",
    "    }\n",
    "\n",
    "    act = activation_funcs.get(cfg.get(\"activation\", \"ReLU\"), nn.ReLU())\n",
    "    dropout_rate = cfg.get(\"dropout\", 0.0)\n",
    "    hidden_dims = cfg.get(\"hidden_dims\", [])\n",
    "    input_dim = cfg[\"input_dim\"]\n",
    "    output_dim = cfg[\"output_dim\"]\n",
    "\n",
    "    layers = []\n",
    "    in_dim = input_dim\n",
    "\n",
    "    # --- 隠れ層を順に構築 ---\n",
    "    for h in hidden_dims:\n",
    "        layers.append(nn.Linear(in_dim, h))\n",
    "        layers.append(act)\n",
    "        if dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        in_dim = h\n",
    "\n",
    "    # --- 出力層（活性化関数なし） ---\n",
    "    layers.append(nn.Linear(in_dim, output_dim))\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1081e8b-397f-4e44-a46a-0e146fafca3c",
   "metadata": {},
   "source": [
    "## 学習ループの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe8e772-dd3f-4c58-bc01-4605d67865fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_with_early_stopping(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=100,\n",
    "    patience=5,\n",
    "    device=None,            # ← デフォルトは None に\n",
    "    verbose=True,\n",
    "    min_delta=0.0,\n",
    "    save_path=\"best_model.pth\",\n",
    "    meta: dict | None = None,  # ← 保存したい付随情報（cfg, x_mean 等）をまとめて渡す\n",
    "):\n",
    "    \"\"\"\n",
    "    Early Stopping 付き学習ループ（回帰: MSE想定）。\n",
    "    - 検証損失が最良のときの state_dict を保存\n",
    "    - 学習後にベスト重みを復元\n",
    "    - meta に渡された dict は torch.save の payload に同梱\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        running_train, n_train = 0.0, 0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            bs = xb.size(0)\n",
    "            running_train += loss.item() * bs\n",
    "            n_train += bs\n",
    "\n",
    "        train_loss = running_train / max(n_train, 1)\n",
    "\n",
    "        # ----- Validate -----\n",
    "        model.eval()\n",
    "        running_val, n_val = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "\n",
    "                bs = xb.size(0)\n",
    "                running_val += loss.item() * bs\n",
    "                n_val += bs\n",
    "\n",
    "        val_loss = running_val / max(n_val, 1)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | val {val_loss:.6f}\")\n",
    "\n",
    "        # ----- Early Stopping 判定 -----\n",
    "        if (best_val_loss - val_loss) > min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "\n",
    "            payload = {\"model_state_dict\": best_state}\n",
    "            if meta is not None:\n",
    "                payload.update(meta)  # 例: {\"cfg\": cfg, \"x_mean\": ..., ...}\n",
    "            torch.save(payload, save_path)\n",
    "\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best val {best_val_loss:.6f})\")\n",
    "                break\n",
    "\n",
    "    # ベスト重みを復元\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    else:\n",
    "        # 念のため保存済みファイルからの復元も試す\n",
    "        try:\n",
    "            ckpt = torch.load(save_path, map_location=device)\n",
    "            model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f5e11-3a85-48ce-bb79-f067a6691b2c",
   "metadata": {},
   "source": [
    "## 評価関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83779fc-3569-483e-b957-eba72bcf1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価関数\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    RMSE と 決定係数 R² を計算する関数\n",
    "    -----------------------------------\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like or torch.Tensor\n",
    "        正解値\n",
    "    y_pred : array-like or torch.Tensor\n",
    "        予測値\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        {\"RMSE\": ..., \"R2\": ...}\n",
    "    \"\"\"\n",
    "\n",
    "    # Tensor の場合は NumPy 配列に変換\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "    # 平均二乗誤差 (MSE)\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # 決定係数 R²\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\"RMSE\": rmse, \"R2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8d42de7-9eb7-4ecc-8488-0bbcd30eca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_loader_original_scale(model, loader, device, y_mean=None, y_std=None, y_scaler=None):\n",
    "    model.eval()\n",
    "    preds_std, trues_std = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(xb)  # 標準化後スケールでの予測\n",
    "            preds_std.append(out.cpu())\n",
    "            trues_std.append(yb.cpu())\n",
    "\n",
    "    y_pred_std = torch.cat(preds_std, dim=0).numpy()\n",
    "    y_true_std = torch.cat(trues_std, dim=0).numpy()\n",
    "\n",
    "    # ---- 元スケールへ逆変換 ----\n",
    "    if y_scaler is not None:\n",
    "        # scikit-learnのStandardScalerを使っている場合\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_std)\n",
    "        y_true = y_scaler.inverse_transform(y_true_std)\n",
    "    else:\n",
    "        # 手元の平均・標準偏差で逆変換する場合\n",
    "        y_mean = np.asarray(y_mean).reshape(1, -1)\n",
    "        y_std  = np.asarray(y_std).reshape(1, -1)\n",
    "        y_pred = y_pred_std * y_std + y_mean\n",
    "        y_true = y_true_std * y_std + y_mean\n",
    "\n",
    "    return evaluate_regression(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6ea17-ca7f-4022-9137-781c204db4b3",
   "metadata": {},
   "source": [
    "## シード値ごとの学習ラン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6728f5f2-7293-4493-8d30-7266dc708c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 回のシード実行で Dataset 作成 → split → DataLoader → モデル初期化 → 学習（early stopping）→ 評価（元スケール）\n",
    "\n",
    "def run_one_seed(\n",
    "    seed: int,\n",
    "    cfg: dict,\n",
    "    x_train_std: np.ndarray,\n",
    "    y_train_std: np.ndarray,\n",
    "    x_mean: np.ndarray,\n",
    "    x_std: np.ndarray,\n",
    "    y_mean: np.ndarray,\n",
    "    y_std: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    1つのseedについて、学習→評価（train/val）を実行してメトリクスを返す。\n",
    "    戻り値: metrics_train(dict), metrics_val(dict), model, history(dict)\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # ---- データ準備（テンソル化）\n",
    "    # y を (N, 1) にそろえる（必要な場合のみ）\n",
    "    y_arr = y_train_std if y_train_std.ndim == 2 else y_train_std[:, None]\n",
    "    X = torch.from_numpy(np.ascontiguousarray(x_train_std)).float()\n",
    "    Y = torch.from_numpy(np.ascontiguousarray(y_arr)).float()\n",
    "\n",
    "    assert X.shape[0] == Y.shape[0], \"x と y のサンプル数が一致しません\"\n",
    "\n",
    "    full_ds = TensorDataset(X, Y)\n",
    "\n",
    "    # ---- split（seedごとに再現性を持たせる）\n",
    "    N = len(full_ds)\n",
    "    n_val = int(cfg.get(\"val_rate\", 0.2) * N)\n",
    "    n_train = N - n_val\n",
    "    train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=g)\n",
    "\n",
    "    # ---- DataLoader\n",
    "    batch_size = cfg.get(\"batch_size\", 128)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=0, pin_memory=True, generator=g)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0, pin_memory=True)\n",
    "\n",
    "    # ---- モデル & 初期化\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_ffnn(cfg).to(device)\n",
    "    init_weights(model, activation=cfg.get(\"activation\", \"ReLU\"))\n",
    "\n",
    "    # ---- 損失 & Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=cfg.get(\"learning_rate\", 1e-3),\n",
    "                           weight_decay=cfg.get(\"weight_decay\", 0.0))\n",
    "\n",
    "    # ---- 学習（early stopping）\n",
    "    save_path = cfg.get(\"save_path\", f\"best_model_seed{seed}.pth\")\n",
    "    meta = {\"cfg\": cfg, \"x_mean\": x_mean, \"x_std\": x_std, \"y_mean\": y_mean, \"y_std\": y_std}\n",
    "    model, history = train_with_early_stopping(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=cfg.get(\"num_epochs\", 100),\n",
    "        patience=cfg.get(\"patience\", 5),\n",
    "        device=device,\n",
    "        verbose=cfg.get(\"verbose\", True),\n",
    "        min_delta=cfg.get(\"min_delta\", 1e-5),\n",
    "        save_path=save_path,\n",
    "        meta=meta,\n",
    "    )\n",
    "\n",
    "    # ---- 評価（標準化前スケールへ戻す）\n",
    "    metrics_train = eval_on_loader_original_scale(\n",
    "        model, train_loader, device, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "    metrics_val = eval_on_loader_original_scale(\n",
    "        model, val_loader, device, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "\n",
    "    return metrics_train, metrics_val, model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5683c08-c778-488e-a759-e94f7ca3878d",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e3eb8b-5698-487f-a0a1-b03325f21e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 1.039605 | val 0.549461\n",
      "Epoch 002 | train 0.469244 | val 0.388148\n",
      "Epoch 003 | train 0.365373 | val 0.317620\n",
      "Epoch 004 | train 0.275231 | val 0.283514\n",
      "Epoch 005 | train 0.227343 | val 0.255998\n",
      "Epoch 006 | train 0.205770 | val 0.237697\n",
      "Epoch 007 | train 0.178623 | val 0.223128\n",
      "Epoch 008 | train 0.180912 | val 0.209453\n",
      "Epoch 009 | train 0.169950 | val 0.197717\n",
      "Epoch 010 | train 0.137445 | val 0.188000\n",
      "Epoch 011 | train 0.153260 | val 0.178004\n",
      "Epoch 012 | train 0.128839 | val 0.168590\n",
      "Epoch 013 | train 0.139460 | val 0.159773\n",
      "Epoch 014 | train 0.118100 | val 0.152886\n",
      "Epoch 015 | train 0.120747 | val 0.145547\n",
      "Epoch 016 | train 0.114791 | val 0.141380\n",
      "Epoch 017 | train 0.113975 | val 0.134461\n",
      "Epoch 018 | train 0.109230 | val 0.130815\n",
      "Epoch 019 | train 0.103550 | val 0.124024\n",
      "Epoch 020 | train 0.090231 | val 0.120351\n",
      "Epoch 021 | train 0.091384 | val 0.116366\n",
      "Epoch 022 | train 0.093047 | val 0.113439\n",
      "Epoch 023 | train 0.078776 | val 0.108969\n",
      "Epoch 024 | train 0.095887 | val 0.106310\n",
      "Epoch 025 | train 0.088932 | val 0.102244\n",
      "Epoch 026 | train 0.091619 | val 0.100377\n",
      "Epoch 027 | train 0.069369 | val 0.097337\n",
      "Epoch 028 | train 0.090605 | val 0.097556\n",
      "Epoch 029 | train 0.082324 | val 0.095279\n",
      "Epoch 030 | train 0.083957 | val 0.091577\n",
      "Epoch 031 | train 0.068964 | val 0.090509\n",
      "Epoch 032 | train 0.072651 | val 0.095855\n",
      "Epoch 033 | train 0.070330 | val 0.091660\n",
      "Epoch 034 | train 0.079687 | val 0.091224\n",
      "Epoch 035 | train 0.075756 | val 0.086595\n",
      "Epoch 036 | train 0.076872 | val 0.084720\n",
      "Epoch 037 | train 0.065524 | val 0.084407\n",
      "Epoch 038 | train 0.064897 | val 0.083178\n",
      "Epoch 039 | train 0.068597 | val 0.082883\n",
      "Epoch 040 | train 0.066954 | val 0.082571\n",
      "Epoch 041 | train 0.075426 | val 0.082165\n",
      "Epoch 042 | train 0.063673 | val 0.081900\n",
      "Epoch 043 | train 0.070870 | val 0.082420\n",
      "Epoch 044 | train 0.066840 | val 0.082061\n",
      "Epoch 045 | train 0.058944 | val 0.083802\n",
      "Epoch 046 | train 0.066424 | val 0.080659\n",
      "Epoch 047 | train 0.063848 | val 0.080035\n",
      "Epoch 048 | train 0.061999 | val 0.080223\n",
      "Epoch 049 | train 0.059381 | val 0.080905\n",
      "Epoch 050 | train 0.059643 | val 0.080781\n",
      "Epoch 051 | train 0.059316 | val 0.079980\n",
      "Epoch 052 | train 0.063424 | val 0.080344\n",
      "Epoch 053 | train 0.066179 | val 0.079979\n",
      "Epoch 054 | train 0.059913 | val 0.081312\n",
      "Epoch 055 | train 0.064745 | val 0.080335\n",
      "Epoch 056 | train 0.064612 | val 0.082480\n",
      "Early stopping at epoch 56 (best val 0.079980)\n",
      "[seed 2] train={'RMSE': 384.8285052342383, 'R2': 0.9513652476185172}, val={'RMSE': 484.4895836484687, 'R2': 0.9121736357232095}\n",
      "seed値2での学習が終了しました\n"
     ]
    }
   ],
   "source": [
    "seeds = best_seed\n",
    "metrics_train_list = []\n",
    "metrics_val_list = []\n",
    "\n",
    "\n",
    "for s in seeds:\n",
    "    mt, mv, model_s, hist_s = run_one_seed(\n",
    "        seed=s,\n",
    "        cfg=cfg,\n",
    "        x_train_std=x_train_std,\n",
    "        y_train_std=y_train_std,\n",
    "        x_mean = x_mean,\n",
    "        x_std = x_std,\n",
    "        y_mean=y_mean,\n",
    "        y_std=y_std,\n",
    "    )\n",
    "    print(f\"[seed {s}] train={mt}, val={mv}\")\n",
    "    metrics_train_list.append(mt)\n",
    "    metrics_val_list.append(mv)\n",
    "\n",
    "    print(f\"seed値{s}での学習が終了しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4a062-27dc-4fda-920a-2b494589f66b",
   "metadata": {},
   "source": [
    "## testLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7644c5b-5096-448d-9674-2a95bedc3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なデータの取り出し（test）\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# inputの取り出し\n",
    "for i in range(test_idx.shape[0]):\n",
    "    s = int(test_idx.iloc[i, 0]) - 1\n",
    "    e = int(test_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(input_cols, input_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        x_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(x_part)\n",
    "\n",
    "    X_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    x_test.append(X_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "x_test = np.vstack(x_test)\n",
    "\n",
    "\n",
    "# outputの取り出し\n",
    "for i in range(test_idx.shape[0]):\n",
    "    s = int(test_idx.iloc[i, 0]) - 1\n",
    "    e = int(test_idx.iloc[i, 1]) - 1\n",
    "\n",
    "    # ---- X（入力データ）: 各列をその列ごとの lag 分だけずらして抽出\n",
    "    cols_block = []\n",
    "    for col, lag in zip(output_cols, output_lags):\n",
    "        start = s - lag\n",
    "        end = e - lag\n",
    "        # lag分だけ前の行を取り出す（指定範囲のまま、NaN埋め不要）\n",
    "        y_part = d_all.iloc[start:end+1, col].to_numpy().reshape(-1, 1)\n",
    "        cols_block.append(y_part)\n",
    "\n",
    "    Y_seg = np.hstack(cols_block)  # (L, len(input_cols))\n",
    "\n",
    "    # 区間ごとに格納\n",
    "    y_test.append(Y_seg)\n",
    "\n",
    "# ---- すべての区間を縦方向に結合\n",
    "y_test = np.vstack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce4044c-e162-45be-9f68-da31ce7c0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの標準化（train時の標準化パラメータを用いて）\n",
    "x_test_std = (x_test - x_mean) / x_std\n",
    "y_test_std = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242eb86a-3fed-4ef0-b75c-37621ef04289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- データ準備（テンソル化）\n",
    "# y を (N, 1) にそろえる（必要な場合のみ）\n",
    "y_arr = y_test_std if y_test_std.ndim == 2 else y_test_std[:, None]\n",
    "X = torch.from_numpy(np.ascontiguousarray(x_test_std)).float()\n",
    "Y = torch.from_numpy(np.ascontiguousarray(y_arr)).float()\n",
    "\n",
    "assert X.shape[0] == Y.shape[0], \"x と y のサンプル数が一致しません\"\n",
    "\n",
    "test_ds = TensorDataset(X, Y)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=cfg[\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a26049-ffa0-40c9-ab55-26f068bec106",
   "metadata": {},
   "source": [
    "## モデルで計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7efde27-dd7b-4d65-b09c-cc5f08f3fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_s = model_s.to(device)\n",
    "\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "model_s.eval()\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred = model_s(xb)\n",
    "\n",
    "        # GPU → CPU に戻して蓄積\n",
    "        y_true_list.append(yb.cpu())\n",
    "        y_pred_list.append(pred.cpu())\n",
    "\n",
    "# Tensorをまとめてnumpyに変換\n",
    "y_true_std = torch.cat(y_true_list).numpy()\n",
    "y_pred_std = torch.cat(y_pred_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac64a585-c2fc-40a1-b44b-404e46a5b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化前のスケールに戻す\n",
    "\n",
    "y_true = y_true_std * y_std + y_mean\n",
    "y_pred = y_pred_std * y_std + y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486aefcf-b492-4285-8836-6d1a700faf74",
   "metadata": {},
   "source": [
    "## テストデータでの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480a3326-11d0-4050-817c-4e6ec492d6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 379.0867136595893, 'R2': 0.9269968310845473}\n"
     ]
    }
   ],
   "source": [
    "metrics_test = evaluate_regression(y_true, y_pred)\n",
    "print(metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286380d4-e3d5-4da6-941b-56eb1feeaf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test metrics saved to: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_FFNN\\Trial_1\\metrics_trial_1_test.xlsx\n"
     ]
    }
   ],
   "source": [
    "# エクセルに保存\n",
    "\n",
    "df_test = pd.DataFrame([metrics_test])           # 1行の表にする\n",
    "\n",
    "# 保存先（cfgに無ければデフォルト名）\n",
    "out_xlsx = cfg.get(\"metrics_excel_path\", \"metrics_test.xlsx\")\n",
    "os.makedirs(os.path.dirname(out_xlsx) or \".\", exist_ok=True)\n",
    "\n",
    "# Excelに書き出し\n",
    "with pd.ExcelWriter(out_xlsx) as w:\n",
    "    df_test.to_excel(w, sheet_name=\"test_metrics\", index=False)\n",
    "\n",
    "print(f\"✅ Test metrics saved to: {out_xlsx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135ae5d-a0ba-4012-b819-36cf9eaa96a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3c6a9-2956-4c33-832e-8ab5f094f011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd4ce2-0dbe-4b9e-93c2-ad7f8e4a3a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5799eec-65c4-4519-a608-4f8091059ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
