{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891b5118-461c-4f28-aeb3-24ad8676adb8",
   "metadata": {},
   "source": [
    "# 学習済みモデルの読み込み・出力（エンコーダ・デコーダ型LSTM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524d4720-4edd-4880-a6a9-89412d9711bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e345c-d772-4776-8f83-fec5867ca911",
   "metadata": {},
   "source": [
    "# モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e4bf21-7fea-4462-b9f1-4cdfaf3c1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateBridge(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoderの(h, c)をDecoder初期状態へ写像するブリッジ。\n",
    "    - 層数/隠れ次元が異なってもOK\n",
    "    - bridge_mode:\n",
    "        - \"zero_pad\":  層合わせ=0埋め or 切り落とし、隠れ次元は線形射影\n",
    "        - \"repeat_top\":層合わせ=最上層の繰り返し/切り落とし、隠れ次元は線形射影\n",
    "        - \"linear_stack\": [B, L_enc, H_enc] -> 線形で [B, L_dec, H_dec] へ（層方向も学習で混合）\n",
    "\n",
    "    - enc_layers: エンコーダの層の深さ\n",
    "    - dec_layers: デコーダの層の深さ\n",
    "    - enc_hidden: エンコーダのノード数\n",
    "    - dec_hidden: デコーダのノード数\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hidden, dec_hidden, mode=\"zero_pad\"):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.enc_hidden = enc_hidden\n",
    "        self.dec_hidden = dec_hidden\n",
    "        self.mode = mode\n",
    "\n",
    "        # 隠れ次元の変換（h/c共用）\n",
    "        if mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            self.proj = nn.Linear(enc_hidden, dec_hidden, bias=True)\n",
    "        elif mode == \"linear_stack\":\n",
    "            # 層方向もまとめて線形変換\n",
    "            self.proj_h = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "            self.proj_c = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bridge mode: {mode}\")\n",
    "\n",
    "    def _match_layers(self, x, how=\"zero_pad\"):\n",
    "        \"\"\"\n",
    "        x: [L_enc, B, H_enc] を層数だけ合わせる（隠れ次元は未変換）\n",
    "        return: [L_dec, B, H_enc]\n",
    "\n",
    "        B: バッチサイズ\n",
    "        \"\"\"\n",
    "        L_enc, B, H = x.shape\n",
    "        L_dec = self.dec_layers\n",
    "\n",
    "        if L_dec == L_enc:\n",
    "            return x\n",
    "\n",
    "        if L_dec < L_enc:\n",
    "            # 上位層を優先して切り落とす（直観的には最上層が一番抽象的）\n",
    "            return x[:L_dec, :, :]\n",
    "\n",
    "        # L_dec > L_enc の場合\n",
    "        pad_count = L_dec - L_enc\n",
    "        if how == \"repeat_top\":\n",
    "            top = x[-1:, :, :].expand(pad_count, B, H)  # 最上層を複製\n",
    "            return torch.cat([x, top], dim=0)\n",
    "        else:  # zero_pad\n",
    "            pad = x.new_zeros(pad_count, B, H)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        \"\"\"\n",
    "        h_enc, c_enc: [L_enc, B, H_enc]\n",
    "        返り値: (h0_dec, c0_dec) それぞれ [L_dec, B, H_dec]\n",
    "        \"\"\"\n",
    "        if self.mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            # 層合わせ（まだ enc_hidden 次元のまま）\n",
    "            h = self._match_layers(h_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            c = self._match_layers(c_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            # 次元射影\n",
    "            L, B, H = h.shape\n",
    "            h = self.proj(h)  # broadcasting: [L,B,H_enc]->[L,B,H_dec]\n",
    "            c = self.proj(c)\n",
    "            return h, c\n",
    "\n",
    "        else:  # linear_stack\n",
    "            # [L_enc,B,H_enc] -> [B, L_enc*H_enc]\n",
    "            L_enc, B, H_enc = h_enc.shape\n",
    "            flat_h = h_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            flat_c = c_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            # 線形写像\n",
    "            out_h = self.proj_h(flat_h)  # [B, L_dec*H_dec]\n",
    "            out_c = self.proj_c(flat_c)\n",
    "            # [L_dec,B,H_dec] に戻す\n",
    "            L_dec, H_dec = self.dec_layers, self.dec_hidden\n",
    "            h = out_h.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            c = out_c.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e364b48b-87f6-4715-b4ef-76fef1cb37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_enc: int, # エンコーダ入力変数の数\n",
    "        in_dec: int, # デコーダ入力変数の数\n",
    "        out_dim: int, # 出力変数の数\n",
    "        enc_hidden: int = 128,\n",
    "        dec_hidden: int = 128,\n",
    "        enc_layers: int = 2,\n",
    "        dec_layers: int = 3,\n",
    "        bridge_mode: str = \"zero_pad\",  # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "        dropout: float = 0.0, # LSTMの層間ドロップアウト率\n",
    "        bidirectional_enc: bool = False,  # エンコーダのみ双方向にするかどうか（必要ならEncoderを双方向にも）\n",
    "        head_activation=\"relu\", # 活性化関数\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional_enc = bidirectional_enc\n",
    "        enc_dir = 2 if bidirectional_enc else 1\n",
    "        enc_hidden_eff = enc_hidden * enc_dir  # 双方向なら出力次元が倍\n",
    "\n",
    "        self.enc = nn.LSTM(\n",
    "            input_size=in_enc,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if enc_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional_enc\n",
    "        )\n",
    "\n",
    "        self.dec = nn.LSTM(\n",
    "            input_size=in_dec,\n",
    "            hidden_size=dec_hidden,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if dec_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Encoderが双方向のときは、(h_fwd, h_bwd) を結合した次元 enc_hidden_eff を\n",
    "        # Decoder hidden 次元へ写像する必要がある\n",
    "        self.bridge = StateBridge(\n",
    "            enc_layers=enc_layers * enc_dir,\n",
    "            dec_layers=dec_layers,\n",
    "            enc_hidden=enc_hidden,\n",
    "            dec_hidden=dec_hidden,\n",
    "            mode=bridge_mode\n",
    "        ) if (enc_layers != dec_layers or enc_dir != 1 or enc_hidden != dec_hidden or bridge_mode==\"linear_stack\") else None\n",
    "\n",
    "        self.head = nn.Linear(dec_hidden, out_dim) # 全結合層\n",
    "\n",
    "        self.act = {\n",
    "            \"identity\": nn.Identity(),\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "        }[head_activation]\n",
    "\n",
    "    def _extract_final_states(self, out, hc):\n",
    "        \"\"\"\n",
    "        LSTMの出力から (h_T, c_T) を取り出して成形。\n",
    "        双方向Encoderの場合は各層ごとに [fwd, bwd] を層方向に並べる。\n",
    "        \"\"\"\n",
    "        h, c = hc  # [num_layers * num_directions, B, H]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, enc_x, dec_x):\n",
    "        \"\"\"\n",
    "        enc_x: [B, Te, in_enc]\n",
    "        dec_x: [B, Td, in_dec]\n",
    "        return: yhat [B, Td, out_dim]\n",
    "        \"\"\"\n",
    "        _, (h_T, c_T) = self.enc(enc_x)  # h_T,c_T: [L_enc * dir, B, H_enc]\n",
    "\n",
    "        if self.bridge is not None:\n",
    "            h0_dec, c0_dec = self.bridge(h_T, c_T)  # [L_dec, B, H_dec]\n",
    "        else:\n",
    "            # 形・次元が完全一致ならそのまま\n",
    "            h0_dec, c0_dec = h_T, c_T\n",
    "\n",
    "        dec_out, _ = self.dec(dec_x, (h0_dec, c0_dec))  # [B, Td, H_dec]\n",
    "        yhat = self.act(self.head(dec_out))             # [B, Td, out_dim]\n",
    "        return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5b579-2f5a-41de-b0b1-e22758955478",
   "metadata": {},
   "source": [
    "# モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf070cb5-cce4-4d1d-a0d7-21acffb9d9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----平均----\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "dtype: float64\n",
      "----標準偏差----\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "dtype: float64\n",
      "----y_pos----\n",
      "[5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryoya\\AppData\\Local\\Temp\\ipykernel_5872\\385223451.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(save_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 保存したパスを指定\n",
    "save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\Tiral_3\\LSTM_trial_3_3\"\n",
    "\n",
    "# チェックポイントの読み込み\n",
    "ckpt = torch.load(save_path, map_location=\"cpu\")\n",
    "\n",
    "# モデルの再構築\n",
    "cfg = ckpt[\"cfg\"]\n",
    "model = Seq2SeqLSTM(\n",
    "    in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "    enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "    enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "    bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "    bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "    head_activation=cfg[\"head_activation\"]\n",
    ").to(device)\n",
    "\n",
    "# パラメータをロード\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval() # 評価モードに切り替え\n",
    "\n",
    "# 標準化パラメータの取り出し\n",
    "scaler = ckpt[\"scaler\"]\n",
    "mean = scaler[\"mean\"]                # pandas.Series\n",
    "std  = scaler[\"std\"]                 # pandas.Series\n",
    "data_columns = scaler[\"data_columns\"]  # 列名リスト\n",
    "y_pos = scaler[\"y_pos\"]\n",
    "\n",
    "print(\"----平均----\")\n",
    "print(mean)\n",
    "print(\"----標準偏差----\")\n",
    "print(std)\n",
    "print(\"----y_pos----\")\n",
    "print(y_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b693346-2eb3-487f-a19f-92259a410cf3",
   "metadata": {},
   "source": [
    "# モデル出力と実測値を出力・保存（試しに）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f35968-0f1b-4d8c-b445-92db4d69b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データファイルの読み込み・列番号・タイムステップ長の指定\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_hourlyAve_for_LSTM_trial3.xlsx\"\n",
    "\n",
    "# 列番号（0始まり）で指定\n",
    "enc_cols   = [5, 3, 4]      # エンコーダ入力の列番号\n",
    "dec_cols   = [5, 3]  # デコーダ入力の列番号\n",
    "y_cols      = [4]          # 出力（目的変数）の列番号\n",
    "\n",
    "Te = 72\n",
    "Td = 240\n",
    "\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "# 必要列だけ抽出（順番固定）\n",
    "use_cols = enc_cols + dec_cols + y_cols\n",
    "data = df.iloc[:, use_cols].copy()\n",
    "\n",
    "data_norm = (data - mean) / std # 全期間のデータを標準化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b839ee-6c42-41ed-af82-9792a1d5ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルに入力する変数を作成する (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "\n",
    "Fe, Fd, Fo = cfg[\"in_enc\"], cfg[\"in_dec\"], cfg[\"out_dim\"]\n",
    "\n",
    "# 出力したい部分の開始行番号を指定（0始まり） 38664 ,38760,(13032: 2020/06/27), (48048: 2024/06/25)\n",
    "s = 48048\n",
    "\n",
    "enc_window = data_norm.iloc[s : s + Te]\n",
    "dec_window = data_norm.iloc[s + Te : s + Te + Td]\n",
    "# テンソル化\n",
    "enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))\n",
    "dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))\n",
    "y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))\n",
    "\n",
    "# モデルに入力できる形へ変形\n",
    "enc_in = enc_X.unsqueeze(0).to(device)\n",
    "dec_in = dec_X.unsqueeze(0).to(device)\n",
    "\n",
    "# デコーダに対応する時刻、実測のYを抽出\n",
    "dec_T = df.iloc[s+Te:s+Te+Td, 0:2]\n",
    "obs_Y = df.iloc[s+Te:s+Te+Td, y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae75e75-f1a4-4193-95e4-fb7faec906af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルから予測\n",
    "pred_Y_norm = model(enc_in, dec_in)\n",
    "pred_Y_norm = pred_Y_norm.squeeze(0)\n",
    "\n",
    "# 逆標準化\n",
    "ymean = mean.iloc[y_pos]\n",
    "ystd = std.iloc[y_pos]\n",
    "ymean_t = torch.tensor(ymean.values, dtype=torch.float32, device=pred_Y_norm.device).view(1, -1)\n",
    "ystd_t  = torch.tensor(ystd.values,  dtype=torch.float32, device=pred_Y_norm.device).view(1, -1)\n",
    "\n",
    "pred_Y = pred_Y_norm * ystd_t + ymean_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de87871e-3a85-4ee6-a8d6-4fcfb660905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelに保存しました: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\Tiral_3\\output_3_3_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 予測結果などを結合し、エクセルで出力\n",
    "\n",
    "# 1. pandas Series → DataFrame\n",
    "dec_T_df = pd.DataFrame(dec_T).reset_index(drop=True)\n",
    "obs_Y_df  = pd.DataFrame(obs_Y).reset_index(drop=True)\n",
    "\n",
    "# 2. Tensor → NumPy → DataFrame\n",
    "pred_Y_df = pd.DataFrame(pred_Y.detach().cpu().numpy())\n",
    "dec_X_df  = pd.DataFrame(dec_X.detach().cpu().numpy())\n",
    "\n",
    "# 3. 横方向に結合\n",
    "out_df = pd.concat([dec_T_df, obs_Y_df, pred_Y_df, dec_X_df], axis=1)\n",
    "\n",
    "\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\Tiral_3\\output_3_3_3.xlsx\"\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(\"Excelに保存しました:\", excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f039a8-8a4d-4a4c-8579-e1f4a1193e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14461d3-6c0c-49dd-9170-f9f710b0f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe3d75-b9c0-4e96-b1ef-edc7341103fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
