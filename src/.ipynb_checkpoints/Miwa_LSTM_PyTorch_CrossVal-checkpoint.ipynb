{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963bce3f-1775-4161-9421-d079e6fe003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c38fc-ede6-489b-aca3-cdefb225dbda",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f48d8da-0d81-4a62-a583-24286c7cde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ユーザ設定 ======\n",
    "\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\CrossVal_4\\Miwa_hourlyAve_for_LSTM_CrossVal_4.xlsx\"\n",
    "flood_idx_path_train = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\CrossVal_4\\Miwa_flood_idx_CrossVal_4_train.xlsx\"\n",
    "\n",
    "# 列番号（0始まり）で指定\n",
    "enc_cols   = [5, 3, 4]      # エンコーダ入力の列番号（例：3変数）\n",
    "dec_cols   = [5, 3]  # デコーダ入力の列番号（例：2変数）\n",
    "y_cols      = [4]          # 出力（目的変数）の列番号（例：1変数）\n",
    "\n",
    "Te = 72    # エンコーダのタイムステップ長\n",
    "Td = 24    # デコーダのタイムステップ長\n",
    "\n",
    "\n",
    "# 洪水区間（1始まり行番号で指定してOK。Python内部で0始まりに直す）\n",
    "df_ranges_train = pd.read_excel(flood_idx_path_train, header=0)\n",
    "flood_ranges_train_1based = [tuple(x) for x in df_ranges_train.to_numpy()]\n",
    "\n",
    "# 0-basedに変換（pandasは0-based）\n",
    "flood_ranges_train = [(s-1, e-1) for (s, e) in flood_ranges_train_1based]\n",
    "\n",
    "\n",
    "\n",
    "# ====== 読み込み ======\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "# 必要列だけ抽出（順番固定）\n",
    "use_cols = enc_cols + dec_cols + y_cols\n",
    "data = df.iloc[:, use_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a22806a-34db-4259-a00d-423f88dd6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---平均（train）----\n",
      "CumRain_24h     13.542308\n",
      "Qin(m3/s)       41.130710\n",
      "Tur(ppm)       386.520820\n",
      "CumRain_24h     13.542308\n",
      "Qin(m3/s)       41.130710\n",
      "Tur(ppm)       386.520820\n",
      "dtype: float64\n",
      "----標準偏差（train）----\n",
      "CumRain_24h     25.957971\n",
      "Qin(m3/s)       40.794214\n",
      "Tur(ppm)       935.757710\n",
      "CumRain_24h     25.957971\n",
      "Qin(m3/s)       40.794214\n",
      "Tur(ppm)       935.757710\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ====== 標準化：train dataから平均・標準偏差を算出 ======\n",
    "\n",
    "flood_data_train_parts = [data.iloc[s:e+1, :] for (s, e) in flood_ranges_train]\n",
    "flood_data_train = pd.concat(flood_data_train_parts, axis=0)\n",
    "\n",
    "mean = flood_data_train.mean(numeric_only=True)\n",
    "std  = flood_data_train.std(numeric_only=True).replace(0, 1.0)\n",
    "data_norm = (data - mean) / std # 全期間のデータを標準化\n",
    "\n",
    "print('---平均（train）----')\n",
    "print(mean)\n",
    "\n",
    "print('----標準偏差（train）----')\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561171f-1e70-4dfe-a140-b7335fc31bbc",
   "metadata": {},
   "source": [
    "## 各出水ごとにDataSetを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3110981d-e3fb-4906-9c2d-043f927e0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, name, triplets):\n",
    "        self.name = name\n",
    "        self.triplets = triplets  # list of (enc_X, dec_X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triplets[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    enc_seqs, dec_seqs, ys = zip(*batch)\n",
    "    # ここでは全サンプル同一長さ前提（Te/Td固定）なので単純stack\n",
    "    enc_x = torch.stack(enc_seqs, dim=0)  # [B, Te, Fe]\n",
    "    dec_x = torch.stack(dec_seqs, dim=0)  # [B, Td, Fd]\n",
    "    y     = torch.stack(ys,       dim=0)  # [B, Td, Fo]\n",
    "    \n",
    "    # マスク（将来可変長のときに使う）\n",
    "    B, Td, _ = y.shape\n",
    "    mask = torch.ones(B, Td, 1, dtype=torch.float32)\n",
    "    return enc_x, dec_x, y, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45546f1f-6969-463f-994e-7efed39ffcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "idx = 0 # インデックスの初期化\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_train:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "\n",
    "    samples_train = []\n",
    "    \n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_train.append((enc_X, dec_X, y))\n",
    "\n",
    "    idx += 1\n",
    "    datasets.append(FloodSeq2SeqDataset(f\"Dataset_{idx}\", samples_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4bb266-1be7-4185-9264-f4735ffc1408",
   "metadata": {},
   "source": [
    "## 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6841fb-178a-488f-9507-d1d39201e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    \"\"\"collate_fnの戻り値が (enc,dec,y) か (enc,dec,y,mask) のどちらでも対応\"\"\"\n",
    "    if len(batch) == 3:\n",
    "        enc_x, dec_x, y = batch\n",
    "        mask = torch.ones_like(y[..., :1])  # [B,Td,1]\n",
    "    elif len(batch) == 4:\n",
    "        enc_x, dec_x, y, mask = batch\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected batch format\")\n",
    "    return enc_x.to(device), dec_x.to(device), y.to(device), mask.to(device)\n",
    "\n",
    "def masked_mse(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1] (1=valid, 0=pad)\n",
    "    diff2 = (pred - target) ** 2\n",
    "    diff2 = diff2 * mask\n",
    "    denom = mask.sum(dim=(1,2)).clamp_min(1.0)  # per-sample\n",
    "    per_sample = diff2.sum(dim=(1,2)) / denom\n",
    "    return per_sample.mean()\n",
    "\n",
    "def masked_rmse(pred, target, mask):\n",
    "    return torch.sqrt(masked_mse(pred, target, mask))\n",
    "\n",
    "def masked_r2(pred, target, mask):\n",
    "    # R² = 1 - SSE/SST, マスク版\n",
    "    mean = (target * mask).sum(dim=(1,2), keepdim=True) / mask.sum(dim=(1,2), keepdim=True).clamp_min(1.0)\n",
    "    sse = ((pred - target) ** 2 * mask).sum(dim=(1,2))\n",
    "    sst = ((target - mean) ** 2 * mask).sum(dim=(1,2)).clamp_min(1e-12)\n",
    "    r2  = 1.0 - sse / sst\n",
    "    return r2.mean()\n",
    "\n",
    "def masked_corr(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1]\n",
    "    pred = pred * mask\n",
    "    target = target * mask\n",
    "    valid = mask.sum(dim=(1,2)).clamp_min(1.0)\n",
    "\n",
    "    # 平均\n",
    "    mean_pred = pred.sum(dim=(1,2)) / valid\n",
    "    mean_target = target.sum(dim=(1,2)) / valid\n",
    "\n",
    "    # 偏差\n",
    "    diff_pred = (pred - mean_pred.view(-1,1,1)) * mask\n",
    "    diff_target = (target - mean_target.view(-1,1,1)) * mask\n",
    "\n",
    "    # 共分散と分散\n",
    "    cov = (diff_pred * diff_target).sum(dim=(1,2)) / valid\n",
    "    var_pred = (diff_pred**2).sum(dim=(1,2)) / valid\n",
    "    var_target = (diff_target**2).sum(dim=(1,2)) / valid\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_pred * var_target) + 1e-12)\n",
    "    return corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523d00e-d03d-4403-9c7f-a7a3b972b5ff",
   "metadata": {},
   "source": [
    "## モデル定義（Seq2SeqLSTM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39049592-69b7-424d-ba87-29ef8388af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateBridge(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoderの(h, c)をDecoder初期状態へ写像するブリッジ。\n",
    "    - 層数/隠れ次元が異なってもOK\n",
    "    - bridge_mode:\n",
    "        - \"zero_pad\":  層合わせ=0埋め or 切り落とし、隠れ次元は線形射影\n",
    "        - \"repeat_top\":層合わせ=最上層の繰り返し/切り落とし、隠れ次元は線形射影\n",
    "        - \"linear_stack\": [B, L_enc, H_enc] -> 線形で [B, L_dec, H_dec] へ（層方向も学習で混合）\n",
    "\n",
    "    - enc_layers: エンコーダの層の深さ\n",
    "    - dec_layers: デコーダの層の深さ\n",
    "    - enc_hidden: エンコーダのノード数\n",
    "    - dec_hidden: デコーダのノード数\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hidden, dec_hidden, mode=\"zero_pad\"):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.enc_hidden = enc_hidden\n",
    "        self.dec_hidden = dec_hidden\n",
    "        self.mode = mode\n",
    "\n",
    "        # 隠れ次元の変換（h/c共用）\n",
    "        if mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            self.proj = nn.Linear(enc_hidden, dec_hidden, bias=True)\n",
    "        elif mode == \"linear_stack\":\n",
    "            # 層方向もまとめて線形変換\n",
    "            self.proj_h = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "            self.proj_c = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bridge mode: {mode}\")\n",
    "\n",
    "    def _match_layers(self, x, how=\"zero_pad\"):\n",
    "        \"\"\"\n",
    "        x: [L_enc, B, H_enc] を層数だけ合わせる（隠れ次元は未変換）\n",
    "        return: [L_dec, B, H_enc]\n",
    "\n",
    "        B: バッチサイズ\n",
    "        \"\"\"\n",
    "        L_enc, B, H = x.shape\n",
    "        L_dec = self.dec_layers\n",
    "\n",
    "        if L_dec == L_enc:\n",
    "            return x\n",
    "\n",
    "        if L_dec < L_enc:\n",
    "            # 上位層を優先して切り落とす（直観的には最上層が一番抽象的）\n",
    "            return x[:L_dec, :, :]\n",
    "\n",
    "        # L_dec > L_enc の場合\n",
    "        pad_count = L_dec - L_enc\n",
    "        if how == \"repeat_top\":\n",
    "            top = x[-1:, :, :].expand(pad_count, B, H)  # 最上層を複製\n",
    "            return torch.cat([x, top], dim=0)\n",
    "        else:  # zero_pad\n",
    "            pad = x.new_zeros(pad_count, B, H)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        \"\"\"\n",
    "        h_enc, c_enc: [L_enc, B, H_enc]\n",
    "        返り値: (h0_dec, c0_dec) それぞれ [L_dec, B, H_dec]\n",
    "        \"\"\"\n",
    "        if self.mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            # 層合わせ（まだ enc_hidden 次元のまま）\n",
    "            h = self._match_layers(h_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            c = self._match_layers(c_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            # 次元射影\n",
    "            L, B, H = h.shape\n",
    "            h = self.proj(h)  # broadcasting: [L,B,H_enc]->[L,B,H_dec]\n",
    "            c = self.proj(c)\n",
    "            return h, c\n",
    "\n",
    "        else:  # linear_stack\n",
    "            # [L_enc,B,H_enc] -> [B, L_enc*H_enc]\n",
    "            L_enc, B, H_enc = h_enc.shape\n",
    "            flat_h = h_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            flat_c = c_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            # 線形写像\n",
    "            out_h = self.proj_h(flat_h)  # [B, L_dec*H_dec]\n",
    "            out_c = self.proj_c(flat_c)\n",
    "            # [L_dec,B,H_dec] に戻す\n",
    "            L_dec, H_dec = self.dec_layers, self.dec_hidden\n",
    "            h = out_h.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            c = out_c.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8928cc8c-8a95-4825-b791-2c67940f313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_enc: int, # エンコーダ入力変数の数\n",
    "        in_dec: int, # デコーダ入力変数の数\n",
    "        out_dim: int, # 出力変数の数\n",
    "        enc_hidden: int = 128,\n",
    "        dec_hidden: int = 128,\n",
    "        enc_layers: int = 2,\n",
    "        dec_layers: int = 3,\n",
    "        bridge_mode: str = \"zero_pad\",  # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "        dropout: float = 0.0, # LSTMの層間ドロップアウト率\n",
    "        bidirectional_enc: bool = False,  # エンコーダのみ双方向にするかどうか（必要ならEncoderを双方向にも）\n",
    "        head_activation=\"relu\", # 活性化関数\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,           # 時間方向のカーネル幅（奇数推奨）\n",
    "        conv_channels: int = None,      # 省略時は dec_hidden を維持\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional_enc = bidirectional_enc\n",
    "        enc_dir = 2 if bidirectional_enc else 1\n",
    "        enc_hidden_eff = enc_hidden * enc_dir  # 双方向なら出力次元が倍\n",
    "\n",
    "        self.use_conv = bool(use_conv)\n",
    "\n",
    "        self.enc = nn.LSTM(\n",
    "            input_size=in_enc,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if enc_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional_enc\n",
    "        )\n",
    "\n",
    "        self.dec = nn.LSTM(\n",
    "            input_size=in_dec,\n",
    "            hidden_size=dec_hidden,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if dec_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Encoderが双方向のときは、(h_fwd, h_bwd) を結合した次元 enc_hidden_eff を\n",
    "        # Decoder hidden 次元へ写像する必要がある\n",
    "        self.bridge = StateBridge(\n",
    "            enc_layers=enc_layers * enc_dir,\n",
    "            dec_layers=dec_layers,\n",
    "            enc_hidden=enc_hidden,\n",
    "            dec_hidden=dec_hidden,\n",
    "            mode=bridge_mode\n",
    "        ) if (enc_layers != dec_layers or enc_dir != 1 or enc_hidden != dec_hidden or bridge_mode==\"linear_stack\") else None\n",
    "\n",
    "        \n",
    "        # ---------- 中間層（1次元畳み込み） ----------\n",
    "        if conv_channels is None:\n",
    "            conv_channels = dec_hidden\n",
    "        self.conv_channels = conv_channels\n",
    "        if self.use_conv:\n",
    "            # Conv1dは [B, C=特徴, T=時間] を受け取るので後で転置する\n",
    "            padding = conv_kernel // 2  # SAME相当（奇数カーネル推奨）\n",
    "            self.conv1d = nn.Conv1d(\n",
    "                in_channels=dec_hidden,\n",
    "                out_channels=conv_channels,\n",
    "                kernel_size=conv_kernel,\n",
    "                padding=padding\n",
    "            )\n",
    "            self.conv_act = {\n",
    "                \"identity\": nn.Identity(),\n",
    "                \"relu\": nn.ReLU(),\n",
    "                \"tanh\": nn.Tanh(),\n",
    "                \"sigmoid\": nn.Sigmoid(),\n",
    "            }.get(head_activation, nn.ReLU())\n",
    "            self.conv_dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "            # 出力ヘッドは conv_channels → out_dim\n",
    "            self.head = nn.Linear(conv_channels, out_dim)\n",
    "            # ここでの self.act はヘッド直前では使わない（Conv後に適用済み）\n",
    "            self.act = nn.Identity()\n",
    "        else:\n",
    "            # 畳み込みを使わない場合は dec_hidden → out_dim\n",
    "            self.head = nn.Linear(dec_hidden, out_dim)\n",
    "            self.act = {\n",
    "                \"identity\": nn.Identity(),\n",
    "                \"relu\": nn.ReLU(),\n",
    "                \"tanh\": nn.Tanh(),\n",
    "                \"sigmoid\": nn.Sigmoid(),\n",
    "            }[head_activation]\n",
    "\n",
    "    def _extract_final_states(self, out, hc):\n",
    "        \"\"\"\n",
    "        LSTMの出力から (h_T, c_T) を取り出して成形。\n",
    "        双方向Encoderの場合は各層ごとに [fwd, bwd] を層方向に並べる。\n",
    "        \"\"\"\n",
    "        h, c = hc  # [num_layers * num_directions, B, H]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, enc_x, dec_x):\n",
    "        \"\"\"\n",
    "        enc_x: [B, Te, in_enc]\n",
    "        dec_x: [B, Td, in_dec]\n",
    "        return: yhat [B, Td, out_dim]\n",
    "        \"\"\"\n",
    "        # ----- Encoder -----\n",
    "        _, (h_T, c_T) = self.enc(enc_x)  # h_T,c_T: [L_enc * dir, B, H_enc]\n",
    "\n",
    "        # ----- Bridge -----\n",
    "        if self.bridge is not None:\n",
    "            h0_dec, c0_dec = self.bridge(h_T, c_T)  # [L_dec, B, H_dec]\n",
    "        else:\n",
    "            h0_dec, c0_dec = h_T, c_T\n",
    "\n",
    "        # ----- Decoder -----\n",
    "        dec_out, _ = self.dec(dec_x, (h0_dec, c0_dec))  # [B, Td, H_dec]\n",
    "\n",
    "        if self.use_conv:\n",
    "            # 時間方向のConv1d: [B, H_dec, Td] -> Conv -> [B, C, Td] -> [B, Td, C]\n",
    "            x = dec_out.transpose(1, 2)             # [B, H_dec, Td]\n",
    "            x = self.conv1d(x)                      # [B, conv_channels, Td]\n",
    "            x = self.conv_act(x)\n",
    "            x = self.conv_dropout(x)\n",
    "            x = x.transpose(1, 2)                   # [B, Td, conv_channels]\n",
    "            yhat = self.head(x)                     # [B, Td, out_dim]\n",
    "        else:\n",
    "            # 従来パス：活性化→線形\n",
    "            yhat = self.head(self.act(dec_out))     # [B, Td, out_dim]\n",
    "\n",
    "        return yhat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf4a47e-3e81-4d98-a70f-cd52577f51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重み初期化用の関数\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # 例: Xavier（正規分布）\n",
    "        # init.xavier_normal_(m.weight)\n",
    "        # ReLU系のLinearならHeにしたい場合:\n",
    "        init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Conv1d):\n",
    "        # Conv1d も Linear と同様に初期化可能\n",
    "        # 例: Xavier（正規分布）\n",
    "        # init.xavier_normal_(m.weight)\n",
    "        # ReLU系のLinearならHeにしたい場合:\n",
    "        init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        # LSTM の場合は named_parameters() で内部ゲートを個別に初期化\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                # 入力→隠れ：Xavier が安定\n",
    "                with torch.no_grad():\n",
    "                    init.xavier_uniform_(param)\n",
    "            elif \"weight_hh\" in name:\n",
    "                # 隠れ→隠れ：Orthogonal が定番\n",
    "                with torch.no_grad():\n",
    "                    init.orthogonal_(param)\n",
    "            elif \"bias\" in name:\n",
    "                with torch.no_grad():\n",
    "                    init.zeros_(param)\n",
    "                    # 必要なら忘却ゲートバイアスを +1 初期化することも可能\n",
    "                    # hidden_size = param.shape[0] // 4\n",
    "                    # param[hidden_size:2*hidden_size] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab996d5-3b69-4cd0-9de9-801f3aed70ad",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定\n",
    "### ※保存Excelファイルのパスも指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be0533b-eb5a-4c3e-8543-c580fc7e75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg = {\n",
    "    # Model\n",
    "    \"in_enc\": 3,\n",
    "    \"in_dec\": 2,\n",
    "    \"out_dim\": 1,\n",
    "    \"enc_hidden\": 16, # 【要変更】\n",
    "    \"dec_hidden\": 16, # 【要変更】\n",
    "    \"enc_layers\": 2, # 【要変更】\n",
    "    \"dec_layers\": 2, # 【要変更】\n",
    "    \"bridge_mode\": \"zero_pad\",   # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "    \"batch_size\": 512, # 【要変更】\n",
    "    \"dropout\": 0.1,\n",
    "    \"bidirectional_enc\": False,\n",
    "    \"head_activation\": \"relu\", # \"identity\", \"relu\", \"tanh\", \"sigmoid\" など 【要変更】\n",
    "    # Train\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-2,\n",
    "    \"weight_decay\": 0.0, # L2正規化係数。0なら無効\n",
    "    \"grad_clip\": 1.0, # 勾配クリッピングの閾値。０かNoneなら無効\n",
    "    \"print_every\": 1, # 学習の進捗を何エポックごとに出力するか\n",
    "    \"patience\": 10, # early stopping\n",
    "    \"use_conv\": True # 畳み込み層を使うかどうか【要変更】\n",
    "}\n",
    "\n",
    "save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_4/CrossVal_4_result_3_6_2.xlsx\" # 【要変更】\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133729e-3d3a-43fd-91c6-b3996c0d0549",
   "metadata": {},
   "source": [
    "## 学習関数・評価関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec129399-e7fc-45dc-85f7-feba4053ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数・評価関数の定義\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if cfg[\"grad_clip\"]:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = enc_x.size(0) # バッチサイズ\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return total_loss / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0; total_rmse = 0.0; total_r2 = 0.0; total_corr = 0.0; n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "        rmse = masked_rmse(yhat, y, mask)\n",
    "        r2   = masked_r2(yhat, y, mask)\n",
    "        corr = masked_corr(yhat, y, mask)\n",
    "\n",
    "        bs = enc_x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_rmse += rmse.item() * bs\n",
    "        total_r2   += r2.item() * bs\n",
    "        total_corr += corr.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / max(n,1),\n",
    "        \"rmse\": total_rmse / max(n,1),\n",
    "        \"r2\":   total_r2   / max(n,1),\n",
    "        \"corr\": total_corr / max(n,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43fe2d27-82c0-4c41-a91d-6c62e414e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize_y_by_index(y_std, mean, std, y_pos):\n",
    "    \"\"\"\n",
    "    y_std:  標準化スケールの出力テンソル [B, T, Fo]\n",
    "    mean, std: pandas.Series（学習時にfitしたもの。index=列名）\n",
    "    y_pos: 出力列の「列番号（位置）」リスト（例: [Fe+Fd, Fe+Fd+1, ...]）\n",
    "    return: 元スケールの y [B, T, Fo]\n",
    "    \"\"\"\n",
    "    m = torch.tensor(mean.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    s = torch.tensor(std.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    return y_std * s + m\n",
    "\n",
    "\n",
    "def masked_corr(pred, target, mask, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    マスク付きピアソン相関係数（バッチ平均）\n",
    "    pred/target: [B, T, Fo], mask: [B, T, 1]（1=有効, 0=無効）\n",
    "    返り値: スカラー（バッチ平均の相関）\n",
    "    \"\"\"\n",
    "    # 有効点数（サンプルごと）\n",
    "    valid = mask.sum(dim=(1, 2)).clamp_min(1.0)  # [B]\n",
    "\n",
    "    # 平均（サンプルごと）\n",
    "    mean_p = (pred * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "    mean_t = (target * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "\n",
    "    # 偏差\n",
    "    dp = (pred - mean_p) * mask\n",
    "    dt = (target - mean_t) * mask\n",
    "\n",
    "    # 共分散・分散（サンプルごと）\n",
    "    cov = dp.mul(dt).sum(dim=(1, 2)) / valid        # [B]\n",
    "    var_p = dp.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "    var_t = dt.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_p * var_t) + eps)  # [B]\n",
    "    return corr.mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale_by_index(model, loader, mean, std, data_columns, y_pos):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 厳密集計用\n",
    "    total_sse = 0.0   # 全有効点での誤差二乗和\n",
    "    total_cnt = 0.0   # 全有効点数（マスク=1の総数）\n",
    "    total_r2  = 0.0   # R² のバッチ加重平均用\n",
    "    total_corr = 0.0  # 相関R のバッチ加重平均用\n",
    "    n = 0             # サンプル数（バッチ内のBの合計）\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 3:\n",
    "            enc_x, dec_x, y_std = batch\n",
    "            mask = torch.ones_like(y_std[..., :1])\n",
    "        elif len(batch) == 4:\n",
    "            enc_x, dec_x, y_std, mask = batch\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected batch format\")\n",
    "\n",
    "        # 統一デバイス・dtype\n",
    "        enc_x = enc_x.to(device=device, dtype=torch.float32)\n",
    "        dec_x = dec_x.to(device=device, dtype=torch.float32)\n",
    "        y_std = y_std.to(device=device, dtype=torch.float32)\n",
    "        mask  = mask.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # 予測（標準化スケール）\n",
    "        yhat_std = model(enc_x, dec_x)\n",
    "\n",
    "        # 出力だけ逆標準化\n",
    "        yhat = inverse_standardize_y_by_index(yhat_std, mean, std, y_pos)\n",
    "        y    = inverse_standardize_y_by_index(y_std,     mean, std, y_pos)\n",
    "\n",
    "        # 厳密RMSE用：SSEと有効点数を直接合算\n",
    "        sse_batch = ((yhat - y) ** 2 * mask).sum().item()\n",
    "        cnt_batch = mask.sum().item()\n",
    "        total_sse += sse_batch\n",
    "        total_cnt += max(cnt_batch, 1.0)\n",
    "\n",
    "        # R² と 相関R はサンプル数で加重平均\n",
    "        r2    = masked_r2(yhat, y, mask).item()\n",
    "        corr  = masked_corr(yhat, y, mask).item()\n",
    "        bs = enc_x.size(0)\n",
    "        total_r2   += r2   * bs\n",
    "        total_corr += corr * bs\n",
    "        n += bs\n",
    "\n",
    "    mse  = total_sse / max(total_cnt, 1.0)\n",
    "    rmse = mse ** 0.5\n",
    "    r2   = total_r2   / max(n, 1)\n",
    "    corr = total_corr / max(n, 1)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \"corr\": corr}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a7321-128e-4e53-8c50-3cb077d3d40f",
   "metadata": {},
   "source": [
    "## 学習（交差検証のループ）\n",
    "### ※各ループにおいて、重みやバイアスの初期値を変えて、5回繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef1d258-c1b0-4830-b4ce-389a6195421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss=0.9322 | val_loss=0.1953 val_rmse=0.4365 val_r2=-98403.5698val_corr=0.1160\n",
      "[2/100] train_loss=0.7585 | val_loss=0.1341 val_rmse=0.3525 val_r2=-48662.5853val_corr=0.0940\n",
      "[3/100] train_loss=0.5183 | val_loss=0.2155 val_rmse=0.4562 val_r2=-94221.2457val_corr=0.0897\n",
      "[4/100] train_loss=0.4976 | val_loss=0.1237 val_rmse=0.3385 val_r2=-41366.5299val_corr=0.1139\n",
      "[5/100] train_loss=0.4095 | val_loss=0.1195 val_rmse=0.3392 val_r2=-55366.4548val_corr=0.1299\n",
      "[6/100] train_loss=0.3714 | val_loss=0.0927 val_rmse=0.2970 val_r2=-27819.9314val_corr=0.1369\n",
      "[7/100] train_loss=0.3040 | val_loss=0.0647 val_rmse=0.2460 val_r2=-8760.2179val_corr=0.1354\n",
      "[8/100] train_loss=0.2744 | val_loss=0.0658 val_rmse=0.2492 val_r2=-12126.0094val_corr=0.1258\n",
      "[9/100] train_loss=0.2578 | val_loss=0.0578 val_rmse=0.2343 val_r2=-10131.5868val_corr=0.1391\n",
      "[10/100] train_loss=0.2469 | val_loss=0.0517 val_rmse=0.2244 val_r2=-10512.2095val_corr=0.1599\n",
      "[11/100] train_loss=0.2227 | val_loss=0.0880 val_rmse=0.2899 val_r2=-32661.9507val_corr=0.1180\n",
      "[12/100] train_loss=0.2252 | val_loss=0.0628 val_rmse=0.2413 val_r2=-9267.2006val_corr=0.1285\n",
      "[13/100] train_loss=0.1960 | val_loss=0.0508 val_rmse=0.2207 val_r2=-6193.0752val_corr=0.1415\n",
      "[14/100] train_loss=0.2005 | val_loss=0.0658 val_rmse=0.2497 val_r2=-17777.5837val_corr=0.1336\n",
      "[15/100] train_loss=0.1919 | val_loss=0.0681 val_rmse=0.2550 val_r2=-21495.9683val_corr=0.1257\n",
      "[16/100] train_loss=0.1798 | val_loss=0.0510 val_rmse=0.2177 val_r2=-3892.2298val_corr=0.1254\n",
      "[17/100] train_loss=0.1801 | val_loss=0.0570 val_rmse=0.2302 val_r2=-7496.4535val_corr=0.1252\n",
      "[18/100] train_loss=0.1630 | val_loss=0.0699 val_rmse=0.2561 val_r2=-13885.4481val_corr=0.1176\n",
      "[19/100] train_loss=0.1591 | val_loss=0.0627 val_rmse=0.2407 val_r2=-5021.0955val_corr=0.1196\n",
      "[20/100] train_loss=0.1529 | val_loss=0.0619 val_rmse=0.2417 val_r2=-4014.8436val_corr=0.1245\n",
      "[21/100] train_loss=0.1467 | val_loss=0.0693 val_rmse=0.2529 val_r2=-5174.4238val_corr=0.1276\n",
      "[22/100] train_loss=0.1423 | val_loss=0.0731 val_rmse=0.2599 val_r2=-4925.4812val_corr=0.1299\n",
      "[23/100] train_loss=0.1333 | val_loss=0.0696 val_rmse=0.2542 val_r2=-2708.3844val_corr=0.1450\n",
      "Early stopping at epoch 23 (best epoch=13, val_loss=0.0508)\n",
      "1 番目の 1 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.9328 | val_loss=0.2240 val_rmse=0.4695 val_r2=-146801.2383val_corr=0.1059\n",
      "[2/100] train_loss=0.7282 | val_loss=0.1927 val_rmse=0.4261 val_r2=-124236.0710val_corr=0.0912\n",
      "[3/100] train_loss=0.5236 | val_loss=0.1896 val_rmse=0.4273 val_r2=-73950.1056val_corr=0.1004\n",
      "[4/100] train_loss=0.4877 | val_loss=0.1113 val_rmse=0.3250 val_r2=-37328.0556val_corr=0.1329\n",
      "[5/100] train_loss=0.4021 | val_loss=0.1572 val_rmse=0.3925 val_r2=-102314.6971val_corr=0.1103\n",
      "[6/100] train_loss=0.3584 | val_loss=0.1134 val_rmse=0.3320 val_r2=-54525.4758val_corr=0.1260\n",
      "[7/100] train_loss=0.3059 | val_loss=0.0619 val_rmse=0.2392 val_r2=-4306.9200val_corr=0.1436\n",
      "[8/100] train_loss=0.2915 | val_loss=0.0592 val_rmse=0.2340 val_r2=-7047.7998val_corr=0.1282\n",
      "[9/100] train_loss=0.2557 | val_loss=0.0694 val_rmse=0.2546 val_r2=-16285.1563val_corr=0.1259\n",
      "[10/100] train_loss=0.2420 | val_loss=0.0521 val_rmse=0.2234 val_r2=-6206.8364val_corr=0.1483\n",
      "[11/100] train_loss=0.2266 | val_loss=0.0518 val_rmse=0.2209 val_r2=-4988.4037val_corr=0.1434\n",
      "[12/100] train_loss=0.2166 | val_loss=0.0559 val_rmse=0.2277 val_r2=-7634.1279val_corr=0.1295\n",
      "[13/100] train_loss=0.2044 | val_loss=0.0522 val_rmse=0.2201 val_r2=-6567.0795val_corr=0.1286\n",
      "[14/100] train_loss=0.1952 | val_loss=0.0483 val_rmse=0.2114 val_r2=-5181.6884val_corr=0.1282\n",
      "[15/100] train_loss=0.1926 | val_loss=0.0566 val_rmse=0.2293 val_r2=-7338.5612val_corr=0.1266\n",
      "[16/100] train_loss=0.1913 | val_loss=0.0575 val_rmse=0.2307 val_r2=-8511.6230val_corr=0.1403\n",
      "[17/100] train_loss=0.1853 | val_loss=0.0538 val_rmse=0.2230 val_r2=-3276.2886val_corr=0.1309\n",
      "[18/100] train_loss=0.1814 | val_loss=0.0581 val_rmse=0.2313 val_r2=-4641.8271val_corr=0.1374\n",
      "[19/100] train_loss=0.1719 | val_loss=0.0639 val_rmse=0.2440 val_r2=-10600.3295val_corr=0.1419\n",
      "[20/100] train_loss=0.1591 | val_loss=0.0584 val_rmse=0.2319 val_r2=-5084.1668val_corr=0.1320\n",
      "[21/100] train_loss=0.1536 | val_loss=0.0610 val_rmse=0.2378 val_r2=-5029.7336val_corr=0.1325\n",
      "[22/100] train_loss=0.1512 | val_loss=0.0674 val_rmse=0.2488 val_r2=-5718.8595val_corr=0.1306\n",
      "[23/100] train_loss=0.1471 | val_loss=0.0684 val_rmse=0.2506 val_r2=-4759.0952val_corr=0.1211\n",
      "[24/100] train_loss=0.1537 | val_loss=0.0671 val_rmse=0.2487 val_r2=-11222.0184val_corr=0.1319\n",
      "Early stopping at epoch 24 (best epoch=14, val_loss=0.0483)\n",
      "1 番目の 2 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.8266 | val_loss=0.1617 val_rmse=0.3914 val_r2=-86084.2995val_corr=0.0832\n",
      "[2/100] train_loss=0.4975 | val_loss=0.1384 val_rmse=0.3663 val_r2=-38454.7137val_corr=0.1206\n",
      "[3/100] train_loss=0.4246 | val_loss=0.0874 val_rmse=0.2874 val_r2=-24118.4665val_corr=0.1486\n",
      "[4/100] train_loss=0.3471 | val_loss=0.1136 val_rmse=0.3334 val_r2=-65753.0679val_corr=0.1402\n",
      "[5/100] train_loss=0.2943 | val_loss=0.0600 val_rmse=0.2392 val_r2=-17447.3597val_corr=0.1194\n",
      "[6/100] train_loss=0.2757 | val_loss=0.0487 val_rmse=0.2122 val_r2=-3173.9932val_corr=0.1171\n",
      "[7/100] train_loss=0.2420 | val_loss=0.0557 val_rmse=0.2278 val_r2=-10173.9779val_corr=0.1281\n",
      "[8/100] train_loss=0.2237 | val_loss=0.0498 val_rmse=0.2162 val_r2=-4020.7868val_corr=0.1402\n",
      "[9/100] train_loss=0.2052 | val_loss=0.0501 val_rmse=0.2189 val_r2=-5245.5853val_corr=0.1386\n",
      "[10/100] train_loss=0.2019 | val_loss=0.0537 val_rmse=0.2229 val_r2=-5931.3785val_corr=0.1332\n",
      "[11/100] train_loss=0.1925 | val_loss=0.0573 val_rmse=0.2305 val_r2=-7798.5669val_corr=0.1206\n",
      "[12/100] train_loss=0.1848 | val_loss=0.0524 val_rmse=0.2202 val_r2=-7241.9449val_corr=0.1223\n",
      "[13/100] train_loss=0.1822 | val_loss=0.0614 val_rmse=0.2379 val_r2=-6946.7055val_corr=0.1226\n",
      "[14/100] train_loss=0.1780 | val_loss=0.0605 val_rmse=0.2365 val_r2=-6233.6668val_corr=0.1267\n",
      "[15/100] train_loss=0.1705 | val_loss=0.0573 val_rmse=0.2315 val_r2=-4006.1641val_corr=0.1259\n",
      "[16/100] train_loss=0.1676 | val_loss=0.0604 val_rmse=0.2364 val_r2=-5981.9118val_corr=0.1413\n",
      "Early stopping at epoch 16 (best epoch=6, val_loss=0.0487)\n",
      "1 番目の 3 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.8912 | val_loss=0.2904 val_rmse=0.5370 val_r2=-274617.3137val_corr=0.0892\n",
      "[2/100] train_loss=0.5270 | val_loss=0.1740 val_rmse=0.4092 val_r2=-61878.8022val_corr=0.1189\n",
      "[3/100] train_loss=0.4158 | val_loss=0.0819 val_rmse=0.2763 val_r2=-5288.1640val_corr=0.1079\n",
      "[4/100] train_loss=0.3934 | val_loss=0.0875 val_rmse=0.2876 val_r2=-21128.4745val_corr=0.1151\n",
      "[5/100] train_loss=0.3216 | val_loss=0.0872 val_rmse=0.2902 val_r2=-42302.0346val_corr=0.0963\n",
      "[6/100] train_loss=0.2763 | val_loss=0.0645 val_rmse=0.2458 val_r2=-14324.6762val_corr=0.1083\n",
      "[7/100] train_loss=0.2571 | val_loss=0.0487 val_rmse=0.2167 val_r2=-7099.8505val_corr=0.1251\n",
      "[8/100] train_loss=0.2318 | val_loss=0.0555 val_rmse=0.2290 val_r2=-6367.9424val_corr=0.1440\n",
      "[9/100] train_loss=0.2369 | val_loss=0.0657 val_rmse=0.2472 val_r2=-15063.9704val_corr=0.1402\n",
      "[10/100] train_loss=0.2156 | val_loss=0.0528 val_rmse=0.2243 val_r2=-8091.1451val_corr=0.1376\n",
      "[11/100] train_loss=0.2039 | val_loss=0.0533 val_rmse=0.2239 val_r2=-5489.3559val_corr=0.1240\n",
      "[12/100] train_loss=0.1934 | val_loss=0.0665 val_rmse=0.2505 val_r2=-21533.7103val_corr=0.1269\n",
      "[13/100] train_loss=0.1841 | val_loss=0.0677 val_rmse=0.2528 val_r2=-19602.8210val_corr=0.1195\n",
      "[14/100] train_loss=0.1716 | val_loss=0.0563 val_rmse=0.2296 val_r2=-8133.6459val_corr=0.1212\n",
      "[15/100] train_loss=0.1649 | val_loss=0.0556 val_rmse=0.2273 val_r2=-6918.0106val_corr=0.1276\n",
      "[16/100] train_loss=0.1592 | val_loss=0.0672 val_rmse=0.2495 val_r2=-13512.2831val_corr=0.1395\n",
      "[17/100] train_loss=0.1501 | val_loss=0.0620 val_rmse=0.2412 val_r2=-8039.7129val_corr=0.1348\n",
      "Early stopping at epoch 17 (best epoch=7, val_loss=0.0487)\n",
      "1 番目の 4 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.9099 | val_loss=0.2576 val_rmse=0.5054 val_r2=-213152.8503val_corr=0.1140\n",
      "[2/100] train_loss=0.6148 | val_loss=0.2645 val_rmse=0.4988 val_r2=-108617.9315val_corr=0.1005\n",
      "[3/100] train_loss=0.5771 | val_loss=0.1077 val_rmse=0.3220 val_r2=-20540.1703val_corr=0.1309\n",
      "[4/100] train_loss=0.4400 | val_loss=0.0849 val_rmse=0.2817 val_r2=-15078.6756val_corr=0.1392\n",
      "[5/100] train_loss=0.3967 | val_loss=0.1376 val_rmse=0.3673 val_r2=-86372.7617val_corr=0.1246\n",
      "[6/100] train_loss=0.3385 | val_loss=0.1347 val_rmse=0.3632 val_r2=-82191.2015val_corr=0.1212\n",
      "[7/100] train_loss=0.3123 | val_loss=0.0721 val_rmse=0.2616 val_r2=-20315.9715val_corr=0.1339\n",
      "[8/100] train_loss=0.2761 | val_loss=0.0608 val_rmse=0.2380 val_r2=-4466.9505val_corr=0.1297\n",
      "[9/100] train_loss=0.2707 | val_loss=0.0534 val_rmse=0.2228 val_r2=-7291.4498val_corr=0.1193\n",
      "[10/100] train_loss=0.2404 | val_loss=0.0617 val_rmse=0.2393 val_r2=-12194.5313val_corr=0.1115\n",
      "[11/100] train_loss=0.2302 | val_loss=0.0573 val_rmse=0.2322 val_r2=-7314.6023val_corr=0.1227\n",
      "[12/100] train_loss=0.2147 | val_loss=0.0551 val_rmse=0.2300 val_r2=-8268.1725val_corr=0.1321\n",
      "[13/100] train_loss=0.2113 | val_loss=0.0592 val_rmse=0.2349 val_r2=-8357.9333val_corr=0.1281\n",
      "[14/100] train_loss=0.1990 | val_loss=0.0698 val_rmse=0.2552 val_r2=-15765.0019val_corr=0.1148\n",
      "[15/100] train_loss=0.1926 | val_loss=0.0662 val_rmse=0.2478 val_r2=-11280.4642val_corr=0.1081\n",
      "[16/100] train_loss=0.1833 | val_loss=0.0617 val_rmse=0.2397 val_r2=-5931.6168val_corr=0.1077\n",
      "[17/100] train_loss=0.1765 | val_loss=0.0623 val_rmse=0.2406 val_r2=-5979.9721val_corr=0.1062\n",
      "[18/100] train_loss=0.1645 | val_loss=0.0625 val_rmse=0.2402 val_r2=-8951.5310val_corr=0.1012\n",
      "[19/100] train_loss=0.1571 | val_loss=0.0663 val_rmse=0.2474 val_r2=-8107.1628val_corr=0.0909\n",
      "Early stopping at epoch 19 (best epoch=9, val_loss=0.0534)\n",
      "1 番目の 5 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6162 | val_loss=1.0861 val_rmse=1.0421 val_r2=-12.5414val_corr=0.4727\n",
      "[2/100] train_loss=0.5226 | val_loss=0.7370 val_rmse=0.8585 val_r2=-7.9004val_corr=0.4977\n",
      "[3/100] train_loss=0.4012 | val_loss=0.3724 val_rmse=0.6103 val_r2=-16.3139val_corr=0.4613\n",
      "[4/100] train_loss=0.3750 | val_loss=0.3585 val_rmse=0.5987 val_r2=-6.7133val_corr=0.4943\n",
      "[5/100] train_loss=0.3188 | val_loss=0.4166 val_rmse=0.6455 val_r2=-6.9721val_corr=0.5055\n",
      "[6/100] train_loss=0.2923 | val_loss=0.2821 val_rmse=0.5312 val_r2=-6.2068val_corr=0.5426\n",
      "[7/100] train_loss=0.2400 | val_loss=0.1858 val_rmse=0.4311 val_r2=-3.8634val_corr=0.5586\n",
      "[8/100] train_loss=0.2019 | val_loss=0.2233 val_rmse=0.4726 val_r2=-8.9911val_corr=0.4656\n",
      "[9/100] train_loss=0.1754 | val_loss=0.2251 val_rmse=0.4745 val_r2=-10.1684val_corr=0.4750\n",
      "[10/100] train_loss=0.1659 | val_loss=0.2139 val_rmse=0.4624 val_r2=-5.7945val_corr=0.5518\n",
      "[11/100] train_loss=0.1495 | val_loss=0.2726 val_rmse=0.5221 val_r2=-12.9662val_corr=0.6588\n",
      "[12/100] train_loss=0.1406 | val_loss=0.2545 val_rmse=0.5045 val_r2=-5.1427val_corr=0.5980\n",
      "[13/100] train_loss=0.1421 | val_loss=0.2293 val_rmse=0.4788 val_r2=-5.0158val_corr=0.5926\n",
      "[14/100] train_loss=0.1393 | val_loss=0.2282 val_rmse=0.4777 val_r2=-3.0267val_corr=0.5708\n",
      "[15/100] train_loss=0.1294 | val_loss=0.3026 val_rmse=0.5500 val_r2=-3.9421val_corr=0.5697\n",
      "[16/100] train_loss=0.1274 | val_loss=0.2622 val_rmse=0.5121 val_r2=-4.2918val_corr=0.5014\n",
      "[17/100] train_loss=0.1157 | val_loss=0.2717 val_rmse=0.5212 val_r2=-4.4767val_corr=0.4531\n",
      "Early stopping at epoch 17 (best epoch=7, val_loss=0.1858)\n",
      "2 番目の 1 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6249 | val_loss=1.0106 val_rmse=1.0053 val_r2=-13.0018val_corr=0.6665\n",
      "[2/100] train_loss=0.4966 | val_loss=0.6237 val_rmse=0.7897 val_r2=-10.6452val_corr=0.6959\n",
      "[3/100] train_loss=0.3709 | val_loss=0.3355 val_rmse=0.5792 val_r2=-18.7217val_corr=0.6522\n",
      "[4/100] train_loss=0.3350 | val_loss=0.3959 val_rmse=0.6292 val_r2=-4.8322val_corr=0.5595\n",
      "[5/100] train_loss=0.2958 | val_loss=0.2874 val_rmse=0.5361 val_r2=-5.0782val_corr=0.5739\n",
      "[6/100] train_loss=0.2494 | val_loss=0.2006 val_rmse=0.4479 val_r2=-6.1826val_corr=0.6104\n",
      "[7/100] train_loss=0.2288 | val_loss=0.2336 val_rmse=0.4833 val_r2=-5.0274val_corr=0.6031\n",
      "[8/100] train_loss=0.1953 | val_loss=0.2542 val_rmse=0.5042 val_r2=-4.6934val_corr=0.6054\n",
      "[9/100] train_loss=0.1739 | val_loss=0.3610 val_rmse=0.6009 val_r2=-7.9616val_corr=0.6699\n",
      "[10/100] train_loss=0.1604 | val_loss=0.3491 val_rmse=0.5908 val_r2=-6.0235val_corr=0.4431\n",
      "[11/100] train_loss=0.1497 | val_loss=0.5046 val_rmse=0.7103 val_r2=-9.6465val_corr=0.4633\n",
      "[12/100] train_loss=0.1480 | val_loss=0.4766 val_rmse=0.6903 val_r2=-7.8029val_corr=0.5199\n",
      "[13/100] train_loss=0.1420 | val_loss=0.4885 val_rmse=0.6989 val_r2=-7.3041val_corr=0.6332\n",
      "[14/100] train_loss=0.1351 | val_loss=0.4839 val_rmse=0.6956 val_r2=-5.3476val_corr=0.6134\n",
      "[15/100] train_loss=0.1311 | val_loss=0.4406 val_rmse=0.6638 val_r2=-5.5075val_corr=0.5317\n",
      "[16/100] train_loss=0.1284 | val_loss=0.5426 val_rmse=0.7366 val_r2=-7.3977val_corr=0.4505\n",
      "Early stopping at epoch 16 (best epoch=6, val_loss=0.2006)\n",
      "2 番目の 2 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.5249 | val_loss=0.5932 val_rmse=0.7702 val_r2=-7.7254val_corr=0.5474\n",
      "[2/100] train_loss=0.3648 | val_loss=0.2992 val_rmse=0.5470 val_r2=-9.7163val_corr=0.5512\n",
      "[3/100] train_loss=0.3029 | val_loss=0.3825 val_rmse=0.6185 val_r2=-5.3613val_corr=0.5872\n",
      "[4/100] train_loss=0.2782 | val_loss=0.2353 val_rmse=0.4851 val_r2=-8.5117val_corr=0.6188\n",
      "[5/100] train_loss=0.2288 | val_loss=0.1841 val_rmse=0.4291 val_r2=-3.2642val_corr=0.5541\n",
      "[6/100] train_loss=0.1980 | val_loss=0.2176 val_rmse=0.4665 val_r2=-2.9499val_corr=0.5065\n",
      "[7/100] train_loss=0.1778 | val_loss=0.2328 val_rmse=0.4825 val_r2=-15.7950val_corr=0.5033\n",
      "[8/100] train_loss=0.1615 | val_loss=0.2999 val_rmse=0.5476 val_r2=-6.1781val_corr=0.3718\n",
      "[9/100] train_loss=0.1561 | val_loss=0.3261 val_rmse=0.5711 val_r2=-6.5804val_corr=0.4158\n",
      "[10/100] train_loss=0.1510 | val_loss=0.3568 val_rmse=0.5973 val_r2=-9.9125val_corr=0.5133\n",
      "[11/100] train_loss=0.1515 | val_loss=0.3299 val_rmse=0.5743 val_r2=-4.2156val_corr=0.6702\n",
      "[12/100] train_loss=0.1417 | val_loss=0.3514 val_rmse=0.5928 val_r2=-7.6930val_corr=0.7642\n",
      "[13/100] train_loss=0.1403 | val_loss=0.3009 val_rmse=0.5486 val_r2=-7.4378val_corr=0.7314\n",
      "[14/100] train_loss=0.1382 | val_loss=0.3618 val_rmse=0.6015 val_r2=-7.7756val_corr=0.6502\n",
      "[15/100] train_loss=0.1267 | val_loss=0.3601 val_rmse=0.6001 val_r2=-10.5081val_corr=0.5100\n",
      "Early stopping at epoch 15 (best epoch=5, val_loss=0.1841)\n",
      "2 番目の 3 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.5961 | val_loss=0.6880 val_rmse=0.8295 val_r2=-23.6960val_corr=0.6662\n",
      "[2/100] train_loss=0.3648 | val_loss=0.3594 val_rmse=0.5995 val_r2=-15.9024val_corr=0.6659\n",
      "[3/100] train_loss=0.3237 | val_loss=0.3647 val_rmse=0.6039 val_r2=-6.1081val_corr=0.6730\n",
      "[4/100] train_loss=0.2771 | val_loss=0.1853 val_rmse=0.4304 val_r2=-27.0617val_corr=0.7691\n",
      "[5/100] train_loss=0.2493 | val_loss=0.1715 val_rmse=0.4141 val_r2=-9.4765val_corr=0.6681\n",
      "[6/100] train_loss=0.2071 | val_loss=0.2412 val_rmse=0.4912 val_r2=-5.0033val_corr=0.4333\n",
      "[7/100] train_loss=0.1900 | val_loss=0.1653 val_rmse=0.4065 val_r2=-2.8194val_corr=0.4985\n",
      "[8/100] train_loss=0.1628 | val_loss=0.1578 val_rmse=0.3972 val_r2=-13.1605val_corr=0.5947\n",
      "[9/100] train_loss=0.1632 | val_loss=0.1329 val_rmse=0.3645 val_r2=-4.6675val_corr=0.6868\n",
      "[10/100] train_loss=0.1446 | val_loss=0.1675 val_rmse=0.4093 val_r2=-1.5928val_corr=0.7148\n",
      "[11/100] train_loss=0.1421 | val_loss=0.1237 val_rmse=0.3518 val_r2=-3.1010val_corr=0.8100\n",
      "[12/100] train_loss=0.1446 | val_loss=0.0945 val_rmse=0.3075 val_r2=-8.5255val_corr=0.7785\n",
      "[13/100] train_loss=0.1346 | val_loss=0.1487 val_rmse=0.3857 val_r2=-1.7138val_corr=0.6890\n",
      "[14/100] train_loss=0.1329 | val_loss=0.2296 val_rmse=0.4792 val_r2=-2.7249val_corr=0.6481\n",
      "[15/100] train_loss=0.1282 | val_loss=0.1264 val_rmse=0.3555 val_r2=-8.5419val_corr=0.6698\n",
      "[16/100] train_loss=0.1271 | val_loss=0.2105 val_rmse=0.4588 val_r2=-2.9740val_corr=0.6869\n",
      "[17/100] train_loss=0.1223 | val_loss=0.1341 val_rmse=0.3662 val_r2=-1.9025val_corr=0.7226\n",
      "[18/100] train_loss=0.1123 | val_loss=0.1609 val_rmse=0.4011 val_r2=-2.2288val_corr=0.7315\n",
      "[19/100] train_loss=0.1089 | val_loss=0.1098 val_rmse=0.3313 val_r2=-3.0316val_corr=0.7630\n",
      "[20/100] train_loss=0.1071 | val_loss=0.1537 val_rmse=0.3921 val_r2=-1.6842val_corr=0.7626\n",
      "[21/100] train_loss=0.1063 | val_loss=0.1386 val_rmse=0.3723 val_r2=-1.7711val_corr=0.7782\n",
      "[22/100] train_loss=0.1015 | val_loss=0.1317 val_rmse=0.3630 val_r2=-2.8313val_corr=0.7503\n",
      "Early stopping at epoch 22 (best epoch=12, val_loss=0.0945)\n",
      "2 番目の 4 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6152 | val_loss=0.8425 val_rmse=0.9179 val_r2=-17.5736val_corr=0.5438\n",
      "[2/100] train_loss=0.4253 | val_loss=0.3040 val_rmse=0.5514 val_r2=-11.9775val_corr=0.6111\n",
      "[3/100] train_loss=0.3652 | val_loss=0.3204 val_rmse=0.5660 val_r2=-5.7799val_corr=0.5886\n",
      "[4/100] train_loss=0.3003 | val_loss=0.3930 val_rmse=0.6269 val_r2=-7.8259val_corr=0.5585\n",
      "[5/100] train_loss=0.2894 | val_loss=0.2367 val_rmse=0.4865 val_r2=-6.1644val_corr=0.5973\n",
      "[6/100] train_loss=0.2425 | val_loss=0.2092 val_rmse=0.4574 val_r2=-4.0368val_corr=0.5827\n",
      "[7/100] train_loss=0.2191 | val_loss=0.2553 val_rmse=0.5052 val_r2=-4.6105val_corr=0.4354\n",
      "[8/100] train_loss=0.1973 | val_loss=0.2436 val_rmse=0.4935 val_r2=-27.4568val_corr=0.3139\n",
      "[9/100] train_loss=0.1664 | val_loss=0.3685 val_rmse=0.6071 val_r2=-2.3441val_corr=0.5674\n",
      "[10/100] train_loss=0.1557 | val_loss=0.3421 val_rmse=0.5849 val_r2=-3.3002val_corr=0.5937\n",
      "[11/100] train_loss=0.1516 | val_loss=0.3131 val_rmse=0.5596 val_r2=-9.4470val_corr=0.4863\n",
      "[12/100] train_loss=0.1420 | val_loss=0.3277 val_rmse=0.5725 val_r2=-1.6794val_corr=0.5422\n",
      "[13/100] train_loss=0.1411 | val_loss=0.2945 val_rmse=0.5426 val_r2=-4.7260val_corr=0.6542\n",
      "[14/100] train_loss=0.1354 | val_loss=0.2863 val_rmse=0.5351 val_r2=-7.0403val_corr=0.7205\n",
      "[15/100] train_loss=0.1319 | val_loss=0.3145 val_rmse=0.5608 val_r2=-2.3584val_corr=0.6911\n",
      "[16/100] train_loss=0.1287 | val_loss=0.3345 val_rmse=0.5784 val_r2=-3.8534val_corr=0.6391\n",
      "Early stopping at epoch 16 (best epoch=6, val_loss=0.2092)\n",
      "2 番目の 5 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7236 | val_loss=0.1429 val_rmse=0.3781 val_r2=-12.5329val_corr=0.4623\n",
      "[2/100] train_loss=0.5212 | val_loss=0.2841 val_rmse=0.5330 val_r2=-12.1259val_corr=0.4001\n",
      "[3/100] train_loss=0.4013 | val_loss=0.1861 val_rmse=0.4313 val_r2=-8.7677val_corr=0.3302\n",
      "[4/100] train_loss=0.3083 | val_loss=0.0731 val_rmse=0.2704 val_r2=-22.6547val_corr=0.4492\n",
      "[5/100] train_loss=0.2550 | val_loss=0.1168 val_rmse=0.3417 val_r2=-13.1010val_corr=0.3794\n",
      "[6/100] train_loss=0.2068 | val_loss=0.0630 val_rmse=0.2510 val_r2=-8.8817val_corr=0.3410\n",
      "[7/100] train_loss=0.1844 | val_loss=0.0401 val_rmse=0.2004 val_r2=-2.0434val_corr=0.6154\n",
      "[8/100] train_loss=0.1805 | val_loss=0.1172 val_rmse=0.3424 val_r2=-13.9472val_corr=0.6212\n",
      "[9/100] train_loss=0.1750 | val_loss=0.0371 val_rmse=0.1926 val_r2=-2.4337val_corr=0.4531\n",
      "[10/100] train_loss=0.1599 | val_loss=0.0425 val_rmse=0.2063 val_r2=-7.3749val_corr=0.4381\n",
      "[11/100] train_loss=0.1467 | val_loss=0.0397 val_rmse=0.1993 val_r2=-1.8391val_corr=0.4867\n",
      "[12/100] train_loss=0.1428 | val_loss=0.0402 val_rmse=0.2006 val_r2=-10.8448val_corr=0.6582\n",
      "[13/100] train_loss=0.1356 | val_loss=0.0716 val_rmse=0.2677 val_r2=-2.4631val_corr=0.5196\n",
      "[14/100] train_loss=0.1446 | val_loss=0.0451 val_rmse=0.2123 val_r2=-5.1580val_corr=0.3007\n",
      "[15/100] train_loss=0.1482 | val_loss=0.0564 val_rmse=0.2375 val_r2=-7.6562val_corr=0.3776\n",
      "[16/100] train_loss=0.1263 | val_loss=0.0515 val_rmse=0.2270 val_r2=-0.8102val_corr=0.5585\n",
      "[17/100] train_loss=0.1282 | val_loss=0.0496 val_rmse=0.2228 val_r2=-15.1714val_corr=0.6576\n",
      "[18/100] train_loss=0.1214 | val_loss=0.0687 val_rmse=0.2621 val_r2=-2.5238val_corr=0.4473\n",
      "[19/100] train_loss=0.1245 | val_loss=0.0643 val_rmse=0.2536 val_r2=-7.6583val_corr=0.3978\n",
      "Early stopping at epoch 19 (best epoch=9, val_loss=0.0371)\n",
      "3 番目の 1 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7320 | val_loss=0.1318 val_rmse=0.3631 val_r2=-16.1892val_corr=0.6163\n",
      "[2/100] train_loss=0.5042 | val_loss=0.5497 val_rmse=0.7414 val_r2=-16.9722val_corr=0.5464\n",
      "[3/100] train_loss=0.4639 | val_loss=0.2058 val_rmse=0.4536 val_r2=-5.4060val_corr=0.2395\n",
      "[4/100] train_loss=0.3290 | val_loss=0.0791 val_rmse=0.2813 val_r2=-32.2932val_corr=0.2416\n",
      "[5/100] train_loss=0.2953 | val_loss=0.1569 val_rmse=0.3960 val_r2=-13.3849val_corr=0.4638\n",
      "[6/100] train_loss=0.2469 | val_loss=0.0658 val_rmse=0.2566 val_r2=-5.7592val_corr=0.5311\n",
      "[7/100] train_loss=0.2198 | val_loss=0.0546 val_rmse=0.2336 val_r2=-27.5960val_corr=0.4741\n",
      "[8/100] train_loss=0.2143 | val_loss=0.0640 val_rmse=0.2530 val_r2=-4.4745val_corr=0.4639\n",
      "[9/100] train_loss=0.1838 | val_loss=0.0759 val_rmse=0.2754 val_r2=-2.2479val_corr=0.5240\n",
      "[10/100] train_loss=0.1809 | val_loss=0.0470 val_rmse=0.2169 val_r2=-24.1793val_corr=0.6248\n",
      "[11/100] train_loss=0.1777 | val_loss=0.0357 val_rmse=0.1889 val_r2=-8.6139val_corr=0.5631\n",
      "[12/100] train_loss=0.1657 | val_loss=0.0901 val_rmse=0.3001 val_r2=-2.6658val_corr=0.4855\n",
      "[13/100] train_loss=0.1699 | val_loss=0.0792 val_rmse=0.2813 val_r2=-4.8954val_corr=0.3853\n",
      "[14/100] train_loss=0.1522 | val_loss=0.0536 val_rmse=0.2314 val_r2=-3.5092val_corr=0.3734\n",
      "[15/100] train_loss=0.1522 | val_loss=0.0740 val_rmse=0.2720 val_r2=-9.5358val_corr=0.5433\n",
      "[16/100] train_loss=0.1511 | val_loss=0.0491 val_rmse=0.2217 val_r2=-3.1022val_corr=0.5398\n",
      "[17/100] train_loss=0.1456 | val_loss=0.0650 val_rmse=0.2549 val_r2=-3.5030val_corr=0.5463\n",
      "[18/100] train_loss=0.1467 | val_loss=0.0601 val_rmse=0.2452 val_r2=-2.2816val_corr=0.5130\n",
      "[19/100] train_loss=0.1409 | val_loss=0.0933 val_rmse=0.3055 val_r2=-10.8505val_corr=0.4600\n",
      "[20/100] train_loss=0.1362 | val_loss=0.0992 val_rmse=0.3149 val_r2=-10.5223val_corr=0.5571\n",
      "[21/100] train_loss=0.1314 | val_loss=0.0658 val_rmse=0.2564 val_r2=-3.3335val_corr=0.6006\n",
      "Early stopping at epoch 21 (best epoch=11, val_loss=0.0357)\n",
      "3 番目の 2 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6062 | val_loss=0.2838 val_rmse=0.5327 val_r2=-13.0023val_corr=0.5917\n",
      "[2/100] train_loss=0.3894 | val_loss=0.1912 val_rmse=0.4373 val_r2=-5.0046val_corr=0.5793\n",
      "[3/100] train_loss=0.2797 | val_loss=0.0735 val_rmse=0.2710 val_r2=-29.8593val_corr=0.3623\n",
      "[4/100] train_loss=0.2448 | val_loss=0.1203 val_rmse=0.3469 val_r2=-15.5803val_corr=0.3020\n",
      "[5/100] train_loss=0.2202 | val_loss=0.0434 val_rmse=0.2084 val_r2=-1.3908val_corr=0.4678\n",
      "[6/100] train_loss=0.1970 | val_loss=0.0757 val_rmse=0.2752 val_r2=-25.1705val_corr=0.7253\n",
      "[7/100] train_loss=0.1819 | val_loss=0.0556 val_rmse=0.2359 val_r2=-4.7628val_corr=0.4285\n",
      "[8/100] train_loss=0.1750 | val_loss=0.0420 val_rmse=0.2050 val_r2=-9.0769val_corr=0.4064\n",
      "[9/100] train_loss=0.1689 | val_loss=0.0551 val_rmse=0.2347 val_r2=-23.5592val_corr=0.4132\n",
      "[10/100] train_loss=0.1542 | val_loss=0.0466 val_rmse=0.2159 val_r2=-1.0708val_corr=0.4609\n",
      "[11/100] train_loss=0.1561 | val_loss=0.0676 val_rmse=0.2601 val_r2=-5.1603val_corr=0.5301\n",
      "[12/100] train_loss=0.1515 | val_loss=0.0624 val_rmse=0.2498 val_r2=-5.4852val_corr=0.6581\n",
      "[13/100] train_loss=0.1473 | val_loss=0.0389 val_rmse=0.1971 val_r2=-2.4799val_corr=0.6222\n",
      "[14/100] train_loss=0.1441 | val_loss=0.0427 val_rmse=0.2066 val_r2=-16.3774val_corr=0.4932\n",
      "[15/100] train_loss=0.1394 | val_loss=0.0414 val_rmse=0.2035 val_r2=-3.0314val_corr=0.3970\n",
      "[16/100] train_loss=0.1364 | val_loss=0.0438 val_rmse=0.2092 val_r2=-0.6936val_corr=0.4377\n",
      "[17/100] train_loss=0.1262 | val_loss=0.0503 val_rmse=0.2242 val_r2=-15.0284val_corr=0.5148\n",
      "[18/100] train_loss=0.1195 | val_loss=0.0589 val_rmse=0.2426 val_r2=-6.7375val_corr=0.5538\n",
      "[19/100] train_loss=0.1192 | val_loss=0.0503 val_rmse=0.2243 val_r2=-0.9996val_corr=0.5163\n",
      "[20/100] train_loss=0.1176 | val_loss=0.0942 val_rmse=0.3069 val_r2=-47.3639val_corr=0.6434\n",
      "[21/100] train_loss=0.1275 | val_loss=0.0588 val_rmse=0.2426 val_r2=-0.6781val_corr=0.4609\n",
      "[22/100] train_loss=0.1149 | val_loss=0.0828 val_rmse=0.2877 val_r2=-37.9245val_corr=0.3997\n",
      "[23/100] train_loss=0.1083 | val_loss=0.0650 val_rmse=0.2549 val_r2=-6.5208val_corr=0.5034\n",
      "Early stopping at epoch 23 (best epoch=13, val_loss=0.0389)\n",
      "3 番目の 3 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6924 | val_loss=0.1638 val_rmse=0.4047 val_r2=-115.2104val_corr=0.6582\n",
      "[2/100] train_loss=0.3785 | val_loss=0.1207 val_rmse=0.3474 val_r2=-10.9953val_corr=0.5711\n",
      "[3/100] train_loss=0.3328 | val_loss=0.1101 val_rmse=0.3318 val_r2=-36.9528val_corr=0.5006\n",
      "[4/100] train_loss=0.2583 | val_loss=0.1380 val_rmse=0.3715 val_r2=-41.6050val_corr=0.4102\n",
      "[5/100] train_loss=0.2236 | val_loss=0.0784 val_rmse=0.2799 val_r2=-6.9813val_corr=0.4467\n",
      "[6/100] train_loss=0.2083 | val_loss=0.0654 val_rmse=0.2558 val_r2=-6.4980val_corr=0.6062\n",
      "[7/100] train_loss=0.1941 | val_loss=0.0877 val_rmse=0.2961 val_r2=-23.4219val_corr=0.7531\n",
      "[8/100] train_loss=0.1945 | val_loss=0.0851 val_rmse=0.2918 val_r2=-1.1690val_corr=0.6524\n",
      "[9/100] train_loss=0.1789 | val_loss=0.0382 val_rmse=0.1954 val_r2=-0.4150val_corr=0.6020\n",
      "[10/100] train_loss=0.1666 | val_loss=0.0616 val_rmse=0.2483 val_r2=-19.3011val_corr=0.7222\n",
      "[11/100] train_loss=0.1610 | val_loss=0.0433 val_rmse=0.2081 val_r2=-18.3418val_corr=0.5942\n",
      "[12/100] train_loss=0.1547 | val_loss=0.0458 val_rmse=0.2140 val_r2=-3.3994val_corr=0.4458\n",
      "[13/100] train_loss=0.1536 | val_loss=0.0434 val_rmse=0.2084 val_r2=-1.8248val_corr=0.5515\n",
      "[14/100] train_loss=0.1458 | val_loss=0.0577 val_rmse=0.2402 val_r2=-4.7850val_corr=0.7363\n",
      "[15/100] train_loss=0.1425 | val_loss=0.0473 val_rmse=0.2174 val_r2=-3.0818val_corr=0.6884\n",
      "[16/100] train_loss=0.1356 | val_loss=0.0811 val_rmse=0.2848 val_r2=-4.6222val_corr=0.6804\n",
      "[17/100] train_loss=0.1383 | val_loss=0.0538 val_rmse=0.2319 val_r2=-6.2078val_corr=0.5561\n",
      "[18/100] train_loss=0.1269 | val_loss=0.0688 val_rmse=0.2624 val_r2=-7.2272val_corr=0.4780\n",
      "[19/100] train_loss=0.1225 | val_loss=0.0442 val_rmse=0.2101 val_r2=-1.1551val_corr=0.4453\n",
      "Early stopping at epoch 19 (best epoch=9, val_loss=0.0382)\n",
      "3 番目の 4 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7206 | val_loss=0.1107 val_rmse=0.3328 val_r2=-88.6438val_corr=0.5529\n",
      "[2/100] train_loss=0.4088 | val_loss=0.6515 val_rmse=0.8071 val_r2=-49.2656val_corr=0.5287\n",
      "[3/100] train_loss=0.3835 | val_loss=0.0922 val_rmse=0.3036 val_r2=-10.8169val_corr=0.4823\n",
      "[4/100] train_loss=0.3048 | val_loss=0.0905 val_rmse=0.3008 val_r2=-78.5521val_corr=0.4192\n",
      "[5/100] train_loss=0.2606 | val_loss=0.1312 val_rmse=0.3623 val_r2=-2.9951val_corr=0.5331\n",
      "[6/100] train_loss=0.2461 | val_loss=0.0674 val_rmse=0.2596 val_r2=-11.1199val_corr=0.5470\n",
      "[7/100] train_loss=0.2145 | val_loss=0.0726 val_rmse=0.2695 val_r2=-42.8220val_corr=0.5392\n",
      "[8/100] train_loss=0.2100 | val_loss=0.0697 val_rmse=0.2641 val_r2=-24.4322val_corr=0.5604\n",
      "[9/100] train_loss=0.1840 | val_loss=0.0484 val_rmse=0.2201 val_r2=-4.5817val_corr=0.5763\n",
      "[10/100] train_loss=0.1972 | val_loss=0.0441 val_rmse=0.2100 val_r2=-3.7125val_corr=0.6319\n",
      "[11/100] train_loss=0.1738 | val_loss=0.0935 val_rmse=0.3057 val_r2=-21.6437val_corr=0.6527\n",
      "[12/100] train_loss=0.1728 | val_loss=0.0379 val_rmse=0.1947 val_r2=-2.3028val_corr=0.5346\n",
      "[13/100] train_loss=0.1631 | val_loss=0.0605 val_rmse=0.2459 val_r2=-2.1769val_corr=0.4964\n",
      "[14/100] train_loss=0.1584 | val_loss=0.0522 val_rmse=0.2284 val_r2=-4.4616val_corr=0.5449\n",
      "[15/100] train_loss=0.1591 | val_loss=0.0599 val_rmse=0.2447 val_r2=-4.3702val_corr=0.5958\n",
      "[16/100] train_loss=0.1519 | val_loss=0.0356 val_rmse=0.1887 val_r2=-2.4811val_corr=0.5304\n",
      "[17/100] train_loss=0.1611 | val_loss=0.0574 val_rmse=0.2397 val_r2=-8.3272val_corr=0.4383\n",
      "[18/100] train_loss=0.1421 | val_loss=0.0557 val_rmse=0.2361 val_r2=-5.7500val_corr=0.3927\n",
      "[19/100] train_loss=0.1377 | val_loss=0.0846 val_rmse=0.2909 val_r2=-5.2871val_corr=0.5394\n",
      "[20/100] train_loss=0.1298 | val_loss=0.0724 val_rmse=0.2690 val_r2=-5.9752val_corr=0.5690\n",
      "[21/100] train_loss=0.1264 | val_loss=0.0578 val_rmse=0.2405 val_r2=-4.4333val_corr=0.5658\n",
      "[22/100] train_loss=0.1192 | val_loss=0.0828 val_rmse=0.2878 val_r2=-8.7766val_corr=0.4774\n",
      "[23/100] train_loss=0.1169 | val_loss=0.0486 val_rmse=0.2205 val_r2=-4.6232val_corr=0.6150\n",
      "[24/100] train_loss=0.1168 | val_loss=0.0441 val_rmse=0.2099 val_r2=-5.5693val_corr=0.6192\n",
      "[25/100] train_loss=0.1109 | val_loss=0.0550 val_rmse=0.2345 val_r2=-2.2077val_corr=0.4175\n",
      "[26/100] train_loss=0.1158 | val_loss=0.0530 val_rmse=0.2302 val_r2=-1.4708val_corr=0.5093\n",
      "Early stopping at epoch 26 (best epoch=16, val_loss=0.0356)\n",
      "3 番目の 5 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.4559 | val_loss=1.1398 val_rmse=1.0520 val_r2=-20.4820val_corr=0.4489\n",
      "[2/100] train_loss=0.3478 | val_loss=0.7829 val_rmse=0.8722 val_r2=-19.1325val_corr=0.4648\n",
      "[3/100] train_loss=0.2542 | val_loss=0.5981 val_rmse=0.7663 val_r2=-206.1881val_corr=0.4172\n",
      "[4/100] train_loss=0.2072 | val_loss=0.6822 val_rmse=0.8141 val_r2=-14.0521val_corr=0.4216\n",
      "[5/100] train_loss=0.1595 | val_loss=0.6572 val_rmse=0.8011 val_r2=-78.2127val_corr=0.4466\n",
      "[6/100] train_loss=0.1238 | val_loss=0.4836 val_rmse=0.6855 val_r2=-11.0925val_corr=0.4864\n",
      "[7/100] train_loss=0.1141 | val_loss=0.5491 val_rmse=0.7316 val_r2=-44.0516val_corr=0.5061\n",
      "[8/100] train_loss=0.0939 | val_loss=0.5245 val_rmse=0.7143 val_r2=-19.9387val_corr=0.5572\n",
      "[9/100] train_loss=0.0910 | val_loss=0.4566 val_rmse=0.6661 val_r2=-11.8992val_corr=0.5474\n",
      "[10/100] train_loss=0.0801 | val_loss=0.4409 val_rmse=0.6561 val_r2=-54.0877val_corr=0.5074\n",
      "[11/100] train_loss=0.0775 | val_loss=0.4553 val_rmse=0.6648 val_r2=-5.7601val_corr=0.4634\n",
      "[12/100] train_loss=0.0736 | val_loss=0.4673 val_rmse=0.6740 val_r2=-13.9390val_corr=0.4420\n",
      "[13/100] train_loss=0.0732 | val_loss=0.4205 val_rmse=0.6389 val_r2=-6.3722val_corr=0.4919\n",
      "[14/100] train_loss=0.0678 | val_loss=0.4365 val_rmse=0.6512 val_r2=-9.5618val_corr=0.5268\n",
      "[15/100] train_loss=0.0692 | val_loss=0.4405 val_rmse=0.6537 val_r2=-3.9525val_corr=0.5529\n",
      "[16/100] train_loss=0.0657 | val_loss=0.4116 val_rmse=0.6320 val_r2=-4.3919val_corr=0.5563\n",
      "[17/100] train_loss=0.0629 | val_loss=0.4218 val_rmse=0.6401 val_r2=-9.4845val_corr=0.5481\n",
      "[18/100] train_loss=0.0620 | val_loss=0.4085 val_rmse=0.6297 val_r2=-4.7900val_corr=0.5682\n",
      "[19/100] train_loss=0.0617 | val_loss=0.4325 val_rmse=0.6477 val_r2=-3.1857val_corr=0.5863\n",
      "[20/100] train_loss=0.0612 | val_loss=0.4202 val_rmse=0.6389 val_r2=-8.6112val_corr=0.5958\n",
      "[21/100] train_loss=0.0582 | val_loss=0.4139 val_rmse=0.6336 val_r2=-3.3789val_corr=0.6057\n",
      "[22/100] train_loss=0.0572 | val_loss=0.4507 val_rmse=0.6609 val_r2=-2.2397val_corr=0.6039\n",
      "[23/100] train_loss=0.0583 | val_loss=0.4109 val_rmse=0.6311 val_r2=-2.0072val_corr=0.6005\n",
      "[24/100] train_loss=0.0580 | val_loss=0.4257 val_rmse=0.6425 val_r2=-2.6871val_corr=0.5881\n",
      "[25/100] train_loss=0.0575 | val_loss=0.4370 val_rmse=0.6507 val_r2=-1.7826val_corr=0.5923\n",
      "[26/100] train_loss=0.0563 | val_loss=0.3978 val_rmse=0.6208 val_r2=-1.8773val_corr=0.5930\n",
      "[27/100] train_loss=0.0560 | val_loss=0.4574 val_rmse=0.6657 val_r2=-2.0398val_corr=0.5697\n",
      "[28/100] train_loss=0.0545 | val_loss=0.4333 val_rmse=0.6481 val_r2=-2.8607val_corr=0.5782\n",
      "[29/100] train_loss=0.0548 | val_loss=0.4478 val_rmse=0.6590 val_r2=-3.7097val_corr=0.5424\n",
      "[30/100] train_loss=0.0555 | val_loss=0.4655 val_rmse=0.6717 val_r2=-2.6453val_corr=0.5871\n",
      "[31/100] train_loss=0.0556 | val_loss=0.4264 val_rmse=0.6428 val_r2=-2.1996val_corr=0.5969\n",
      "[32/100] train_loss=0.0535 | val_loss=0.4892 val_rmse=0.6886 val_r2=-2.8057val_corr=0.5952\n",
      "[33/100] train_loss=0.0547 | val_loss=0.4053 val_rmse=0.6271 val_r2=-5.2978val_corr=0.6202\n",
      "[34/100] train_loss=0.0563 | val_loss=0.4876 val_rmse=0.6875 val_r2=-3.9004val_corr=0.5938\n",
      "[35/100] train_loss=0.0549 | val_loss=0.4584 val_rmse=0.6672 val_r2=-9.7813val_corr=0.6088\n",
      "[36/100] train_loss=0.0537 | val_loss=0.4470 val_rmse=0.6582 val_r2=-2.9586val_corr=0.5855\n",
      "Early stopping at epoch 36 (best epoch=26, val_loss=0.3978)\n",
      "4 番目の 1 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.4648 | val_loss=1.1541 val_rmse=1.0596 val_r2=-57.7263val_corr=0.5493\n",
      "[2/100] train_loss=0.3699 | val_loss=0.9004 val_rmse=0.9369 val_r2=-59.3467val_corr=0.5651\n",
      "[3/100] train_loss=0.2588 | val_loss=0.5696 val_rmse=0.7437 val_r2=-7.9698val_corr=0.5170\n",
      "[4/100] train_loss=0.2013 | val_loss=0.6459 val_rmse=0.7926 val_r2=-19.9944val_corr=0.3572\n",
      "[5/100] train_loss=0.1410 | val_loss=0.7338 val_rmse=0.8433 val_r2=-3.8998val_corr=0.4057\n",
      "[6/100] train_loss=0.1268 | val_loss=0.5634 val_rmse=0.7401 val_r2=-17.1409val_corr=0.4865\n",
      "[7/100] train_loss=0.1128 | val_loss=0.5977 val_rmse=0.7615 val_r2=-5.5127val_corr=0.5494\n",
      "[8/100] train_loss=0.0904 | val_loss=0.5029 val_rmse=0.7001 val_r2=-35.2925val_corr=0.5746\n",
      "[9/100] train_loss=0.0833 | val_loss=0.4208 val_rmse=0.6408 val_r2=-40.6503val_corr=0.5835\n",
      "[10/100] train_loss=0.0783 | val_loss=0.4541 val_rmse=0.6642 val_r2=-8.9766val_corr=0.5671\n",
      "[11/100] train_loss=0.0710 | val_loss=0.3941 val_rmse=0.6183 val_r2=-3.8031val_corr=0.5247\n",
      "[12/100] train_loss=0.0718 | val_loss=0.4502 val_rmse=0.6610 val_r2=-5.9653val_corr=0.4540\n",
      "[13/100] train_loss=0.0685 | val_loss=0.4333 val_rmse=0.6486 val_r2=-6.3081val_corr=0.4349\n",
      "[14/100] train_loss=0.0672 | val_loss=0.4270 val_rmse=0.6437 val_r2=-4.0771val_corr=0.4174\n",
      "[15/100] train_loss=0.0628 | val_loss=0.4392 val_rmse=0.6525 val_r2=-3.0435val_corr=0.4094\n",
      "[16/100] train_loss=0.0617 | val_loss=0.4202 val_rmse=0.6382 val_r2=-3.2002val_corr=0.4529\n",
      "[17/100] train_loss=0.0628 | val_loss=0.4611 val_rmse=0.6686 val_r2=-2.4284val_corr=0.5108\n",
      "[18/100] train_loss=0.0617 | val_loss=0.4337 val_rmse=0.6486 val_r2=-3.6812val_corr=0.5409\n",
      "[19/100] train_loss=0.0606 | val_loss=0.4570 val_rmse=0.6660 val_r2=-5.2132val_corr=0.5222\n",
      "[20/100] train_loss=0.0600 | val_loss=0.4510 val_rmse=0.6613 val_r2=-3.8352val_corr=0.4964\n",
      "[21/100] train_loss=0.0588 | val_loss=0.4364 val_rmse=0.6504 val_r2=-3.0805val_corr=0.4903\n",
      "Early stopping at epoch 21 (best epoch=11, val_loss=0.3941)\n",
      "4 番目の 2 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.3997 | val_loss=0.7674 val_rmse=0.8658 val_r2=-90.2047val_corr=0.5222\n",
      "[2/100] train_loss=0.2360 | val_loss=0.5125 val_rmse=0.7072 val_r2=-51.5120val_corr=0.5362\n",
      "[3/100] train_loss=0.1697 | val_loss=0.6499 val_rmse=0.7939 val_r2=-4.6512val_corr=0.4965\n",
      "[4/100] train_loss=0.1189 | val_loss=0.5591 val_rmse=0.7369 val_r2=-10.6546val_corr=0.4126\n",
      "[5/100] train_loss=0.1065 | val_loss=0.5633 val_rmse=0.7395 val_r2=-9.7225val_corr=0.4282\n",
      "[6/100] train_loss=0.0906 | val_loss=0.5316 val_rmse=0.7184 val_r2=-8.4824val_corr=0.5381\n",
      "[7/100] train_loss=0.0834 | val_loss=0.4575 val_rmse=0.6672 val_r2=-19.3954val_corr=0.5897\n",
      "[8/100] train_loss=0.0767 | val_loss=0.4357 val_rmse=0.6504 val_r2=-5.9282val_corr=0.5914\n",
      "[9/100] train_loss=0.0762 | val_loss=0.4301 val_rmse=0.6466 val_r2=-12.9776val_corr=0.6022\n",
      "[10/100] train_loss=0.0721 | val_loss=0.4303 val_rmse=0.6463 val_r2=-5.4576val_corr=0.5975\n",
      "[11/100] train_loss=0.0705 | val_loss=0.4840 val_rmse=0.6853 val_r2=-4.5085val_corr=0.5943\n",
      "[12/100] train_loss=0.0697 | val_loss=0.4667 val_rmse=0.6726 val_r2=-2.1830val_corr=0.6038\n",
      "[13/100] train_loss=0.0679 | val_loss=0.4469 val_rmse=0.6583 val_r2=-2.9348val_corr=0.6272\n",
      "[14/100] train_loss=0.0674 | val_loss=0.4470 val_rmse=0.6581 val_r2=-1.0784val_corr=0.6529\n",
      "[15/100] train_loss=0.0649 | val_loss=0.4323 val_rmse=0.6478 val_r2=-6.1975val_corr=0.6722\n",
      "[16/100] train_loss=0.0644 | val_loss=0.4405 val_rmse=0.6534 val_r2=-1.4544val_corr=0.6362\n",
      "[17/100] train_loss=0.0653 | val_loss=0.4179 val_rmse=0.6371 val_r2=-7.3945val_corr=0.6210\n",
      "[18/100] train_loss=0.0634 | val_loss=0.4756 val_rmse=0.6791 val_r2=-2.8327val_corr=0.5840\n",
      "[19/100] train_loss=0.0618 | val_loss=0.4378 val_rmse=0.6519 val_r2=-5.8195val_corr=0.6069\n",
      "[20/100] train_loss=0.0598 | val_loss=0.4389 val_rmse=0.6523 val_r2=-2.3054val_corr=0.5991\n",
      "[21/100] train_loss=0.0599 | val_loss=0.4605 val_rmse=0.6681 val_r2=-2.2033val_corr=0.5798\n",
      "[22/100] train_loss=0.0602 | val_loss=0.4419 val_rmse=0.6544 val_r2=-2.2967val_corr=0.5722\n",
      "[23/100] train_loss=0.0582 | val_loss=0.4774 val_rmse=0.6801 val_r2=-2.3127val_corr=0.5697\n",
      "[24/100] train_loss=0.0569 | val_loss=0.4493 val_rmse=0.6598 val_r2=-2.4952val_corr=0.5932\n",
      "[25/100] train_loss=0.0578 | val_loss=0.5023 val_rmse=0.6976 val_r2=-3.0815val_corr=0.5612\n",
      "[26/100] train_loss=0.0572 | val_loss=0.4467 val_rmse=0.6578 val_r2=-2.9540val_corr=0.5801\n",
      "[27/100] train_loss=0.0573 | val_loss=0.4643 val_rmse=0.6707 val_r2=-3.4179val_corr=0.5463\n",
      "Early stopping at epoch 27 (best epoch=17, val_loss=0.4179)\n",
      "4 番目の 3 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.4607 | val_loss=0.8768 val_rmse=0.9272 val_r2=-272.4189val_corr=0.5643\n",
      "[2/100] train_loss=0.2470 | val_loss=0.5298 val_rmse=0.7198 val_r2=-85.9263val_corr=0.5413\n",
      "[3/100] train_loss=0.1908 | val_loss=0.6862 val_rmse=0.8164 val_r2=-15.5304val_corr=0.5430\n",
      "[4/100] train_loss=0.1306 | val_loss=0.6519 val_rmse=0.7974 val_r2=-55.8339val_corr=0.5546\n",
      "[5/100] train_loss=0.1221 | val_loss=0.6022 val_rmse=0.7652 val_r2=-19.3758val_corr=0.4367\n",
      "[6/100] train_loss=0.0960 | val_loss=0.4856 val_rmse=0.6861 val_r2=-3.3017val_corr=0.4350\n",
      "[7/100] train_loss=0.0908 | val_loss=0.4721 val_rmse=0.6766 val_r2=-2.9935val_corr=0.4989\n",
      "[8/100] train_loss=0.0823 | val_loss=0.4808 val_rmse=0.6827 val_r2=-2.2920val_corr=0.5748\n",
      "[9/100] train_loss=0.0779 | val_loss=0.4775 val_rmse=0.6806 val_r2=-3.1495val_corr=0.5673\n",
      "[10/100] train_loss=0.0727 | val_loss=0.5131 val_rmse=0.7060 val_r2=-10.6367val_corr=0.4939\n",
      "[11/100] train_loss=0.0734 | val_loss=0.4618 val_rmse=0.6694 val_r2=-5.2614val_corr=0.5212\n",
      "[12/100] train_loss=0.0694 | val_loss=0.4491 val_rmse=0.6597 val_r2=-2.0167val_corr=0.5667\n",
      "[13/100] train_loss=0.0725 | val_loss=0.3884 val_rmse=0.6135 val_r2=-2.2558val_corr=0.5278\n",
      "[14/100] train_loss=0.0699 | val_loss=0.4413 val_rmse=0.6540 val_r2=-2.6187val_corr=0.4823\n",
      "[15/100] train_loss=0.0669 | val_loss=0.4342 val_rmse=0.6488 val_r2=-3.1364val_corr=0.5096\n",
      "[16/100] train_loss=0.0646 | val_loss=0.4364 val_rmse=0.6505 val_r2=-3.5220val_corr=0.5112\n",
      "[17/100] train_loss=0.0662 | val_loss=0.4627 val_rmse=0.6698 val_r2=-3.1484val_corr=0.4732\n",
      "[18/100] train_loss=0.0629 | val_loss=0.4121 val_rmse=0.6323 val_r2=-4.2802val_corr=0.4926\n",
      "[19/100] train_loss=0.0638 | val_loss=0.4478 val_rmse=0.6587 val_r2=-2.2595val_corr=0.5304\n",
      "[20/100] train_loss=0.0619 | val_loss=0.4083 val_rmse=0.6294 val_r2=-5.0287val_corr=0.5524\n",
      "[21/100] train_loss=0.0604 | val_loss=0.4419 val_rmse=0.6546 val_r2=-3.4359val_corr=0.5244\n",
      "[22/100] train_loss=0.0608 | val_loss=0.4405 val_rmse=0.6534 val_r2=-2.5315val_corr=0.4994\n",
      "[23/100] train_loss=0.0599 | val_loss=0.4204 val_rmse=0.6383 val_r2=-2.3471val_corr=0.5100\n",
      "Early stopping at epoch 23 (best epoch=13, val_loss=0.3884)\n",
      "4 番目の 4 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.4622 | val_loss=1.0276 val_rmse=1.0026 val_r2=-210.4780val_corr=0.4821\n",
      "[2/100] train_loss=0.2946 | val_loss=0.5445 val_rmse=0.7304 val_r2=-120.4351val_corr=0.5120\n",
      "[3/100] train_loss=0.2248 | val_loss=0.6511 val_rmse=0.7966 val_r2=-44.2298val_corr=0.4881\n",
      "[4/100] train_loss=0.1501 | val_loss=0.6484 val_rmse=0.7952 val_r2=-59.4447val_corr=0.4505\n",
      "[5/100] train_loss=0.1307 | val_loss=0.5534 val_rmse=0.7335 val_r2=-17.7604val_corr=0.4704\n",
      "[6/100] train_loss=0.1159 | val_loss=0.5975 val_rmse=0.7616 val_r2=-8.4240val_corr=0.4986\n",
      "[7/100] train_loss=0.1013 | val_loss=0.4815 val_rmse=0.6837 val_r2=-6.9014val_corr=0.5470\n",
      "[8/100] train_loss=0.0897 | val_loss=0.5230 val_rmse=0.7125 val_r2=-7.2156val_corr=0.5652\n",
      "[9/100] train_loss=0.0861 | val_loss=0.4935 val_rmse=0.6930 val_r2=-20.4450val_corr=0.5567\n",
      "[10/100] train_loss=0.0770 | val_loss=0.4423 val_rmse=0.6567 val_r2=-35.8728val_corr=0.5314\n",
      "[11/100] train_loss=0.0752 | val_loss=0.4842 val_rmse=0.6858 val_r2=-9.0144val_corr=0.4767\n",
      "[12/100] train_loss=0.0711 | val_loss=0.4386 val_rmse=0.6524 val_r2=-5.4257val_corr=0.4443\n",
      "[13/100] train_loss=0.0680 | val_loss=0.4561 val_rmse=0.6655 val_r2=-7.6910val_corr=0.4412\n",
      "[14/100] train_loss=0.0708 | val_loss=0.4215 val_rmse=0.6398 val_r2=-6.9349val_corr=0.4841\n",
      "[15/100] train_loss=0.0669 | val_loss=0.4378 val_rmse=0.6518 val_r2=-5.1974val_corr=0.5173\n",
      "[16/100] train_loss=0.0663 | val_loss=0.4517 val_rmse=0.6625 val_r2=-10.1224val_corr=0.5320\n",
      "[17/100] train_loss=0.0655 | val_loss=0.4466 val_rmse=0.6590 val_r2=-14.9579val_corr=0.5314\n",
      "[18/100] train_loss=0.0612 | val_loss=0.4351 val_rmse=0.6498 val_r2=-4.7693val_corr=0.5243\n",
      "[19/100] train_loss=0.0599 | val_loss=0.4500 val_rmse=0.6606 val_r2=-3.8530val_corr=0.5155\n",
      "[20/100] train_loss=0.0590 | val_loss=0.4348 val_rmse=0.6497 val_r2=-5.8421val_corr=0.5194\n",
      "[21/100] train_loss=0.0585 | val_loss=0.4162 val_rmse=0.6355 val_r2=-4.4774val_corr=0.5254\n",
      "[22/100] train_loss=0.0577 | val_loss=0.4064 val_rmse=0.6280 val_r2=-4.9716val_corr=0.5193\n",
      "[23/100] train_loss=0.0566 | val_loss=0.4786 val_rmse=0.6815 val_r2=-5.4393val_corr=0.4881\n",
      "[24/100] train_loss=0.0573 | val_loss=0.3602 val_rmse=0.5911 val_r2=-3.5665val_corr=0.4789\n",
      "[25/100] train_loss=0.0635 | val_loss=0.5157 val_rmse=0.7071 val_r2=-3.1862val_corr=0.4649\n",
      "[26/100] train_loss=0.0576 | val_loss=0.3761 val_rmse=0.6041 val_r2=-3.9200val_corr=0.4982\n",
      "[27/100] train_loss=0.0576 | val_loss=0.5014 val_rmse=0.6972 val_r2=-3.4805val_corr=0.4883\n",
      "[28/100] train_loss=0.0588 | val_loss=0.3942 val_rmse=0.6183 val_r2=-3.9752val_corr=0.5063\n",
      "[29/100] train_loss=0.0544 | val_loss=0.4726 val_rmse=0.6770 val_r2=-3.5395val_corr=0.5241\n",
      "[30/100] train_loss=0.0565 | val_loss=0.4187 val_rmse=0.6371 val_r2=-2.8060val_corr=0.5271\n",
      "[31/100] train_loss=0.0533 | val_loss=0.4134 val_rmse=0.6330 val_r2=-3.2004val_corr=0.5077\n",
      "[32/100] train_loss=0.0543 | val_loss=0.4303 val_rmse=0.6458 val_r2=-3.0342val_corr=0.4907\n",
      "[33/100] train_loss=0.0516 | val_loss=0.4068 val_rmse=0.6279 val_r2=-3.2263val_corr=0.4761\n",
      "[34/100] train_loss=0.0521 | val_loss=0.4671 val_rmse=0.6728 val_r2=-4.1537val_corr=0.4501\n",
      "Early stopping at epoch 34 (best epoch=24, val_loss=0.3602)\n",
      "4 番目の 5 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7226 | val_loss=0.3372 val_rmse=0.5807 val_r2=-3678.3979val_corr=0.2714\n",
      "[2/100] train_loss=0.5703 | val_loss=0.2972 val_rmse=0.5452 val_r2=-2314.8352val_corr=0.2423\n",
      "[3/100] train_loss=0.4187 | val_loss=0.7650 val_rmse=0.8747 val_r2=-4422.4800val_corr=0.2045\n",
      "[4/100] train_loss=0.3723 | val_loss=0.4607 val_rmse=0.6787 val_r2=-1973.6321val_corr=0.2649\n",
      "[5/100] train_loss=0.2960 | val_loss=0.2787 val_rmse=0.5279 val_r2=-5200.9468val_corr=0.3312\n",
      "[6/100] train_loss=0.2622 | val_loss=0.3487 val_rmse=0.5905 val_r2=-4523.0938val_corr=0.3671\n",
      "[7/100] train_loss=0.2101 | val_loss=0.4981 val_rmse=0.7058 val_r2=-1719.4087val_corr=0.3936\n",
      "[8/100] train_loss=0.1812 | val_loss=0.2300 val_rmse=0.4796 val_r2=-3201.4009val_corr=0.4104\n",
      "[9/100] train_loss=0.1677 | val_loss=0.3325 val_rmse=0.5766 val_r2=-2016.1370val_corr=0.4227\n",
      "[10/100] train_loss=0.1556 | val_loss=0.4468 val_rmse=0.6685 val_r2=-1235.3297val_corr=0.4439\n",
      "[11/100] train_loss=0.1413 | val_loss=0.3483 val_rmse=0.5902 val_r2=-2980.5291val_corr=0.4596\n",
      "[12/100] train_loss=0.1300 | val_loss=0.4895 val_rmse=0.6996 val_r2=-2011.5061val_corr=0.4625\n",
      "[13/100] train_loss=0.1208 | val_loss=0.4540 val_rmse=0.6738 val_r2=-1101.1569val_corr=0.4661\n",
      "[14/100] train_loss=0.1107 | val_loss=0.4463 val_rmse=0.6681 val_r2=-3114.4338val_corr=0.4478\n",
      "[15/100] train_loss=0.1071 | val_loss=0.5162 val_rmse=0.7184 val_r2=-1257.6985val_corr=0.4562\n",
      "[16/100] train_loss=0.0980 | val_loss=0.6420 val_rmse=0.8013 val_r2=-1309.9436val_corr=0.4623\n",
      "[17/100] train_loss=0.0923 | val_loss=0.4898 val_rmse=0.6998 val_r2=-2521.6328val_corr=0.4778\n",
      "[18/100] train_loss=0.0895 | val_loss=0.5507 val_rmse=0.7421 val_r2=-1526.8057val_corr=0.4787\n",
      "Early stopping at epoch 18 (best epoch=8, val_loss=0.2300)\n",
      "5 番目の 1 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7257 | val_loss=0.3552 val_rmse=0.5960 val_r2=-8298.1377val_corr=0.3327\n",
      "[2/100] train_loss=0.5546 | val_loss=0.3392 val_rmse=0.5824 val_r2=-2592.3643val_corr=0.2938\n",
      "[3/100] train_loss=0.3768 | val_loss=0.9010 val_rmse=0.9492 val_r2=-4071.8623val_corr=0.2776\n",
      "[4/100] train_loss=0.3278 | val_loss=0.3098 val_rmse=0.5566 val_r2=-1338.8220val_corr=0.3161\n",
      "[5/100] train_loss=0.2720 | val_loss=0.3044 val_rmse=0.5517 val_r2=-4144.7217val_corr=0.3436\n",
      "[6/100] train_loss=0.2215 | val_loss=0.6001 val_rmse=0.7747 val_r2=-4029.8833val_corr=0.3664\n",
      "[7/100] train_loss=0.2055 | val_loss=0.2352 val_rmse=0.4849 val_r2=-1242.0177val_corr=0.4150\n",
      "[8/100] train_loss=0.1837 | val_loss=0.2515 val_rmse=0.5015 val_r2=-2198.5833val_corr=0.4277\n",
      "[9/100] train_loss=0.1661 | val_loss=0.4951 val_rmse=0.7036 val_r2=-2746.5208val_corr=0.4237\n",
      "[10/100] train_loss=0.1573 | val_loss=0.3746 val_rmse=0.6120 val_r2=-876.0878val_corr=0.4379\n",
      "[11/100] train_loss=0.1442 | val_loss=0.2979 val_rmse=0.5458 val_r2=-1931.3184val_corr=0.4567\n",
      "[12/100] train_loss=0.1404 | val_loss=0.3966 val_rmse=0.6297 val_r2=-3552.6987val_corr=0.4651\n",
      "[13/100] train_loss=0.1338 | val_loss=0.3687 val_rmse=0.6072 val_r2=-1475.3270val_corr=0.4679\n",
      "[14/100] train_loss=0.1275 | val_loss=0.3748 val_rmse=0.6122 val_r2=-925.6025val_corr=0.4689\n",
      "[15/100] train_loss=0.1212 | val_loss=0.4431 val_rmse=0.6656 val_r2=-1837.1376val_corr=0.4712\n",
      "[16/100] train_loss=0.1136 | val_loss=0.4596 val_rmse=0.6779 val_r2=-1877.6260val_corr=0.4813\n",
      "[17/100] train_loss=0.1085 | val_loss=0.4847 val_rmse=0.6962 val_r2=-1421.3477val_corr=0.4875\n",
      "Early stopping at epoch 17 (best epoch=7, val_loss=0.2352)\n",
      "5 番目の 2 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6110 | val_loss=0.3255 val_rmse=0.5705 val_r2=-3126.9731val_corr=0.2670\n",
      "[2/100] train_loss=0.3832 | val_loss=0.8673 val_rmse=0.9313 val_r2=-3453.9958val_corr=0.2829\n",
      "[3/100] train_loss=0.3028 | val_loss=0.2940 val_rmse=0.5422 val_r2=-2635.4265val_corr=0.3507\n",
      "[4/100] train_loss=0.2557 | val_loss=0.3028 val_rmse=0.5503 val_r2=-7292.2881val_corr=0.3777\n",
      "[5/100] train_loss=0.2164 | val_loss=0.3936 val_rmse=0.6274 val_r2=-2263.3398val_corr=0.3727\n",
      "[6/100] train_loss=0.1896 | val_loss=0.4035 val_rmse=0.6352 val_r2=-791.4545val_corr=0.3732\n",
      "[7/100] train_loss=0.1721 | val_loss=0.3267 val_rmse=0.5715 val_r2=-3291.7170val_corr=0.4299\n",
      "[8/100] train_loss=0.1578 | val_loss=0.2606 val_rmse=0.5105 val_r2=-1605.2792val_corr=0.4527\n",
      "[9/100] train_loss=0.1432 | val_loss=0.4225 val_rmse=0.6500 val_r2=-1145.4026val_corr=0.4480\n",
      "[10/100] train_loss=0.1407 | val_loss=0.3370 val_rmse=0.5805 val_r2=-1546.7991val_corr=0.4406\n",
      "[11/100] train_loss=0.1321 | val_loss=0.3525 val_rmse=0.5937 val_r2=-2495.9326val_corr=0.4245\n",
      "[12/100] train_loss=0.1272 | val_loss=0.4446 val_rmse=0.6668 val_r2=-1260.1263val_corr=0.4506\n",
      "[13/100] train_loss=0.1189 | val_loss=0.3681 val_rmse=0.6068 val_r2=-1013.5469val_corr=0.4675\n",
      "[14/100] train_loss=0.1152 | val_loss=0.5433 val_rmse=0.7371 val_r2=-2773.6396val_corr=0.4674\n",
      "[15/100] train_loss=0.1075 | val_loss=0.3720 val_rmse=0.6099 val_r2=-1668.4708val_corr=0.4699\n",
      "[16/100] train_loss=0.1023 | val_loss=0.5318 val_rmse=0.7292 val_r2=-1972.0461val_corr=0.4516\n",
      "[17/100] train_loss=0.0951 | val_loss=0.4949 val_rmse=0.7035 val_r2=-2060.7214val_corr=0.4424\n",
      "[18/100] train_loss=0.0970 | val_loss=0.5208 val_rmse=0.7217 val_r2=-1332.6351val_corr=0.4512\n",
      "Early stopping at epoch 18 (best epoch=8, val_loss=0.2606)\n",
      "5 番目の 3 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.6847 | val_loss=0.3305 val_rmse=0.5749 val_r2=-17908.6680val_corr=0.2973\n",
      "[2/100] train_loss=0.3872 | val_loss=0.8230 val_rmse=0.9072 val_r2=-2512.9177val_corr=0.2775\n",
      "[3/100] train_loss=0.3130 | val_loss=0.2904 val_rmse=0.5389 val_r2=-614.7972val_corr=0.3279\n",
      "[4/100] train_loss=0.2534 | val_loss=0.4630 val_rmse=0.6804 val_r2=-5766.1641val_corr=0.3623\n",
      "[5/100] train_loss=0.2181 | val_loss=0.3377 val_rmse=0.5812 val_r2=-6822.3154val_corr=0.3876\n",
      "[6/100] train_loss=0.1869 | val_loss=0.3107 val_rmse=0.5574 val_r2=-3931.2339val_corr=0.3941\n",
      "[7/100] train_loss=0.1635 | val_loss=0.4720 val_rmse=0.6870 val_r2=-2543.8442val_corr=0.4030\n",
      "[8/100] train_loss=0.1549 | val_loss=0.3139 val_rmse=0.5603 val_r2=-1911.0574val_corr=0.4229\n",
      "[9/100] train_loss=0.1430 | val_loss=0.5396 val_rmse=0.7346 val_r2=-1819.5585val_corr=0.4261\n",
      "[10/100] train_loss=0.1313 | val_loss=0.3611 val_rmse=0.6009 val_r2=-578.7535val_corr=0.4329\n",
      "[11/100] train_loss=0.1246 | val_loss=0.5766 val_rmse=0.7593 val_r2=-1424.0277val_corr=0.4575\n",
      "[12/100] train_loss=0.1157 | val_loss=0.4592 val_rmse=0.6777 val_r2=-2563.5613val_corr=0.4618\n",
      "[13/100] train_loss=0.1090 | val_loss=0.4725 val_rmse=0.6874 val_r2=-2427.8091val_corr=0.4346\n",
      "Early stopping at epoch 13 (best epoch=3, val_loss=0.2904)\n",
      "5 番目の 4 回目の学習が終了しました。\n",
      "[1/100] train_loss=0.7083 | val_loss=0.3227 val_rmse=0.5680 val_r2=-11959.3008val_corr=0.3432\n",
      "[2/100] train_loss=0.4593 | val_loss=0.7043 val_rmse=0.8393 val_r2=-3522.3757val_corr=0.3101\n",
      "[3/100] train_loss=0.3503 | val_loss=0.5651 val_rmse=0.7518 val_r2=-2555.0017val_corr=0.3214\n",
      "[4/100] train_loss=0.2738 | val_loss=0.3153 val_rmse=0.5615 val_r2=-5013.2471val_corr=0.3476\n",
      "[5/100] train_loss=0.2539 | val_loss=0.3476 val_rmse=0.5896 val_r2=-7175.6323val_corr=0.3686\n",
      "[6/100] train_loss=0.2034 | val_loss=0.4072 val_rmse=0.6381 val_r2=-1744.1554val_corr=0.3909\n",
      "[7/100] train_loss=0.1966 | val_loss=0.3081 val_rmse=0.5551 val_r2=-810.6364val_corr=0.4197\n",
      "[8/100] train_loss=0.1738 | val_loss=0.3133 val_rmse=0.5597 val_r2=-3547.9397val_corr=0.4400\n",
      "[9/100] train_loss=0.1652 | val_loss=0.3205 val_rmse=0.5661 val_r2=-1425.4087val_corr=0.4375\n",
      "[10/100] train_loss=0.1520 | val_loss=0.4040 val_rmse=0.6356 val_r2=-948.9579val_corr=0.4368\n",
      "[11/100] train_loss=0.1436 | val_loss=0.3864 val_rmse=0.6216 val_r2=-1912.2903val_corr=0.4502\n",
      "[12/100] train_loss=0.1383 | val_loss=0.3378 val_rmse=0.5812 val_r2=-2866.2021val_corr=0.4581\n",
      "[13/100] train_loss=0.1359 | val_loss=0.3685 val_rmse=0.6070 val_r2=-1682.5803val_corr=0.4516\n",
      "[14/100] train_loss=0.1289 | val_loss=0.3171 val_rmse=0.5631 val_r2=-1107.7236val_corr=0.4486\n",
      "[15/100] train_loss=0.1242 | val_loss=0.4209 val_rmse=0.6488 val_r2=-1734.1527val_corr=0.4515\n",
      "[16/100] train_loss=0.1144 | val_loss=0.4631 val_rmse=0.6805 val_r2=-1399.5405val_corr=0.4585\n",
      "[17/100] train_loss=0.1071 | val_loss=0.3885 val_rmse=0.6233 val_r2=-1452.3616val_corr=0.4724\n",
      "Early stopping at epoch 17 (best epoch=7, val_loss=0.3081)\n",
      "5 番目の 5 回目の学習が終了しました。\n",
      "すべての学習が終了しました。\n"
     ]
    }
   ],
   "source": [
    "num_floods = len(datasets)\n",
    "seeds = [0, 1, 2, 3, 4]               # モデルの初期値を決める際のシード値\n",
    "y_pos = [Fe+Fd]\n",
    "\n",
    "\n",
    "rmse_list = np.zeros((num_floods, 5))\n",
    "r2_list   = np.zeros((num_floods, 5))\n",
    "rmse_list_train = np.zeros((num_floods, 5))\n",
    "r2_list_train   = np.zeros((num_floods, 5))\n",
    "\n",
    "for i in range(num_floods):\n",
    "    # ----- 1. val と train の分割 -----\n",
    "    ds_val = datasets[i]\n",
    "    ds_train = ConcatDataset([datasets[j] for j in range(num_floods) if j != i])\n",
    "\n",
    "    valLoader = DataLoader(ds_val, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "    trainLoader = DataLoader(ds_train, batch_size=cfg[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    \n",
    "    for s_id, seed in enumerate(seeds):\n",
    "        \n",
    "        # モデルの初期化\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        model = Seq2SeqLSTM(in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "                            enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "                            enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "                            bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "                            bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "                            head_activation=cfg[\"head_activation\"],\n",
    "                            use_conv=cfg[\"use_conv\"]\n",
    "                           ).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "        model.apply(init_weights)\n",
    "\n",
    "\n",
    "        best_val = float(\"inf\")\n",
    "        best_epoch = 0\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = None\n",
    "        best_opt_state = None\n",
    "\n",
    "        patience = cfg[\"patience\"]\n",
    "        min_delta = 1e-4\n",
    "\n",
    "        # 学習ループ（early stoppingあり）\n",
    "        for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "            # ---- 1. 学習 ----\n",
    "            train_loss = train_one_epoch(model, trainLoader, optimizer)\n",
    "\n",
    "            # ---- 2. 検証 ----\n",
    "            val_metrics = evaluate(model, valLoader)\n",
    "            val_loss = float(val_metrics[\"loss\"])\n",
    "\n",
    "            # ---- 3. ログ出力 ----\n",
    "            if epoch % cfg[\"print_every\"] == 0:\n",
    "                print(f\"[{epoch}/{cfg['epochs']}] \"\n",
    "                      f\"train_loss={train_loss:.4f} | \"\n",
    "                      f\"val_loss={val_loss:.4f} \"\n",
    "                      f\"val_rmse={val_metrics['rmse']:.4f} \"\n",
    "                      f\"val_r2={val_metrics['r2']:.4f}\"\n",
    "                      f\"val_corr={val_metrics['corr']:.4f}\")\n",
    "\n",
    "            # ---- 4. 改善チェック ----\n",
    "            if best_val - val_loss > min_delta:\n",
    "                best_val = val_loss\n",
    "                best_epoch = epoch\n",
    "                epochs_no_improve = 0\n",
    "                \n",
    "                # ★ モデル重みをcloneして保持\n",
    "                best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "                # ★ Optimizerの状態もcloneして保持（必要に応じて）\n",
    "                best_opt_state = {\n",
    "                    \"state\": {\n",
    "                        k: {kk: (vv.detach().clone() if torch.is_tensor(vv) else vv)\n",
    "                            for kk, vv in v.items()}\n",
    "                        for k, v in optimizer.state_dict()[\"state\"].items()\n",
    "                    },\n",
    "                    \"param_groups\": [dict(g) for g in optimizer.state_dict()[\"param_groups\"]],\n",
    "                }\n",
    "        \n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            # ---- 5. Early Stopping 発動 ----\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} \"\n",
    "                      f\"(best epoch={best_epoch}, val_loss={best_val:.4f})\")\n",
    "                break\n",
    "\n",
    "\n",
    "        # 学習終了後に、実スケールでの標準化パラメータを記録\n",
    "        metrics = evaluate_original_scale_by_index(model, valLoader, mean, std, data.columns, y_pos)\n",
    "        metrics_train = evaluate_original_scale_by_index(model, trainLoader, mean, std, data.columns, y_pos)\n",
    "        \n",
    "\n",
    "        rmse_list[i, s_id] = metrics[\"rmse\"]\n",
    "        r2_list[i, s_id] = metrics[\"r2\"]\n",
    "        rmse_list_train[i, s_id] = metrics_train[\"rmse\"]\n",
    "        r2_list_train[i, s_id] = metrics_train[\"r2\"]\n",
    "        \n",
    "        print(f\"{i+1} 番目の {s_id+1} 回目の学習が終了しました。\")\n",
    "        \n",
    "\n",
    "print(\"すべての学習が終了しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574abd4-e69f-4c6d-94e3-e544128ee7c0",
   "metadata": {},
   "source": [
    "## 学習結果の平均化・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44213f5-0401-45a2-8cdd-05b93febe9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をExcelファイルに保存しました。\n"
     ]
    }
   ],
   "source": [
    "# 行ごとの平均\n",
    "rmse_row_mean = rmse_list.mean(axis=1)\n",
    "r2_row_mean = r2_list.mean(axis=1)\n",
    "\n",
    "rmse_row_mean_train = rmse_list_train.mean(axis=1)\n",
    "r2_row_mean_train = r2_list_train.mean(axis=1)\n",
    "\n",
    "# さらに全体の平均\n",
    "rmse_mean = rmse_row_mean.mean()\n",
    "r2_mean   = r2_row_mean.mean()\n",
    "rmse_mean_train = rmse_row_mean_train.mean()\n",
    "r2_mean_train   = r2_row_mean_train.mean()\n",
    "\n",
    "# 結果をまとめる\n",
    "df_result = pd.DataFrame({\n",
    "    \"RMSE_row_mean_val\": rmse_row_mean,\n",
    "    \"R2_row_mean_val\": r2_row_mean,\n",
    "    \"RMSE_row_mean_train\": rmse_row_mean_train,\n",
    "    \"R2_row_mean_train\": r2_row_mean_train})\n",
    "\n",
    "df_result.loc[\"overall_mean\"] = [rmse_mean, r2_mean, rmse_mean_train, r2_mean_train]\n",
    "\n",
    "# --- Excel 出力 ---\n",
    "with pd.ExcelWriter(save_path, engine=\"openpyxl\") as writer:\n",
    "    df_result.to_excel(writer, sheet_name=\"average\")\n",
    "    pd.DataFrame(rmse_list).to_excel(writer, sheet_name=\"rmse_list\", index=False, header=False)\n",
    "    pd.DataFrame(r2_list).to_excel(writer, sheet_name=\"r2_list\", index=False, header=False)\n",
    "    pd.DataFrame(rmse_list_train).to_excel(writer, sheet_name=\"rmse_list_train\", index=False, header=False)\n",
    "    pd.DataFrame(r2_list_train).to_excel(writer, sheet_name=\"r2_list_train\", index=False, header=False)\n",
    "    \n",
    "print(\"結果をExcelファイルに保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08522551-4926-44f1-a9b6-ff536cc9e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c8437-b846-4d5b-90e6-15234c1a4feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd0d94-a9ae-4339-9cd0-4d902a913f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff664e-2470-4b95-ac07-b3c494c7baa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abbc0b-06c0-48b2-9ad5-b4d78a3562ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
