{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43c1174-7a6d-49d4-a1df-5e337d0f452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5230b-91c8-48e1-bfd5-1e3ebd1fbcb8",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f5bfad-192d-47e4-bf85-1eceab945f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ユーザ設定 ======\n",
    "\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_hourlyAve_for_LSTM_trial3.xlsx\"\n",
    "flood_idx_path_train = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_train.xlsx\"\n",
    "flood_idx_path_val = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_val.xlsx\"\n",
    "flood_idx_path_test = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_test.xlsx\"\n",
    "\n",
    "# 列番号（0始まり）で指定\n",
    "enc_cols   = [5, 3, 4]      # エンコーダ入力の列番号（例：3変数）\n",
    "dec_cols   = [5, 3]  # デコーダ入力の列番号（例：2変数）\n",
    "y_cols      = [4]          # 出力（目的変数）の列番号（例：1変数）\n",
    "\n",
    "Te = 72    # エンコーダのタイムステップ長\n",
    "Td = 240   # デコーダのタイムステップ長\n",
    "\n",
    "batch_size = 16 # ミニバッチサイズ\n",
    "\n",
    "# 洪水区間（1始まり行番号で指定してOK。Python内部で0始まりに直す）\n",
    "df_ranges_train = pd.read_excel(flood_idx_path_train, header=0)\n",
    "flood_ranges_train_1based = [tuple(x) for x in df_ranges_train.to_numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66a7c8d-4770-4d55-8e96-8ec0b8c52632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 読み込み ======\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "# 0-basedに変換（pandasは0-based）\n",
    "flood_ranges_train = [(s-1, e-1) for (s, e) in flood_ranges_train_1based]\n",
    "\n",
    "# 必要列だけ抽出（順番固定）\n",
    "use_cols = enc_cols + dec_cols + y_cols\n",
    "data = df.iloc[:, use_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91c7818-8c54-4ef6-8873-38a2475974e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---平均（train）----\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "dtype: float64\n",
      "----標準偏差（train）----\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ====== 標準化：train dataから平均・標準偏差を算出 ======\n",
    "\n",
    "flood_data_train_parts = [data.iloc[s:e+1, :] for (s, e) in flood_ranges_train]\n",
    "flood_data_train = pd.concat(flood_data_train_parts, axis=0)\n",
    "\n",
    "mean = flood_data_train.mean(numeric_only=True)\n",
    "std  = flood_data_train.std(numeric_only=True).replace(0, 1.0)\n",
    "data_norm = data # 全期間のデータを標準化【今回は標準化を行わないものを試す！！】\n",
    "\n",
    "print('---平均（train）----')\n",
    "print(mean)\n",
    "\n",
    "print('----標準偏差（train）----')\n",
    "print(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b3226e-f265-4ddc-abbb-93d8cc539d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 915\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（train） ======\n",
    "samples_train = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_train:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_train.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01144d4b-68d0-4692-813d-69cb60c50bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 194\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（val） ======\n",
    "\n",
    "df_ranges_val = pd.read_excel(flood_idx_path_val, header=0)\n",
    "flood_ranges_val_1based = [tuple(x) for x in df_ranges_val.to_numpy()]\n",
    "flood_ranges_val = [(s-1, e-1) for (s, e) in flood_ranges_val_1based]\n",
    "\n",
    "\n",
    "samples_val = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_val:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_val.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1677019-e74b-4fa3-99a0-61d270ef32aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 97\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（test） ======\n",
    "\n",
    "df_ranges_test = pd.read_excel(flood_idx_path_test, header=0)\n",
    "flood_ranges_test_1based = [tuple(x) for x in df_ranges_test.to_numpy()]\n",
    "flood_ranges_test = [(s-1, e-1) for (s, e) in flood_ranges_test_1based]\n",
    "\n",
    "\n",
    "samples_test = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_test:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_test.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50ea38-9cfe-4875-a77b-a941b99a7958",
   "metadata": {},
   "source": [
    "# pyTorch Dataset / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189e891d-b527-4c1d-8f98-08c91ffd8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, triplets):\n",
    "        self.triplets = triplets  # list of (enc_X, dec_X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triplets[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    enc_seqs, dec_seqs, ys = zip(*batch)\n",
    "    # ここでは全サンプル同一長さ前提（Te/Td固定）なので単純stack\n",
    "    enc_x = torch.stack(enc_seqs, dim=0)  # [B, Te, Fe]\n",
    "    dec_x = torch.stack(dec_seqs, dim=0)  # [B, Td, Fd]\n",
    "    y     = torch.stack(ys,       dim=0)  # [B, Td, Fo]\n",
    "    \n",
    "    # マスク（将来可変長のときに使う）\n",
    "    B, Td, _ = y.shape\n",
    "    mask = torch.ones(B, Td, 1, dtype=torch.float32)\n",
    "    return enc_x, dec_x, y, mask\n",
    "\n",
    "\n",
    "trainDataset = FloodSeq2SeqDataset(samples_train)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valDataset = FloodSeq2SeqDataset(samples_val)\n",
    "valLoader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "testDataset = FloodSeq2SeqDataset(samples_test)\n",
    "testLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55755df-49f9-44b5-8a2e-9ffb4ed74e98",
   "metadata": {},
   "source": [
    "# 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0f4213-343a-4271-a507-6dbf7db8d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    \"\"\"collate_fnの戻り値が (enc,dec,y) か (enc,dec,y,mask) のどちらでも対応\"\"\"\n",
    "    if len(batch) == 3:\n",
    "        enc_x, dec_x, y = batch\n",
    "        mask = torch.ones_like(y[..., :1])  # [B,Td,1]\n",
    "    elif len(batch) == 4:\n",
    "        enc_x, dec_x, y, mask = batch\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected batch format\")\n",
    "    return enc_x.to(device), dec_x.to(device), y.to(device), mask.to(device)\n",
    "\n",
    "def masked_mse(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1] (1=valid, 0=pad)\n",
    "    diff2 = (pred - target) ** 2\n",
    "    diff2 = diff2 * mask\n",
    "    denom = mask.sum(dim=(1,2)).clamp_min(1.0)  # per-sample\n",
    "    per_sample = diff2.sum(dim=(1,2)) / denom\n",
    "    return per_sample.mean()\n",
    "\n",
    "def masked_rmse(pred, target, mask):\n",
    "    return torch.sqrt(masked_mse(pred, target, mask))\n",
    "\n",
    "def masked_r2(pred, target, mask):\n",
    "    # R² = 1 - SSE/SST, マスク版\n",
    "    mean = (target * mask).sum(dim=(1,2), keepdim=True) / mask.sum(dim=(1,2), keepdim=True).clamp_min(1.0)\n",
    "    sse = ((pred - target) ** 2 * mask).sum(dim=(1,2))\n",
    "    sst = ((target - mean) ** 2 * mask).sum(dim=(1,2)).clamp_min(1e-12)\n",
    "    r2  = 1.0 - sse / sst\n",
    "    return r2.mean()\n",
    "\n",
    "def masked_corr(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1]\n",
    "    pred = pred * mask\n",
    "    target = target * mask\n",
    "    valid = mask.sum(dim=(1,2)).clamp_min(1.0)\n",
    "\n",
    "    # 平均\n",
    "    mean_pred = pred.sum(dim=(1,2)) / valid\n",
    "    mean_target = target.sum(dim=(1,2)) / valid\n",
    "\n",
    "    # 偏差\n",
    "    diff_pred = (pred - mean_pred.view(-1,1,1)) * mask\n",
    "    diff_target = (target - mean_target.view(-1,1,1)) * mask\n",
    "\n",
    "    # 共分散と分散\n",
    "    cov = (diff_pred * diff_target).sum(dim=(1,2)) / valid\n",
    "    var_pred = (diff_pred**2).sum(dim=(1,2)) / valid\n",
    "    var_target = (diff_target**2).sum(dim=(1,2)) / valid\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_pred * var_target) + 1e-12)\n",
    "    return corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056610ed-099b-4966-bdaa-1f00b571489d",
   "metadata": {},
   "source": [
    "# 汎用Seq2Seq LSTM（エンコーダ→デコーダ、損失はマスクで集計）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d5b144-c2c3-4f39-8d5d-e61435c5fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateBridge(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoderの(h, c)をDecoder初期状態へ写像するブリッジ。\n",
    "    - 層数/隠れ次元が異なってもOK\n",
    "    - bridge_mode:\n",
    "        - \"zero_pad\":  層合わせ=0埋め or 切り落とし、隠れ次元は線形射影\n",
    "        - \"repeat_top\":層合わせ=最上層の繰り返し/切り落とし、隠れ次元は線形射影\n",
    "        - \"linear_stack\": [B, L_enc, H_enc] -> 線形で [B, L_dec, H_dec] へ（層方向も学習で混合）\n",
    "\n",
    "    - enc_layers: エンコーダの層の深さ\n",
    "    - dec_layers: デコーダの層の深さ\n",
    "    - enc_hidden: エンコーダのノード数\n",
    "    - dec_hidden: デコーダのノード数\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hidden, dec_hidden, mode=\"zero_pad\"):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.enc_hidden = enc_hidden\n",
    "        self.dec_hidden = dec_hidden\n",
    "        self.mode = mode\n",
    "\n",
    "        # 隠れ次元の変換（h/c共用）\n",
    "        if mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            self.proj = nn.Linear(enc_hidden, dec_hidden, bias=True)\n",
    "        elif mode == \"linear_stack\":\n",
    "            # 層方向もまとめて線形変換\n",
    "            self.proj_h = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "            self.proj_c = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bridge mode: {mode}\")\n",
    "\n",
    "    def _match_layers(self, x, how=\"zero_pad\"):\n",
    "        \"\"\"\n",
    "        x: [L_enc, B, H_enc] を層数だけ合わせる（隠れ次元は未変換）\n",
    "        return: [L_dec, B, H_enc]\n",
    "\n",
    "        B: バッチサイズ\n",
    "        \"\"\"\n",
    "        L_enc, B, H = x.shape\n",
    "        L_dec = self.dec_layers\n",
    "\n",
    "        if L_dec == L_enc:\n",
    "            return x\n",
    "\n",
    "        if L_dec < L_enc:\n",
    "            # 上位層を優先して切り落とす（直観的には最上層が一番抽象的）\n",
    "            return x[:L_dec, :, :]\n",
    "\n",
    "        # L_dec > L_enc の場合\n",
    "        pad_count = L_dec - L_enc\n",
    "        if how == \"repeat_top\":\n",
    "            top = x[-1:, :, :].expand(pad_count, B, H)  # 最上層を複製\n",
    "            return torch.cat([x, top], dim=0)\n",
    "        else:  # zero_pad\n",
    "            pad = x.new_zeros(pad_count, B, H)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        \"\"\"\n",
    "        h_enc, c_enc: [L_enc, B, H_enc]\n",
    "        返り値: (h0_dec, c0_dec) それぞれ [L_dec, B, H_dec]\n",
    "        \"\"\"\n",
    "        if self.mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            # 層合わせ（まだ enc_hidden 次元のまま）\n",
    "            h = self._match_layers(h_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            c = self._match_layers(c_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            # 次元射影\n",
    "            L, B, H = h.shape\n",
    "            h = self.proj(h)  # broadcasting: [L,B,H_enc]->[L,B,H_dec]\n",
    "            c = self.proj(c)\n",
    "            return h, c\n",
    "\n",
    "        else:  # linear_stack\n",
    "            # [L_enc,B,H_enc] -> [B, L_enc*H_enc]\n",
    "            L_enc, B, H_enc = h_enc.shape\n",
    "            flat_h = h_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            flat_c = c_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            # 線形写像\n",
    "            out_h = self.proj_h(flat_h)  # [B, L_dec*H_dec]\n",
    "            out_c = self.proj_c(flat_c)\n",
    "            # [L_dec,B,H_dec] に戻す\n",
    "            L_dec, H_dec = self.dec_layers, self.dec_hidden\n",
    "            h = out_h.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            c = out_c.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17bf2a71-0425-4702-96da-5b6232cfa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_enc: int, # エンコーダ入力変数の数\n",
    "        in_dec: int, # デコーダ入力変数の数\n",
    "        out_dim: int, # 出力変数の数\n",
    "        enc_hidden: int = 128,\n",
    "        dec_hidden: int = 128,\n",
    "        enc_layers: int = 2,\n",
    "        dec_layers: int = 3,\n",
    "        bridge_mode: str = \"zero_pad\",  # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "        dropout: float = 0.0, # LSTMの層間ドロップアウト率\n",
    "        bidirectional_enc: bool = False,  # エンコーダのみ双方向にするかどうか（必要ならEncoderを双方向にも）\n",
    "        head_activation=\"relu\", # 活性化関数\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional_enc = bidirectional_enc\n",
    "        enc_dir = 2 if bidirectional_enc else 1\n",
    "        enc_hidden_eff = enc_hidden * enc_dir  # 双方向なら出力次元が倍\n",
    "\n",
    "        self.enc = nn.LSTM(\n",
    "            input_size=in_enc,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if enc_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional_enc\n",
    "        )\n",
    "\n",
    "        self.dec = nn.LSTM(\n",
    "            input_size=in_dec,\n",
    "            hidden_size=dec_hidden,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if dec_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Encoderが双方向のときは、(h_fwd, h_bwd) を結合した次元 enc_hidden_eff を\n",
    "        # Decoder hidden 次元へ写像する必要がある\n",
    "        self.bridge = StateBridge(\n",
    "            enc_layers=enc_layers * enc_dir,\n",
    "            dec_layers=dec_layers,\n",
    "            enc_hidden=enc_hidden,\n",
    "            dec_hidden=dec_hidden,\n",
    "            mode=bridge_mode\n",
    "        ) if (enc_layers != dec_layers or enc_dir != 1 or enc_hidden != dec_hidden or bridge_mode==\"linear_stack\") else None\n",
    "\n",
    "        self.head = nn.Linear(dec_hidden, out_dim) # 全結合層\n",
    "\n",
    "        self.act = {\n",
    "            \"identity\": nn.Identity(),\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "        }[head_activation]\n",
    "\n",
    "    def _extract_final_states(self, out, hc):\n",
    "        \"\"\"\n",
    "        LSTMの出力から (h_T, c_T) を取り出して成形。\n",
    "        双方向Encoderの場合は各層ごとに [fwd, bwd] を層方向に並べる。\n",
    "        \"\"\"\n",
    "        h, c = hc  # [num_layers * num_directions, B, H]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, enc_x, dec_x):\n",
    "        \"\"\"\n",
    "        enc_x: [B, Te, in_enc]\n",
    "        dec_x: [B, Td, in_dec]\n",
    "        return: yhat [B, Td, out_dim]\n",
    "        \"\"\"\n",
    "        _, (h_T, c_T) = self.enc(enc_x)  # h_T,c_T: [L_enc * dir, B, H_enc]\n",
    "\n",
    "        if self.bridge is not None:\n",
    "            h0_dec, c0_dec = self.bridge(h_T, c_T)  # [L_dec, B, H_dec]\n",
    "        else:\n",
    "            # 形・次元が完全一致ならそのまま\n",
    "            h0_dec, c0_dec = h_T, c_T\n",
    "\n",
    "        dec_out, _ = self.dec(dec_x, (h0_dec, c0_dec))  # [B, Td, H_dec]\n",
    "        yhat = self.head(self.act(dec_out))             # [B, Td, out_dim]\n",
    "        return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfbd76-7603-4f15-bd85-82645d0acd76",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddb4838-b64d-46b4-83bf-eff07d444af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg = {\n",
    "    # Model\n",
    "    \"in_enc\": 3,\n",
    "    \"in_dec\": 2,\n",
    "    \"out_dim\": 1,\n",
    "    \"enc_hidden\": 32,\n",
    "    \"dec_hidden\": 32,\n",
    "    \"enc_layers\": 1,\n",
    "    \"dec_layers\": 1,\n",
    "    \"bridge_mode\": \"zero_pad\",   # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "    \"dropout\": 0.1,\n",
    "    \"bidirectional_enc\": False,\n",
    "    \"head_activation\": \"tanh\", # \"identity\", \"relu\", \"tanh\", \"sigmoid\" など\n",
    "    # Train\n",
    "    \"epochs\": 200,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0.0, # L2正規化係数。0なら無効\n",
    "    \"grad_clip\": 1.0, # 勾配クリッピングの閾値。０かNoneなら無効\n",
    "    \"print_every\": 1, # 学習の進捗を何エポックごとに出力するか\n",
    "    \"patience\": 3, # early stopping\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c75568c-0825-4290-bf08-2b81b03840bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数・評価関数の定義\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if cfg[\"grad_clip\"]:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = enc_x.size(0) # バッチサイズ\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return total_loss / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0; total_rmse = 0.0; total_r2 = 0.0; total_corr = 0.0; n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "        rmse = masked_rmse(yhat, y, mask)\n",
    "        r2   = masked_r2(yhat, y, mask)\n",
    "        corr = masked_corr(yhat, y, mask)\n",
    "\n",
    "        bs = enc_x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_rmse += rmse.item() * bs\n",
    "        total_r2   += r2.item() * bs\n",
    "        total_corr += corr.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / max(n,1),\n",
    "        \"rmse\": total_rmse / max(n,1),\n",
    "        \"r2\":   total_r2   / max(n,1),\n",
    "        \"corr\": total_corr / max(n,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e1155d-44ae-4821-be2e-124b8caa544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200] train_loss=2102564.7736 | val_loss=1955667.5052 val_rmse=1397.7486 val_r2=-0.4831val_corr=0.4930\n",
      "[2/200] train_loss=2100597.6012 | val_loss=1952672.0335 val_rmse=1394.1968 val_r2=-0.4800val_corr=0.3020\n",
      "[3/200] train_loss=2098364.4339 | val_loss=1949972.0619 val_rmse=1391.5007 val_r2=-0.4772val_corr=-0.5811\n",
      "[4/200] train_loss=2096055.0489 | val_loss=1946542.1907 val_rmse=1389.5729 val_r2=-0.4737val_corr=0.2012\n",
      "[5/200] train_loss=2093746.2019 | val_loss=1943664.8093 val_rmse=1392.1365 val_r2=-0.4708val_corr=0.1261\n",
      "[6/200] train_loss=2091716.5598 | val_loss=1941086.9124 val_rmse=1388.9677 val_r2=-0.4682val_corr=0.1065\n",
      "[7/200] train_loss=2089890.1548 | val_loss=1938635.4291 val_rmse=1389.3065 val_r2=-0.4657val_corr=0.0918\n",
      "[8/200] train_loss=2088028.3533 | val_loss=1936041.0206 val_rmse=1388.3369 val_r2=-0.4631val_corr=0.0810\n",
      "[9/200] train_loss=2086196.8966 | val_loss=1933592.1456 val_rmse=1388.1566 val_r2=-0.4606val_corr=0.0723\n",
      "[10/200] train_loss=2084439.8568 | val_loss=1931208.9446 val_rmse=1386.5690 val_r2=-0.4582val_corr=0.0647\n",
      "[11/200] train_loss=2082703.9773 | val_loss=1928866.3376 val_rmse=1386.1934 val_r2=-0.4559val_corr=0.0563\n",
      "[12/200] train_loss=2080987.3820 | val_loss=1926558.3376 val_rmse=1385.8330 val_r2=-0.4535val_corr=0.0504\n",
      "[13/200] train_loss=2079323.7810 | val_loss=1924273.1340 val_rmse=1383.2774 val_r2=-0.4513val_corr=0.0563\n",
      "[14/200] train_loss=2077617.9107 | val_loss=1922039.3711 val_rmse=1384.5884 val_r2=-0.4490val_corr=0.1233\n",
      "[15/200] train_loss=2076024.7489 | val_loss=1919776.9175 val_rmse=1381.6190 val_r2=-0.4468val_corr=0.1308\n",
      "[16/200] train_loss=2074338.2861 | val_loss=1917537.2023 val_rmse=1381.5231 val_r2=-0.4445val_corr=0.1210\n",
      "[17/200] train_loss=2072749.4152 | val_loss=1915325.1649 val_rmse=1382.0799 val_r2=-0.4423val_corr=0.1173\n",
      "[18/200] train_loss=2071075.4149 | val_loss=1913131.3119 val_rmse=1380.2753 val_r2=-0.4401val_corr=0.1460\n",
      "[19/200] train_loss=2069494.4929 | val_loss=1910915.8276 val_rmse=1376.4425 val_r2=-0.4379val_corr=0.1097\n",
      "[20/200] train_loss=2067918.0146 | val_loss=1908706.1830 val_rmse=1375.9673 val_r2=-0.4358val_corr=0.2300\n",
      "[21/200] train_loss=2066328.1063 | val_loss=1906632.5773 val_rmse=1379.7559 val_r2=-0.4336val_corr=0.4432\n",
      "[22/200] train_loss=2064710.2770 | val_loss=1904405.8093 val_rmse=1372.9584 val_r2=-0.4315val_corr=0.2223\n",
      "[23/200] train_loss=2063175.1288 | val_loss=1902283.4021 val_rmse=1375.6549 val_r2=-0.4293val_corr=0.2381\n",
      "[24/200] train_loss=2061599.1052 | val_loss=1900127.3363 val_rmse=1377.0932 val_r2=-0.4272val_corr=0.2455\n",
      "[25/200] train_loss=2060049.1742 | val_loss=1898000.0258 val_rmse=1375.5756 val_r2=-0.4251val_corr=0.2717\n",
      "[26/200] train_loss=2058512.8193 | val_loss=1895957.7088 val_rmse=1372.5154 val_r2=-0.4231val_corr=0.3321\n",
      "[27/200] train_loss=2057033.7781 | val_loss=1893922.9149 val_rmse=1371.1628 val_r2=-0.4211val_corr=0.3621\n",
      "[28/200] train_loss=2055487.7617 | val_loss=1891856.6276 val_rmse=1372.0760 val_r2=-0.4190val_corr=0.3424\n",
      "[29/200] train_loss=2053990.8336 | val_loss=1889781.7680 val_rmse=1372.3137 val_r2=-0.4170val_corr=0.3157\n",
      "[30/200] train_loss=2052473.1041 | val_loss=1887749.7423 val_rmse=1371.4970 val_r2=-0.4150val_corr=0.3282\n",
      "[31/200] train_loss=2051014.7734 | val_loss=1885829.5966 val_rmse=1369.5993 val_r2=-0.4130val_corr=0.4070\n",
      "[32/200] train_loss=2049554.3156 | val_loss=1883826.4227 val_rmse=1371.1547 val_r2=-0.4112val_corr=0.3785\n",
      "[33/200] train_loss=2048094.9373 | val_loss=1881966.4072 val_rmse=1369.7642 val_r2=-0.4093val_corr=0.4269\n",
      "[34/200] train_loss=2046704.9566 | val_loss=1880098.0245 val_rmse=1366.1588 val_r2=-0.4075val_corr=0.4149\n",
      "[35/200] train_loss=2045416.5186 | val_loss=1878350.0825 val_rmse=1369.0573 val_r2=-0.4058val_corr=0.4026\n",
      "[36/200] train_loss=2044123.7451 | val_loss=1876646.9536 val_rmse=1367.7784 val_r2=-0.4042val_corr=0.4009\n",
      "[37/200] train_loss=2042927.8295 | val_loss=1875169.7577 val_rmse=1367.5730 val_r2=-0.4028val_corr=0.3821\n",
      "[38/200] train_loss=2041808.7697 | val_loss=1873724.4639 val_rmse=1365.0454 val_r2=-0.4014val_corr=0.3899\n",
      "[39/200] train_loss=2040691.4742 | val_loss=1872187.9253 val_rmse=1362.3960 val_r2=-0.3998val_corr=0.4030\n",
      "[40/200] train_loss=2039588.5588 | val_loss=1870646.9330 val_rmse=1365.7389 val_r2=-0.3983val_corr=0.4258\n",
      "[41/200] train_loss=2038479.4445 | val_loss=1869199.7139 val_rmse=1365.1229 val_r2=-0.3968val_corr=0.4352\n",
      "[42/200] train_loss=2037336.9430 | val_loss=1867513.3814 val_rmse=1363.7542 val_r2=-0.3952val_corr=0.4144\n",
      "[43/200] train_loss=2036146.5312 | val_loss=1866043.0361 val_rmse=1365.3909 val_r2=-0.3937val_corr=0.4369\n",
      "[44/200] train_loss=2034977.7508 | val_loss=1864416.3299 val_rmse=1364.7757 val_r2=-0.3922val_corr=0.4024\n",
      "[45/200] train_loss=2033834.2527 | val_loss=1862871.9879 val_rmse=1360.2026 val_r2=-0.3907val_corr=0.4311\n",
      "[46/200] train_loss=2032751.9486 | val_loss=1861769.2358 val_rmse=1363.7870 val_r2=-0.3896val_corr=0.4472\n",
      "[47/200] train_loss=2031765.4888 | val_loss=1860097.7990 val_rmse=1361.4050 val_r2=-0.3880val_corr=0.4257\n",
      "[48/200] train_loss=2030675.2473 | val_loss=1858617.4871 val_rmse=1361.1972 val_r2=-0.3865val_corr=0.4436\n",
      "[49/200] train_loss=2029585.2262 | val_loss=1857179.0928 val_rmse=1361.1406 val_r2=-0.3852val_corr=0.4292\n",
      "[50/200] train_loss=2028617.9314 | val_loss=1855815.6856 val_rmse=1358.5635 val_r2=-0.3838val_corr=0.4291\n",
      "[51/200] train_loss=2027606.2303 | val_loss=1854585.5193 val_rmse=1359.6270 val_r2=-0.3825val_corr=0.4107\n",
      "[52/200] train_loss=2026655.0432 | val_loss=1853255.7784 val_rmse=1358.0732 val_r2=-0.3811val_corr=0.4321\n",
      "[53/200] train_loss=2025769.0519 | val_loss=1852004.5406 val_rmse=1356.2911 val_r2=-0.3800val_corr=0.3847\n",
      "[54/200] train_loss=2024747.1500 | val_loss=1850748.5851 val_rmse=1358.0293 val_r2=-0.3786val_corr=0.4442\n",
      "[55/200] train_loss=2023764.8929 | val_loss=1849373.6443 val_rmse=1357.4305 val_r2=-0.3774val_corr=0.3881\n",
      "[56/200] train_loss=2022743.7149 | val_loss=1848030.2706 val_rmse=1357.6765 val_r2=-0.3760val_corr=0.4384\n",
      "[57/200] train_loss=2021809.0319 | val_loss=1846904.0528 val_rmse=1357.0640 val_r2=-0.3748val_corr=0.4607\n",
      "[58/200] train_loss=2020789.2063 | val_loss=1845302.4485 val_rmse=1355.6224 val_r2=-0.3735val_corr=0.3918\n",
      "[59/200] train_loss=2019900.7325 | val_loss=1844385.7474 val_rmse=1354.5250 val_r2=-0.3723val_corr=0.4545\n",
      "[60/200] train_loss=2018998.9938 | val_loss=1843121.8196 val_rmse=1355.3955 val_r2=-0.3711val_corr=0.4585\n",
      "[61/200] train_loss=2018015.6306 | val_loss=1841818.2577 val_rmse=1350.0149 val_r2=-0.3699val_corr=0.4520\n",
      "[62/200] train_loss=2017099.5743 | val_loss=1840442.9908 val_rmse=1350.7289 val_r2=-0.3686val_corr=0.4390\n",
      "[63/200] train_loss=2015927.7298 | val_loss=1838770.9845 val_rmse=1352.4154 val_r2=-0.3670val_corr=0.4148\n",
      "[64/200] train_loss=2014758.6183 | val_loss=1837309.3995 val_rmse=1352.8482 val_r2=-0.3656val_corr=0.4128\n",
      "[65/200] train_loss=2013778.3831 | val_loss=1836112.4742 val_rmse=1352.2636 val_r2=-0.3643val_corr=0.4399\n",
      "[66/200] train_loss=2012821.5011 | val_loss=1834847.4253 val_rmse=1351.2012 val_r2=-0.3631val_corr=0.4435\n",
      "[67/200] train_loss=2011936.6637 | val_loss=1833674.2268 val_rmse=1351.9538 val_r2=-0.3621val_corr=0.4160\n",
      "[68/200] train_loss=2011131.1504 | val_loss=1832876.5206 val_rmse=1351.5967 val_r2=-0.3611val_corr=0.4300\n",
      "[69/200] train_loss=2010378.4391 | val_loss=1831574.3766 val_rmse=1347.0549 val_r2=-0.3598val_corr=0.4304\n",
      "[70/200] train_loss=2009586.0600 | val_loss=1830480.1237 val_rmse=1351.4564 val_r2=-0.3588val_corr=0.4284\n",
      "[71/200] train_loss=2008739.8046 | val_loss=1829370.1289 val_rmse=1350.6539 val_r2=-0.3577val_corr=0.4223\n",
      "[72/200] train_loss=2007783.6358 | val_loss=1828044.9626 val_rmse=1347.1612 val_r2=-0.3563val_corr=0.4540\n",
      "[73/200] train_loss=2006872.2975 | val_loss=1826783.0722 val_rmse=1348.3813 val_r2=-0.3552val_corr=0.4278\n",
      "[74/200] train_loss=2006021.6683 | val_loss=1825582.6959 val_rmse=1348.1765 val_r2=-0.3539val_corr=0.4313\n",
      "[75/200] train_loss=2005015.7383 | val_loss=1824231.1843 val_rmse=1348.2576 val_r2=-0.3527val_corr=0.4420\n",
      "[76/200] train_loss=2004028.4383 | val_loss=1822980.5258 val_rmse=1347.4554 val_r2=-0.3514val_corr=0.4425\n",
      "[77/200] train_loss=2002975.6691 | val_loss=1821333.6121 val_rmse=1348.4155 val_r2=-0.3498val_corr=0.4313\n",
      "[78/200] train_loss=2001803.8746 | val_loss=1820001.5219 val_rmse=1346.3089 val_r2=-0.3483val_corr=0.4322\n",
      "[79/200] train_loss=2000998.3619 | val_loss=1819211.6173 val_rmse=1345.8029 val_r2=-0.3475val_corr=0.4273\n",
      "[80/200] train_loss=2000186.0918 | val_loss=1817926.4948 val_rmse=1344.6324 val_r2=-0.3461val_corr=0.4285\n",
      "[81/200] train_loss=1999269.4455 | val_loss=1816507.5934 val_rmse=1342.2961 val_r2=-0.3448val_corr=0.4355\n",
      "[82/200] train_loss=1998233.7156 | val_loss=1815333.7521 val_rmse=1342.6101 val_r2=-0.3435val_corr=0.4242\n",
      "[83/200] train_loss=1997413.5349 | val_loss=1814430.7848 val_rmse=1344.7497 val_r2=-0.3428val_corr=0.4437\n",
      "[84/200] train_loss=1996742.7366 | val_loss=1813260.7448 val_rmse=1345.5767 val_r2=-0.3417val_corr=0.4331\n",
      "[85/200] train_loss=1995894.8180 | val_loss=1812208.7526 val_rmse=1343.6338 val_r2=-0.3406val_corr=0.4577\n",
      "[86/200] train_loss=1995051.0557 | val_loss=1811124.5464 val_rmse=1343.3258 val_r2=-0.3395val_corr=0.4250\n",
      "[87/200] train_loss=1993992.7235 | val_loss=1809344.7332 val_rmse=1341.7316 val_r2=-0.3377val_corr=0.4406\n",
      "[88/200] train_loss=1992952.9783 | val_loss=1808221.8260 val_rmse=1342.8000 val_r2=-0.3365val_corr=0.4530\n",
      "[89/200] train_loss=1991959.2913 | val_loss=1806947.4575 val_rmse=1341.4348 val_r2=-0.3352val_corr=0.4250\n",
      "[90/200] train_loss=1991009.8776 | val_loss=1805607.0477 val_rmse=1341.3544 val_r2=-0.3341val_corr=0.4378\n",
      "[91/200] train_loss=1990233.1923 | val_loss=1804537.2990 val_rmse=1341.6188 val_r2=-0.3331val_corr=0.4431\n",
      "[92/200] train_loss=1989214.3071 | val_loss=1803174.1740 val_rmse=1336.7335 val_r2=-0.3319val_corr=0.4244\n",
      "[93/200] train_loss=1988333.5030 | val_loss=1802020.9330 val_rmse=1340.2819 val_r2=-0.3306val_corr=0.4531\n",
      "[94/200] train_loss=1987371.4598 | val_loss=1800729.2603 val_rmse=1336.7050 val_r2=-0.3296val_corr=0.4319\n",
      "[95/200] train_loss=1986266.7872 | val_loss=1799070.5180 val_rmse=1338.5545 val_r2=-0.3276val_corr=0.4420\n",
      "[96/200] train_loss=1985304.8609 | val_loss=1797950.5232 val_rmse=1339.8657 val_r2=-0.3266val_corr=0.4548\n",
      "[97/200] train_loss=1984355.7875 | val_loss=1797126.8763 val_rmse=1337.9927 val_r2=-0.3259val_corr=0.4675\n",
      "[98/200] train_loss=1983456.2467 | val_loss=1795679.2668 val_rmse=1338.4042 val_r2=-0.3247val_corr=0.4672\n",
      "[99/200] train_loss=1982393.3207 | val_loss=1794613.3647 val_rmse=1337.3545 val_r2=-0.3233val_corr=0.4544\n",
      "[100/200] train_loss=1981488.1285 | val_loss=1793832.5722 val_rmse=1337.1621 val_r2=-0.3231val_corr=0.4605\n",
      "[101/200] train_loss=1980519.2607 | val_loss=1793494.3093 val_rmse=1337.6627 val_r2=-0.3223val_corr=0.4564\n",
      "[102/200] train_loss=1979593.5563 | val_loss=1792966.4227 val_rmse=1336.0233 val_r2=-0.3222val_corr=0.4707\n",
      "[103/200] train_loss=1978684.6473 | val_loss=1791325.2345 val_rmse=1335.7809 val_r2=-0.3202val_corr=0.4590\n",
      "[104/200] train_loss=1977622.6899 | val_loss=1790185.0825 val_rmse=1336.4897 val_r2=-0.3189val_corr=0.4434\n",
      "[105/200] train_loss=1976788.2374 | val_loss=1789283.7990 val_rmse=1334.9258 val_r2=-0.3188val_corr=0.4600\n",
      "[106/200] train_loss=1975986.7975 | val_loss=1787777.9948 val_rmse=1334.9740 val_r2=-0.3178val_corr=0.4756\n",
      "[107/200] train_loss=1975287.5301 | val_loss=1785671.1546 val_rmse=1329.0225 val_r2=-0.3140val_corr=0.4531\n",
      "[108/200] train_loss=1974487.4053 | val_loss=1785338.8376 val_rmse=1334.1754 val_r2=-0.3141val_corr=0.4739\n",
      "[109/200] train_loss=1973844.4707 | val_loss=1783819.9845 val_rmse=1330.1045 val_r2=-0.3124val_corr=0.4518\n",
      "[110/200] train_loss=1973006.5403 | val_loss=1783051.2010 val_rmse=1331.6082 val_r2=-0.3115val_corr=0.4633\n",
      "[111/200] train_loss=1972174.6104 | val_loss=1781811.9407 val_rmse=1331.3412 val_r2=-0.3102val_corr=0.4461\n",
      "[112/200] train_loss=1971162.4130 | val_loss=1780393.6740 val_rmse=1332.9847 val_r2=-0.3091val_corr=0.4489\n",
      "[113/200] train_loss=1970114.7524 | val_loss=1779245.7835 val_rmse=1329.5438 val_r2=-0.3078val_corr=0.4587\n",
      "[114/200] train_loss=1969231.5180 | val_loss=1778142.5412 val_rmse=1329.0456 val_r2=-0.3066val_corr=0.4538\n",
      "[115/200] train_loss=1968255.7028 | val_loss=1776862.2320 val_rmse=1331.0078 val_r2=-0.3053val_corr=0.4425\n",
      "[116/200] train_loss=1967430.8639 | val_loss=1775688.8144 val_rmse=1331.0052 val_r2=-0.3041val_corr=0.4505\n",
      "[117/200] train_loss=1966350.2699 | val_loss=1774229.9536 val_rmse=1329.9477 val_r2=-0.3029val_corr=0.4501\n",
      "[118/200] train_loss=1965259.9759 | val_loss=1773173.6649 val_rmse=1330.1527 val_r2=-0.3023val_corr=0.4714\n",
      "[119/200] train_loss=1964329.5001 | val_loss=1771609.8763 val_rmse=1327.1681 val_r2=-0.3002val_corr=0.4519\n",
      "[120/200] train_loss=1963144.0219 | val_loss=1769960.1198 val_rmse=1328.1945 val_r2=-0.2988val_corr=0.4516\n",
      "[121/200] train_loss=1961616.6518 | val_loss=1767728.0077 val_rmse=1324.8909 val_r2=-0.2965val_corr=0.4563\n",
      "[122/200] train_loss=1960233.1251 | val_loss=1766214.3570 val_rmse=1326.8146 val_r2=-0.2951val_corr=0.4851\n",
      "[123/200] train_loss=1958966.5903 | val_loss=1764444.3505 val_rmse=1326.5681 val_r2=-0.2934val_corr=0.4544\n",
      "[124/200] train_loss=1957785.8491 | val_loss=1762692.8376 val_rmse=1326.5591 val_r2=-0.2917val_corr=0.4451\n",
      "[125/200] train_loss=1956470.2538 | val_loss=1760737.7938 val_rmse=1324.4371 val_r2=-0.2898val_corr=0.4645\n",
      "[126/200] train_loss=1955106.9811 | val_loss=1759547.1186 val_rmse=1320.3598 val_r2=-0.2885val_corr=0.4696\n",
      "[127/200] train_loss=1953727.1161 | val_loss=1758046.2706 val_rmse=1321.7603 val_r2=-0.2873val_corr=0.4655\n",
      "[128/200] train_loss=1952494.1656 | val_loss=1755633.7371 val_rmse=1321.6159 val_r2=-0.2849val_corr=0.4659\n",
      "[129/200] train_loss=1951056.9003 | val_loss=1754204.7693 val_rmse=1323.0281 val_r2=-0.2838val_corr=0.4744\n",
      "[130/200] train_loss=1949771.4862 | val_loss=1752375.4665 val_rmse=1321.7595 val_r2=-0.2822val_corr=0.4676\n",
      "[131/200] train_loss=1948399.6423 | val_loss=1751249.8802 val_rmse=1321.5570 val_r2=-0.2816val_corr=0.4621\n",
      "[132/200] train_loss=1947095.2281 | val_loss=1749620.6727 val_rmse=1320.4903 val_r2=-0.2801val_corr=0.4608\n",
      "[133/200] train_loss=1945860.9328 | val_loss=1747730.1727 val_rmse=1320.0778 val_r2=-0.2779val_corr=0.4809\n",
      "[134/200] train_loss=1944571.0802 | val_loss=1745086.2874 val_rmse=1318.8327 val_r2=-0.2751val_corr=0.4601\n",
      "[135/200] train_loss=1943517.1673 | val_loss=1744134.1753 val_rmse=1317.1836 val_r2=-0.2739val_corr=0.4702\n",
      "[136/200] train_loss=1942556.5235 | val_loss=1742924.8698 val_rmse=1317.1567 val_r2=-0.2729val_corr=0.4738\n",
      "[137/200] train_loss=1941336.5349 | val_loss=1740826.3351 val_rmse=1313.7471 val_r2=-0.2708val_corr=0.4649\n",
      "[138/200] train_loss=1940022.9815 | val_loss=1740169.3866 val_rmse=1315.4057 val_r2=-0.2703val_corr=0.4806\n",
      "[139/200] train_loss=1938691.0552 | val_loss=1737814.2216 val_rmse=1314.8718 val_r2=-0.2677val_corr=0.4665\n",
      "[140/200] train_loss=1937334.1996 | val_loss=1736123.3428 val_rmse=1313.8451 val_r2=-0.2666val_corr=0.4725\n",
      "[141/200] train_loss=1935938.2320 | val_loss=1734572.5863 val_rmse=1314.4390 val_r2=-0.2646val_corr=0.4752\n",
      "[142/200] train_loss=1934771.8455 | val_loss=1732540.5683 val_rmse=1313.8484 val_r2=-0.2630val_corr=0.4714\n",
      "[143/200] train_loss=1933322.4749 | val_loss=1731172.6753 val_rmse=1308.4813 val_r2=-0.2614val_corr=0.4670\n",
      "[144/200] train_loss=1932225.0183 | val_loss=1729538.5129 val_rmse=1311.6209 val_r2=-0.2599val_corr=0.4711\n",
      "[145/200] train_loss=1930847.9879 | val_loss=1728040.4278 val_rmse=1312.5970 val_r2=-0.2592val_corr=0.4777\n",
      "[146/200] train_loss=1929594.7432 | val_loss=1726259.3969 val_rmse=1311.5697 val_r2=-0.2571val_corr=0.4715\n",
      "[147/200] train_loss=1928386.5130 | val_loss=1724429.9601 val_rmse=1310.7416 val_r2=-0.2552val_corr=0.4703\n",
      "[148/200] train_loss=1927114.0426 | val_loss=1723347.7242 val_rmse=1311.3414 val_r2=-0.2543val_corr=0.4711\n",
      "[149/200] train_loss=1925848.0772 | val_loss=1721683.5026 val_rmse=1309.7489 val_r2=-0.2524val_corr=0.4718\n",
      "[150/200] train_loss=1924555.3572 | val_loss=1719636.0709 val_rmse=1309.3804 val_r2=-0.2505val_corr=0.4682\n",
      "[151/200] train_loss=1923399.4272 | val_loss=1718666.7811 val_rmse=1305.3392 val_r2=-0.2497val_corr=0.4787\n",
      "[152/200] train_loss=1922402.4057 | val_loss=1717688.4201 val_rmse=1306.5073 val_r2=-0.2482val_corr=0.4741\n",
      "[153/200] train_loss=1921186.6604 | val_loss=1716304.6224 val_rmse=1307.4699 val_r2=-0.2481val_corr=0.4818\n",
      "[154/200] train_loss=1920050.2637 | val_loss=1714122.7680 val_rmse=1305.0059 val_r2=-0.2452val_corr=0.4682\n",
      "[155/200] train_loss=1918821.2391 | val_loss=1712565.2448 val_rmse=1305.7720 val_r2=-0.2439val_corr=0.4687\n",
      "[156/200] train_loss=1917634.0385 | val_loss=1710595.9974 val_rmse=1304.0000 val_r2=-0.2420val_corr=0.4744\n",
      "[157/200] train_loss=1916289.8775 | val_loss=1709280.4923 val_rmse=1305.7364 val_r2=-0.2402val_corr=0.4601\n",
      "[158/200] train_loss=1915223.1773 | val_loss=1710231.0677 val_rmse=1302.8566 val_r2=-0.2425val_corr=0.4747\n",
      "[159/200] train_loss=1914199.1998 | val_loss=1706348.2268 val_rmse=1303.0443 val_r2=-0.2377val_corr=0.4723\n",
      "[160/200] train_loss=1913244.6497 | val_loss=1705186.8273 val_rmse=1299.8038 val_r2=-0.2374val_corr=0.4765\n",
      "[161/200] train_loss=1912201.4945 | val_loss=1705004.8389 val_rmse=1303.2691 val_r2=-0.2385val_corr=0.4779\n",
      "[162/200] train_loss=1911100.8746 | val_loss=1701841.9072 val_rmse=1300.8893 val_r2=-0.2337val_corr=0.4734\n",
      "[163/200] train_loss=1910278.5571 | val_loss=1701895.6546 val_rmse=1303.3396 val_r2=-0.2379val_corr=0.4731\n",
      "[164/200] train_loss=1909336.4194 | val_loss=1699835.1662 val_rmse=1300.7330 val_r2=-0.2317val_corr=0.4752\n",
      "[165/200] train_loss=1908163.2254 | val_loss=1701035.1959 val_rmse=1301.0989 val_r2=-0.2331val_corr=0.4900\n",
      "[166/200] train_loss=1907094.8340 | val_loss=1698063.8595 val_rmse=1300.4014 val_r2=-0.2300val_corr=0.4820\n",
      "[167/200] train_loss=1906029.8885 | val_loss=1695052.3235 val_rmse=1297.5648 val_r2=-0.2277val_corr=0.4767\n",
      "[168/200] train_loss=1905084.6770 | val_loss=1696853.4794 val_rmse=1300.3196 val_r2=-0.2310val_corr=0.4841\n",
      "[169/200] train_loss=1904143.5981 | val_loss=1695856.6263 val_rmse=1299.2995 val_r2=-0.2322val_corr=0.4814\n",
      "[170/200] train_loss=1903041.0502 | val_loss=1693456.0464 val_rmse=1297.1778 val_r2=-0.2265val_corr=0.4859\n",
      "[171/200] train_loss=1901924.0787 | val_loss=1693973.1026 val_rmse=1295.7584 val_r2=-0.2303val_corr=0.4932\n",
      "[172/200] train_loss=1900826.2421 | val_loss=1691985.3776 val_rmse=1298.4063 val_r2=-0.2271val_corr=0.4903\n",
      "[173/200] train_loss=1899719.1305 | val_loss=1689871.6405 val_rmse=1295.4794 val_r2=-0.2219val_corr=0.4824\n",
      "[174/200] train_loss=1898518.1254 | val_loss=1688369.7113 val_rmse=1295.2879 val_r2=-0.2230val_corr=0.4853\n",
      "[175/200] train_loss=1897332.1604 | val_loss=1688910.2088 val_rmse=1295.7941 val_r2=-0.2268val_corr=0.4773\n",
      "[176/200] train_loss=1896270.8792 | val_loss=1686400.5931 val_rmse=1292.9806 val_r2=-0.2191val_corr=0.4852\n",
      "[177/200] train_loss=1895204.5198 | val_loss=1685948.7990 val_rmse=1295.8261 val_r2=-0.2240val_corr=0.4805\n",
      "[178/200] train_loss=1894104.0361 | val_loss=1682951.8557 val_rmse=1295.0848 val_r2=-0.2146val_corr=0.4884\n",
      "[179/200] train_loss=1892990.9182 | val_loss=1681977.5979 val_rmse=1294.2600 val_r2=-0.2178val_corr=0.4842\n",
      "[180/200] train_loss=1891919.1352 | val_loss=1680897.4433 val_rmse=1294.6738 val_r2=-0.2150val_corr=0.4789\n",
      "[181/200] train_loss=1890938.6234 | val_loss=1680103.4530 val_rmse=1287.9299 val_r2=-0.2180val_corr=0.4818\n",
      "[182/200] train_loss=1890017.1336 | val_loss=1679021.2461 val_rmse=1293.2214 val_r2=-0.2166val_corr=0.4847\n",
      "[183/200] train_loss=1888894.5831 | val_loss=1677808.1701 val_rmse=1294.2753 val_r2=-0.2175val_corr=0.4823\n",
      "[184/200] train_loss=1888120.5918 | val_loss=1679025.7784 val_rmse=1291.9605 val_r2=-0.2191val_corr=0.5037\n",
      "[185/200] train_loss=1887132.9451 | val_loss=1677349.1443 val_rmse=1292.9676 val_r2=-0.2182val_corr=0.5166\n",
      "[186/200] train_loss=1886058.6189 | val_loss=1673047.5387 val_rmse=1291.4110 val_r2=-0.2132val_corr=0.5013\n",
      "[187/200] train_loss=1885163.7098 | val_loss=1673661.0567 val_rmse=1291.5363 val_r2=-0.2130val_corr=0.5124\n",
      "[188/200] train_loss=1884087.2111 | val_loss=1672507.0232 val_rmse=1291.7168 val_r2=-0.2115val_corr=0.5122\n",
      "[189/200] train_loss=1883120.9418 | val_loss=1671239.6772 val_rmse=1287.9541 val_r2=-0.2119val_corr=0.5121\n",
      "[190/200] train_loss=1882157.1337 | val_loss=1670387.9601 val_rmse=1288.9297 val_r2=-0.2070val_corr=0.5159\n",
      "[191/200] train_loss=1881028.2090 | val_loss=1668604.7062 val_rmse=1288.6945 val_r2=-0.2075val_corr=0.5121\n",
      "[192/200] train_loss=1879770.4544 | val_loss=1666767.2316 val_rmse=1285.6557 val_r2=-0.2020val_corr=0.5114\n",
      "[193/200] train_loss=1878856.9462 | val_loss=1667172.9008 val_rmse=1289.6585 val_r2=-0.2065val_corr=0.5094\n",
      "[194/200] train_loss=1877919.9667 | val_loss=1664755.0232 val_rmse=1287.1735 val_r2=-0.2034val_corr=0.5089\n",
      "[195/200] train_loss=1876904.4514 | val_loss=1664596.0361 val_rmse=1283.2742 val_r2=-0.2045val_corr=0.5071\n",
      "[196/200] train_loss=1875939.9873 | val_loss=1662707.7268 val_rmse=1286.7486 val_r2=-0.2037val_corr=0.5113\n",
      "[197/200] train_loss=1874743.7102 | val_loss=1662042.5644 val_rmse=1286.0281 val_r2=-0.2018val_corr=0.5039\n",
      "[198/200] train_loss=1873640.6500 | val_loss=1660045.0722 val_rmse=1286.5448 val_r2=-0.2024val_corr=0.5109\n",
      "[199/200] train_loss=1872679.9776 | val_loss=1658867.5103 val_rmse=1281.4987 val_r2=-0.1951val_corr=0.5097\n",
      "[200/200] train_loss=1871777.5068 | val_loss=1657571.7191 val_rmse=1285.3574 val_r2=-0.1986val_corr=0.5090\n",
      "Restored best model from epoch 200 (val_loss=1657571.7191)\n"
     ]
    }
   ],
   "source": [
    "# モデル作成・最適化手法の決定・学習実行・保存\n",
    "\n",
    "# 例: train_loader, val_loader が既にある想定\n",
    "model = Seq2SeqLSTM(\n",
    "    in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "    enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "    enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "    bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "    bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "    head_activation=cfg[\"head_activation\"]\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = 0\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "best_opt_state = None\n",
    "\n",
    "patience = cfg[\"patience\"]\n",
    "min_delta = 1e-4\n",
    "\n",
    "for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "    # ---- 1. 学習 ----\n",
    "    train_loss = train_one_epoch(model, trainLoader, optimizer)\n",
    "\n",
    "    # ---- 2. 検証 ----\n",
    "    val_metrics = evaluate(model, valLoader)\n",
    "    val_loss = float(val_metrics[\"loss\"])\n",
    "\n",
    "    # ---- 3. ログ出力 ----\n",
    "    if epoch % cfg[\"print_every\"] == 0:\n",
    "        print(f\"[{epoch}/{cfg['epochs']}] \"\n",
    "              f\"train_loss={train_loss:.4f} | \"\n",
    "              f\"val_loss={val_loss:.4f} \"\n",
    "              f\"val_rmse={val_metrics['rmse']:.4f} \"\n",
    "              f\"val_r2={val_metrics['r2']:.4f}\"\n",
    "              f\"val_corr={val_metrics['corr']:.4f}\")\n",
    "\n",
    "    # ---- 4. 改善チェック ----\n",
    "    if best_val - val_loss > min_delta:\n",
    "        best_val = val_loss\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # ★ モデル重みをcloneして保持\n",
    "        best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        # ★ Optimizerの状態もcloneして保持（必要に応じて）\n",
    "        best_opt_state = {\n",
    "            \"state\": {\n",
    "                k: {kk: (vv.detach().clone() if torch.is_tensor(vv) else vv)\n",
    "                    for kk, vv in v.items()}\n",
    "                for k, v in optimizer.state_dict()[\"state\"].items()\n",
    "            },\n",
    "            \"param_groups\": [dict(g) for g in optimizer.state_dict()[\"param_groups\"]],\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # ---- 5. Early Stopping 発動 ----\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch} \"\n",
    "              f\"(best epoch={best_epoch}, val_loss={best_val:.4f})\")\n",
    "        break\n",
    "\n",
    "# ---- 6. 学習終了後にベストモデルを復元 ----\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    if best_opt_state is not None:\n",
    "        optimizer.load_state_dict(best_opt_state)\n",
    "    print(f\"Restored best model from epoch {best_epoch} (val_loss={best_val:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f37f3-78f5-4574-9119-8365b17fc873",
   "metadata": {},
   "source": [
    "# テスト・モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60745e49-ab66-4d50-94ae-2a6c7bb6753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inverse_standardize_y_by_index(y_std, mean, std, y_pos):\n",
    "    \"\"\"\n",
    "    y_std:  標準化スケールの出力テンソル [B, T, Fo]\n",
    "    mean, std: pandas.Series（学習時にfitしたもの。index=列名）\n",
    "    y_pos: 出力列の「列番号（位置）」リスト（例: [Fe+Fd, Fe+Fd+1, ...]）\n",
    "    return: 元スケールの y [B, T, Fo]\n",
    "    \"\"\"\n",
    "    m = torch.tensor(mean.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    s = torch.tensor(std.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    return y_std * s + m\n",
    "\n",
    "\n",
    "def masked_corr(pred, target, mask, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    マスク付きピアソン相関係数（バッチ平均）\n",
    "    pred/target: [B, T, Fo], mask: [B, T, 1]（1=有効, 0=無効）\n",
    "    返り値: スカラー（バッチ平均の相関）\n",
    "    \"\"\"\n",
    "    # 有効点数（サンプルごと）\n",
    "    valid = mask.sum(dim=(1, 2)).clamp_min(1.0)  # [B]\n",
    "\n",
    "    # 平均（サンプルごと）\n",
    "    mean_p = (pred * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "    mean_t = (target * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "\n",
    "    # 偏差\n",
    "    dp = (pred - mean_p) * mask\n",
    "    dt = (target - mean_t) * mask\n",
    "\n",
    "    # 共分散・分散（サンプルごと）\n",
    "    cov = dp.mul(dt).sum(dim=(1, 2)) / valid        # [B]\n",
    "    var_p = dp.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "    var_t = dt.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_p * var_t) + eps)  # [B]\n",
    "    return corr.mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale_by_index(model, loader, mean, std, data_columns, y_pos):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 厳密集計用\n",
    "    total_sse = 0.0   # 全有効点での誤差二乗和\n",
    "    total_cnt = 0.0   # 全有効点数（マスク=1の総数）\n",
    "    total_r2  = 0.0   # R² のバッチ加重平均用\n",
    "    total_corr = 0.0  # 相関R のバッチ加重平均用\n",
    "    n = 0             # サンプル数（バッチ内のBの合計）\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 3:\n",
    "            enc_x, dec_x, y_std = batch\n",
    "            mask = torch.ones_like(y_std[..., :1])\n",
    "        elif len(batch) == 4:\n",
    "            enc_x, dec_x, y_std, mask = batch\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected batch format\")\n",
    "\n",
    "        # 統一デバイス・dtype\n",
    "        enc_x = enc_x.to(device=device, dtype=torch.float32)\n",
    "        dec_x = dec_x.to(device=device, dtype=torch.float32)\n",
    "        y_std = y_std.to(device=device, dtype=torch.float32)\n",
    "        mask  = mask.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # 予測（標準化スケール）\n",
    "        yhat_std = model(enc_x, dec_x)\n",
    "\n",
    "        # 出力だけ逆標準化\n",
    "        yhat = inverse_standardize_y_by_index(yhat_std, mean, std, y_pos)\n",
    "        y    = inverse_standardize_y_by_index(y_std,     mean, std, y_pos)\n",
    "\n",
    "        # 厳密RMSE用：SSEと有効点数を直接合算\n",
    "        sse_batch = ((yhat - y) ** 2 * mask).sum().item()\n",
    "        cnt_batch = mask.sum().item()\n",
    "        total_sse += sse_batch\n",
    "        total_cnt += max(cnt_batch, 1.0)\n",
    "\n",
    "        # R² と 相関R はサンプル数で加重平均\n",
    "        r2    = masked_r2(yhat, y, mask).item()\n",
    "        corr  = masked_corr(yhat, y, mask).item()\n",
    "        bs = enc_x.size(0)\n",
    "        total_r2   += r2   * bs\n",
    "        total_corr += corr * bs\n",
    "        n += bs\n",
    "\n",
    "    mse  = total_sse / max(total_cnt, 1.0)\n",
    "    rmse = mse ** 0.5\n",
    "    r2   = total_r2   / max(n, 1)\n",
    "    corr = total_corr / max(n, 1)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \"corr\": corr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bff67ec8-34ff-472b-93c9-462f5de34b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = [Fe+Fd] # dataのうち、出力変数の列番号\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48f63051-1ba2-4f24-abbd-838558f226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\Tiral_3\\LSTM_trial_3_6\" # 保存するファイル名の指定\n",
    "\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "    \"cfg\": cfg,\n",
    "    \"epoch\": epoch,\n",
    "    \"val_metrics\": val_metrics,\n",
    "    \"scaler\": {\n",
    "        \"mean\": mean,                  # pandas.Series（index=列名）\n",
    "        \"std\":  std,                   # pandas.Series（index=列名）\n",
    "        \"data_columns\": list(data.columns),  # 学習時の列名順を保存\n",
    "        \"y_pos\": y_pos,                # 出力列の列番号（位置）\n",
    "    }\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c30486-03b7-4dad-b320-72212ee6cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf91fb3-bb8c-4f2b-8c68-b601c3117f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd2dad-52c0-440e-a504-51be466ec84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f0cb6-ee5c-4837-ac5f-3f95d1214c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf888655-67c1-461b-873a-f1a177979125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad25f2-8ac3-4877-b803-0d51ac84e2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669f32f-adbd-4df8-ac7e-c22e709eb691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
