{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43c1174-7a6d-49d4-a1df-5e337d0f452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5230b-91c8-48e1-bfd5-1e3ebd1fbcb8",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f5bfad-192d-47e4-bf85-1eceab945f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ユーザ設定 ======\n",
    "\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_hourlyAve_for_LSTM_trial3.xlsx\"\n",
    "flood_idx_path_train = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_train.xlsx\"\n",
    "flood_idx_path_val = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_val.xlsx\"\n",
    "flood_idx_path_test = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx_test.xlsx\"\n",
    "\n",
    "# 列番号（0始まり）で指定\n",
    "enc_cols   = [5, 3, 4]      # エンコーダ入力の列番号（例：3変数）\n",
    "dec_cols   = [5, 3]  # デコーダ入力の列番号（例：2変数）\n",
    "y_cols      = [4]          # 出力（目的変数）の列番号（例：1変数）\n",
    "\n",
    "Te = 72    # エンコーダのタイムステップ長\n",
    "Td = 240   # デコーダのタイムステップ長\n",
    "\n",
    "batch_size = 16 # ミニバッチサイズ\n",
    "\n",
    "# 洪水区間（1始まり行番号で指定してOK。Python内部で0始まりに直す）\n",
    "df_ranges_train = pd.read_excel(flood_idx_path_train, header=0)\n",
    "flood_ranges_train_1based = [tuple(x) for x in df_ranges_train.to_numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66a7c8d-4770-4d55-8e96-8ec0b8c52632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 読み込み ======\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "# 0-basedに変換（pandasは0-based）\n",
    "flood_ranges_train = [(s-1, e-1) for (s, e) in flood_ranges_train_1based]\n",
    "\n",
    "# 必要列だけ抽出（順番固定）\n",
    "use_cols = enc_cols + dec_cols + y_cols\n",
    "data = df.iloc[:, use_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91c7818-8c54-4ef6-8873-38a2475974e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---平均（train）----\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "CumRain_24h     16.075096\n",
      "Qin(m3/s)       48.531916\n",
      "Tur(ppm)       386.243583\n",
      "dtype: float64\n",
      "----標準偏差（train）----\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "CumRain_24h      26.018061\n",
      "Qin(m3/s)        55.028893\n",
      "Tur(ppm)       1036.826873\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ====== 標準化：train dataから平均・標準偏差を算出 ======\n",
    "\n",
    "flood_data_train_parts = [data.iloc[s:e+1, :] for (s, e) in flood_ranges_train]\n",
    "flood_data_train = pd.concat(flood_data_train_parts, axis=0)\n",
    "\n",
    "mean = flood_data_train.mean(numeric_only=True)\n",
    "std  = flood_data_train.std(numeric_only=True).replace(0, 1.0)\n",
    "data_norm = (data - mean) / std # 全期間のデータを標準化\n",
    "\n",
    "print('---平均（train）----')\n",
    "print(mean)\n",
    "\n",
    "print('----標準偏差（train）----')\n",
    "print(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b3226e-f265-4ddc-abbb-93d8cc539d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 915\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（train） ======\n",
    "samples_train = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_train:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_train.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01144d4b-68d0-4692-813d-69cb60c50bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 194\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（val） ======\n",
    "\n",
    "df_ranges_val = pd.read_excel(flood_idx_path_val, header=0)\n",
    "flood_ranges_val_1based = [tuple(x) for x in df_ranges_val.to_numpy()]\n",
    "flood_ranges_val = [(s-1, e-1) for (s, e) in flood_ranges_val_1based]\n",
    "\n",
    "\n",
    "samples_val = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_val:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_val.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1677019-e74b-4fa3-99a0-61d270ef32aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作成サンプル数: 97\n"
     ]
    }
   ],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（test） ======\n",
    "\n",
    "df_ranges_test = pd.read_excel(flood_idx_path_test, header=0)\n",
    "flood_ranges_test_1based = [tuple(x) for x in df_ranges_test.to_numpy()]\n",
    "flood_ranges_test = [(s-1, e-1) for (s, e) in flood_ranges_test_1based]\n",
    "\n",
    "\n",
    "samples_test = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_test:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_test.append((enc_X, dec_X, y))\n",
    "\n",
    "print(f\"作成サンプル数: {len(samples_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50ea38-9cfe-4875-a77b-a941b99a7958",
   "metadata": {},
   "source": [
    "# pyTorch Dataset / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189e891d-b527-4c1d-8f98-08c91ffd8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, triplets):\n",
    "        self.triplets = triplets  # list of (enc_X, dec_X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triplets[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    enc_seqs, dec_seqs, ys = zip(*batch)\n",
    "    # ここでは全サンプル同一長さ前提（Te/Td固定）なので単純stack\n",
    "    enc_x = torch.stack(enc_seqs, dim=0)  # [B, Te, Fe]\n",
    "    dec_x = torch.stack(dec_seqs, dim=0)  # [B, Td, Fd]\n",
    "    y     = torch.stack(ys,       dim=0)  # [B, Td, Fo]\n",
    "    \n",
    "    # マスク（将来可変長のときに使う）\n",
    "    B, Td, _ = y.shape\n",
    "    mask = torch.ones(B, Td, 1, dtype=torch.float32)\n",
    "    return enc_x, dec_x, y, mask\n",
    "\n",
    "\n",
    "trainDataset = FloodSeq2SeqDataset(samples_train)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valDataset = FloodSeq2SeqDataset(samples_val)\n",
    "valLoader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "testDataset = FloodSeq2SeqDataset(samples_test)\n",
    "testLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55755df-49f9-44b5-8a2e-9ffb4ed74e98",
   "metadata": {},
   "source": [
    "# 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0f4213-343a-4271-a507-6dbf7db8d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    \"\"\"collate_fnの戻り値が (enc,dec,y) か (enc,dec,y,mask) のどちらでも対応\"\"\"\n",
    "    if len(batch) == 3:\n",
    "        enc_x, dec_x, y = batch\n",
    "        mask = torch.ones_like(y[..., :1])  # [B,Td,1]\n",
    "    elif len(batch) == 4:\n",
    "        enc_x, dec_x, y, mask = batch\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected batch format\")\n",
    "    return enc_x.to(device), dec_x.to(device), y.to(device), mask.to(device)\n",
    "\n",
    "def masked_mse(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1] (1=valid, 0=pad)\n",
    "    diff2 = (pred - target) ** 2\n",
    "    diff2 = diff2 * mask\n",
    "    denom = mask.sum(dim=(1,2)).clamp_min(1.0)  # per-sample\n",
    "    per_sample = diff2.sum(dim=(1,2)) / denom\n",
    "    return per_sample.mean()\n",
    "\n",
    "def masked_rmse(pred, target, mask):\n",
    "    return torch.sqrt(masked_mse(pred, target, mask))\n",
    "\n",
    "def masked_r2(pred, target, mask):\n",
    "    # R² = 1 - SSE/SST, マスク版\n",
    "    mean = (target * mask).sum(dim=(1,2), keepdim=True) / mask.sum(dim=(1,2), keepdim=True).clamp_min(1.0)\n",
    "    sse = ((pred - target) ** 2 * mask).sum(dim=(1,2))\n",
    "    sst = ((target - mean) ** 2 * mask).sum(dim=(1,2)).clamp_min(1e-12)\n",
    "    r2  = 1.0 - sse / sst\n",
    "    return r2.mean()\n",
    "\n",
    "def masked_corr(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1]\n",
    "    pred = pred * mask\n",
    "    target = target * mask\n",
    "    valid = mask.sum(dim=(1,2)).clamp_min(1.0)\n",
    "\n",
    "    # 平均\n",
    "    mean_pred = pred.sum(dim=(1,2)) / valid\n",
    "    mean_target = target.sum(dim=(1,2)) / valid\n",
    "\n",
    "    # 偏差\n",
    "    diff_pred = (pred - mean_pred.view(-1,1,1)) * mask\n",
    "    diff_target = (target - mean_target.view(-1,1,1)) * mask\n",
    "\n",
    "    # 共分散と分散\n",
    "    cov = (diff_pred * diff_target).sum(dim=(1,2)) / valid\n",
    "    var_pred = (diff_pred**2).sum(dim=(1,2)) / valid\n",
    "    var_target = (diff_target**2).sum(dim=(1,2)) / valid\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_pred * var_target) + 1e-12)\n",
    "    return corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056610ed-099b-4966-bdaa-1f00b571489d",
   "metadata": {},
   "source": [
    "# 汎用Seq2Seq LSTM（エンコーダ→デコーダ、損失はマスクで集計）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d5b144-c2c3-4f39-8d5d-e61435c5fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateBridge(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoderの(h, c)をDecoder初期状態へ写像するブリッジ。\n",
    "    - 層数/隠れ次元が異なってもOK\n",
    "    - bridge_mode:\n",
    "        - \"zero_pad\":  層合わせ=0埋め or 切り落とし、隠れ次元は線形射影\n",
    "        - \"repeat_top\":層合わせ=最上層の繰り返し/切り落とし、隠れ次元は線形射影\n",
    "        - \"linear_stack\": [B, L_enc, H_enc] -> 線形で [B, L_dec, H_dec] へ（層方向も学習で混合）\n",
    "\n",
    "    - enc_layers: エンコーダの層の深さ\n",
    "    - dec_layers: デコーダの層の深さ\n",
    "    - enc_hidden: エンコーダのノード数\n",
    "    - dec_hidden: デコーダのノード数\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hidden, dec_hidden, mode=\"zero_pad\"):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.enc_hidden = enc_hidden\n",
    "        self.dec_hidden = dec_hidden\n",
    "        self.mode = mode\n",
    "\n",
    "        # 隠れ次元の変換（h/c共用）\n",
    "        if mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            self.proj = nn.Linear(enc_hidden, dec_hidden, bias=True)\n",
    "        elif mode == \"linear_stack\":\n",
    "            # 層方向もまとめて線形変換\n",
    "            self.proj_h = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "            self.proj_c = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bridge mode: {mode}\")\n",
    "\n",
    "    def _match_layers(self, x, how=\"zero_pad\"):\n",
    "        \"\"\"\n",
    "        x: [L_enc, B, H_enc] を層数だけ合わせる（隠れ次元は未変換）\n",
    "        return: [L_dec, B, H_enc]\n",
    "\n",
    "        B: バッチサイズ\n",
    "        \"\"\"\n",
    "        L_enc, B, H = x.shape\n",
    "        L_dec = self.dec_layers\n",
    "\n",
    "        if L_dec == L_enc:\n",
    "            return x\n",
    "\n",
    "        if L_dec < L_enc:\n",
    "            # 上位層を優先して切り落とす（直観的には最上層が一番抽象的）\n",
    "            return x[:L_dec, :, :]\n",
    "\n",
    "        # L_dec > L_enc の場合\n",
    "        pad_count = L_dec - L_enc\n",
    "        if how == \"repeat_top\":\n",
    "            top = x[-1:, :, :].expand(pad_count, B, H)  # 最上層を複製\n",
    "            return torch.cat([x, top], dim=0)\n",
    "        else:  # zero_pad\n",
    "            pad = x.new_zeros(pad_count, B, H)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        \"\"\"\n",
    "        h_enc, c_enc: [L_enc, B, H_enc]\n",
    "        返り値: (h0_dec, c0_dec) それぞれ [L_dec, B, H_dec]\n",
    "        \"\"\"\n",
    "        if self.mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            # 層合わせ（まだ enc_hidden 次元のまま）\n",
    "            h = self._match_layers(h_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            c = self._match_layers(c_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            # 次元射影\n",
    "            L, B, H = h.shape\n",
    "            h = self.proj(h)  # broadcasting: [L,B,H_enc]->[L,B,H_dec]\n",
    "            c = self.proj(c)\n",
    "            return h, c\n",
    "\n",
    "        else:  # linear_stack\n",
    "            # [L_enc,B,H_enc] -> [B, L_enc*H_enc]\n",
    "            L_enc, B, H_enc = h_enc.shape\n",
    "            flat_h = h_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            flat_c = c_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            # 線形写像\n",
    "            out_h = self.proj_h(flat_h)  # [B, L_dec*H_dec]\n",
    "            out_c = self.proj_c(flat_c)\n",
    "            # [L_dec,B,H_dec] に戻す\n",
    "            L_dec, H_dec = self.dec_layers, self.dec_hidden\n",
    "            h = out_h.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            c = out_c.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17bf2a71-0425-4702-96da-5b6232cfa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_enc: int, # エンコーダ入力変数の数\n",
    "        in_dec: int, # デコーダ入力変数の数\n",
    "        out_dim: int, # 出力変数の数\n",
    "        enc_hidden: int = 128,\n",
    "        dec_hidden: int = 128,\n",
    "        enc_layers: int = 2,\n",
    "        dec_layers: int = 3,\n",
    "        bridge_mode: str = \"zero_pad\",  # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "        dropout: float = 0.0, # LSTMの層間ドロップアウト率\n",
    "        bidirectional_enc: bool = False,  # エンコーダのみ双方向にするかどうか（必要ならEncoderを双方向にも）\n",
    "        head_activation=\"relu\", # 活性化関数\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional_enc = bidirectional_enc\n",
    "        enc_dir = 2 if bidirectional_enc else 1\n",
    "        enc_hidden_eff = enc_hidden * enc_dir  # 双方向なら出力次元が倍\n",
    "\n",
    "        self.enc = nn.LSTM(\n",
    "            input_size=in_enc,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if enc_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional_enc\n",
    "        )\n",
    "\n",
    "        self.dec = nn.LSTM(\n",
    "            input_size=in_dec,\n",
    "            hidden_size=dec_hidden,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if dec_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Encoderが双方向のときは、(h_fwd, h_bwd) を結合した次元 enc_hidden_eff を\n",
    "        # Decoder hidden 次元へ写像する必要がある\n",
    "        self.bridge = StateBridge(\n",
    "            enc_layers=enc_layers * enc_dir,\n",
    "            dec_layers=dec_layers,\n",
    "            enc_hidden=enc_hidden,\n",
    "            dec_hidden=dec_hidden,\n",
    "            mode=bridge_mode\n",
    "        ) if (enc_layers != dec_layers or enc_dir != 1 or enc_hidden != dec_hidden or bridge_mode==\"linear_stack\") else None\n",
    "\n",
    "        self.head = nn.Linear(dec_hidden, out_dim) # 全結合層\n",
    "\n",
    "        self.act = {\n",
    "            \"identity\": nn.Identity(),\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "        }[head_activation]\n",
    "\n",
    "    def _extract_final_states(self, out, hc):\n",
    "        \"\"\"\n",
    "        LSTMの出力から (h_T, c_T) を取り出して成形。\n",
    "        双方向Encoderの場合は各層ごとに [fwd, bwd] を層方向に並べる。\n",
    "        \"\"\"\n",
    "        h, c = hc  # [num_layers * num_directions, B, H]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, enc_x, dec_x):\n",
    "        \"\"\"\n",
    "        enc_x: [B, Te, in_enc]\n",
    "        dec_x: [B, Td, in_dec]\n",
    "        return: yhat [B, Td, out_dim]\n",
    "        \"\"\"\n",
    "        _, (h_T, c_T) = self.enc(enc_x)  # h_T,c_T: [L_enc * dir, B, H_enc]\n",
    "\n",
    "        if self.bridge is not None:\n",
    "            h0_dec, c0_dec = self.bridge(h_T, c_T)  # [L_dec, B, H_dec]\n",
    "        else:\n",
    "            # 形・次元が完全一致ならそのまま\n",
    "            h0_dec, c0_dec = h_T, c_T\n",
    "\n",
    "        dec_out, _ = self.dec(dec_x, (h0_dec, c0_dec))  # [B, Td, H_dec]\n",
    "        yhat = self.head(self.act(dec_out))             # [B, Td, out_dim]\n",
    "        return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfbd76-7603-4f15-bd85-82645d0acd76",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fddb4838-b64d-46b4-83bf-eff07d444af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg = {\n",
    "    # Model\n",
    "    \"in_enc\": 3,\n",
    "    \"in_dec\": 2,\n",
    "    \"out_dim\": 1,\n",
    "    \"enc_hidden\": 32,\n",
    "    \"dec_hidden\": 32,\n",
    "    \"enc_layers\": 1,\n",
    "    \"dec_layers\": 1,\n",
    "    \"bridge_mode\": \"zero_pad\",   # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "    \"dropout\": 0.1,\n",
    "    \"bidirectional_enc\": False,\n",
    "    \"head_activation\": \"tanh\", # \"identity\", \"relu\", \"tanh\", \"sigmoid\" など\n",
    "    # Train\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0.0, # L2正規化係数。0なら無効\n",
    "    \"grad_clip\": 1.0, # 勾配クリッピングの閾値。０かNoneなら無効\n",
    "    \"print_every\": 1, # 学習の進捗を何エポックごとに出力するか\n",
    "    \"patience\": 3, # early stopping\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c75568c-0825-4290-bf08-2b81b03840bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数・評価関数の定義\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if cfg[\"grad_clip\"]:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = enc_x.size(0) # バッチサイズ\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return total_loss / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0; total_rmse = 0.0; total_r2 = 0.0; total_corr = 0.0; n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "        rmse = masked_rmse(yhat, y, mask)\n",
    "        r2   = masked_r2(yhat, y, mask)\n",
    "        corr = masked_corr(yhat, y, mask)\n",
    "\n",
    "        bs = enc_x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_rmse += rmse.item() * bs\n",
    "        total_r2   += r2.item() * bs\n",
    "        total_corr += corr.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / max(n,1),\n",
    "        \"rmse\": total_rmse / max(n,1),\n",
    "        \"r2\":   total_r2   / max(n,1),\n",
    "        \"corr\": total_corr / max(n,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e1155d-44ae-4821-be2e-124b8caa544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] train_loss=1.2980 | val_loss=0.8332 val_rmse=0.9111 val_r2=0.3742val_corr=0.8140\n",
      "[2/30] train_loss=0.6388 | val_loss=0.6355 val_rmse=0.7955 val_r2=0.5297val_corr=0.9263\n",
      "[3/30] train_loss=0.3517 | val_loss=0.7432 val_rmse=0.8609 val_r2=0.4448val_corr=0.9063\n",
      "[4/30] train_loss=0.2281 | val_loss=0.5824 val_rmse=0.7613 val_r2=0.5382val_corr=0.8967\n",
      "[5/30] train_loss=0.1670 | val_loss=0.5258 val_rmse=0.7235 val_r2=0.4653val_corr=0.8608\n",
      "[6/30] train_loss=0.1349 | val_loss=0.5605 val_rmse=0.7481 val_r2=0.4799val_corr=0.8700\n",
      "[7/30] train_loss=0.1166 | val_loss=0.5716 val_rmse=0.7545 val_r2=0.4347val_corr=0.8640\n",
      "[8/30] train_loss=0.1036 | val_loss=0.6010 val_rmse=0.7731 val_r2=0.4162val_corr=0.8600\n",
      "Early stopping at epoch 8 (best epoch=5, val_loss=0.5258)\n",
      "Restored best model from epoch 5 (val_loss=0.5258)\n"
     ]
    }
   ],
   "source": [
    "# モデル作成・最適化手法の決定・学習実行・保存\n",
    "\n",
    "# 例: train_loader, val_loader が既にある想定\n",
    "model = Seq2SeqLSTM(\n",
    "    in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "    enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "    enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "    bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "    bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "    head_activation=cfg[\"head_activation\"]\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = 0\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "best_opt_state = None\n",
    "\n",
    "patience = cfg[\"patience\"]\n",
    "min_delta = 1e-4\n",
    "\n",
    "for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "    # ---- 1. 学習 ----\n",
    "    train_loss = train_one_epoch(model, trainLoader, optimizer)\n",
    "\n",
    "    # ---- 2. 検証 ----\n",
    "    val_metrics = evaluate(model, valLoader)\n",
    "    val_loss = float(val_metrics[\"loss\"])\n",
    "\n",
    "    # ---- 3. ログ出力 ----\n",
    "    if epoch % cfg[\"print_every\"] == 0:\n",
    "        print(f\"[{epoch}/{cfg['epochs']}] \"\n",
    "              f\"train_loss={train_loss:.4f} | \"\n",
    "              f\"val_loss={val_loss:.4f} \"\n",
    "              f\"val_rmse={val_metrics['rmse']:.4f} \"\n",
    "              f\"val_r2={val_metrics['r2']:.4f}\"\n",
    "              f\"val_corr={val_metrics['corr']:.4f}\")\n",
    "\n",
    "    # ---- 4. 改善チェック ----\n",
    "    if best_val - val_loss > min_delta:\n",
    "        best_val = val_loss\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # ★ モデル重みをcloneして保持\n",
    "        best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        # ★ Optimizerの状態もcloneして保持（必要に応じて）\n",
    "        best_opt_state = {\n",
    "            \"state\": {\n",
    "                k: {kk: (vv.detach().clone() if torch.is_tensor(vv) else vv)\n",
    "                    for kk, vv in v.items()}\n",
    "                for k, v in optimizer.state_dict()[\"state\"].items()\n",
    "            },\n",
    "            \"param_groups\": [dict(g) for g in optimizer.state_dict()[\"param_groups\"]],\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # ---- 5. Early Stopping 発動 ----\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch} \"\n",
    "              f\"(best epoch={best_epoch}, val_loss={best_val:.4f})\")\n",
    "        break\n",
    "\n",
    "# ---- 6. 学習終了後にベストモデルを復元 ----\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    if best_opt_state is not None:\n",
    "        optimizer.load_state_dict(best_opt_state)\n",
    "    print(f\"Restored best model from epoch {best_epoch} (val_loss={best_val:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f37f3-78f5-4574-9119-8365b17fc873",
   "metadata": {},
   "source": [
    "# テスト・モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60745e49-ab66-4d50-94ae-2a6c7bb6753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inverse_standardize_y_by_index(y_std, mean, std, y_pos):\n",
    "    \"\"\"\n",
    "    y_std:  標準化スケールの出力テンソル [B, T, Fo]\n",
    "    mean, std: pandas.Series（学習時にfitしたもの。index=列名）\n",
    "    y_pos: 出力列の「列番号（位置）」リスト（例: [Fe+Fd, Fe+Fd+1, ...]）\n",
    "    return: 元スケールの y [B, T, Fo]\n",
    "    \"\"\"\n",
    "    m = torch.tensor(mean.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    s = torch.tensor(std.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    return y_std * s + m\n",
    "\n",
    "\n",
    "def masked_corr(pred, target, mask, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    マスク付きピアソン相関係数（バッチ平均）\n",
    "    pred/target: [B, T, Fo], mask: [B, T, 1]（1=有効, 0=無効）\n",
    "    返り値: スカラー（バッチ平均の相関）\n",
    "    \"\"\"\n",
    "    # 有効点数（サンプルごと）\n",
    "    valid = mask.sum(dim=(1, 2)).clamp_min(1.0)  # [B]\n",
    "\n",
    "    # 平均（サンプルごと）\n",
    "    mean_p = (pred * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "    mean_t = (target * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "\n",
    "    # 偏差\n",
    "    dp = (pred - mean_p) * mask\n",
    "    dt = (target - mean_t) * mask\n",
    "\n",
    "    # 共分散・分散（サンプルごと）\n",
    "    cov = dp.mul(dt).sum(dim=(1, 2)) / valid        # [B]\n",
    "    var_p = dp.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "    var_t = dt.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_p * var_t) + eps)  # [B]\n",
    "    return corr.mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale_by_index(model, loader, mean, std, data_columns, y_pos):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 厳密集計用\n",
    "    total_sse = 0.0   # 全有効点での誤差二乗和\n",
    "    total_cnt = 0.0   # 全有効点数（マスク=1の総数）\n",
    "    total_r2  = 0.0   # R² のバッチ加重平均用\n",
    "    total_corr = 0.0  # 相関R のバッチ加重平均用\n",
    "    n = 0             # サンプル数（バッチ内のBの合計）\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 3:\n",
    "            enc_x, dec_x, y_std = batch\n",
    "            mask = torch.ones_like(y_std[..., :1])\n",
    "        elif len(batch) == 4:\n",
    "            enc_x, dec_x, y_std, mask = batch\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected batch format\")\n",
    "\n",
    "        # 統一デバイス・dtype\n",
    "        enc_x = enc_x.to(device=device, dtype=torch.float32)\n",
    "        dec_x = dec_x.to(device=device, dtype=torch.float32)\n",
    "        y_std = y_std.to(device=device, dtype=torch.float32)\n",
    "        mask  = mask.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # 予測（標準化スケール）\n",
    "        yhat_std = model(enc_x, dec_x)\n",
    "\n",
    "        # 出力だけ逆標準化\n",
    "        yhat = inverse_standardize_y_by_index(yhat_std, mean, std, y_pos)\n",
    "        y    = inverse_standardize_y_by_index(y_std,     mean, std, y_pos)\n",
    "\n",
    "        # 厳密RMSE用：SSEと有効点数を直接合算\n",
    "        sse_batch = ((yhat - y) ** 2 * mask).sum().item()\n",
    "        cnt_batch = mask.sum().item()\n",
    "        total_sse += sse_batch\n",
    "        total_cnt += max(cnt_batch, 1.0)\n",
    "\n",
    "        # R² と 相関R はサンプル数で加重平均\n",
    "        r2    = masked_r2(yhat, y, mask).item()\n",
    "        corr  = masked_corr(yhat, y, mask).item()\n",
    "        bs = enc_x.size(0)\n",
    "        total_r2   += r2   * bs\n",
    "        total_corr += corr * bs\n",
    "        n += bs\n",
    "\n",
    "    mse  = total_sse / max(total_cnt, 1.0)\n",
    "    rmse = mse ** 0.5\n",
    "    r2   = total_r2   / max(n, 1)\n",
    "    corr = total_corr / max(n, 1)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \"corr\": corr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff67ec8-34ff-472b-93c9-462f5de34b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 139634.32182130584, 'rmse': 373.6767611469916, 'r2': -1.5821348268961168, 'corr': 0.5695543694741947}\n"
     ]
    }
   ],
   "source": [
    "y_pos = [Fe+Fd] # dataのうち、出力変数の列番号\n",
    "\n",
    "test_metrics = evaluate_original_scale_by_index(model, testLoader, mean, std, data.columns, y_pos)\n",
    "\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48f63051-1ba2-4f24-abbd-838558f226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\Tiral_3\\LSTM_trial_3_5\" # 保存するファイル名の指定\n",
    "\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "    \"cfg\": cfg,\n",
    "    \"epoch\": epoch,\n",
    "    \"val_metrics\": val_metrics,\n",
    "    \"test_metrics\": test_metrics,\n",
    "    \"scaler\": {\n",
    "        \"mean\": mean,                  # pandas.Series（index=列名）\n",
    "        \"std\":  std,                   # pandas.Series（index=列名）\n",
    "        \"data_columns\": list(data.columns),  # 学習時の列名順を保存\n",
    "        \"y_pos\": y_pos,                # 出力列の列番号（位置）\n",
    "    }\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c30486-03b7-4dad-b320-72212ee6cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf91fb3-bb8c-4f2b-8c68-b601c3117f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd2dad-52c0-440e-a504-51be466ec84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f0cb6-ee5c-4837-ac5f-3f95d1214c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf888655-67c1-461b-873a-f1a177979125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad25f2-8ac3-4877-b803-0d51ac84e2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669f32f-adbd-4df8-ac7e-c22e709eb691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
