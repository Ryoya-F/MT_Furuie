{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ff3f52-38bb-4372-8ffd-89514d224512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9be78-83a5-42be-80c2-6e382366af85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332659ca-20af-4399-8460-d0c4516b2eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af639279-66bc-455b-91fc-377f7db00fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e8eaf-71c7-4694-b0b2-da0489a009f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 動作確認用コード（後で消す）\n",
    "data_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_hourlyAve_2019_2025_processed.xlsx\"\n",
    "\n",
    "df = pd.read_excel(data_path, header=0)\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")  # 数値以外は NaN にする\n",
    "all_data = df.to_numpy(dtype=np.float32)\n",
    "\n",
    "print(all_data[1:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577d26a-1f43-4d77-bca6-e24184bc3030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719242c-8481-42ef-b883-941b2e7ef13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認用コード（後で消す）\n",
    "\n",
    "flood_idx_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\Trial_3\\Miwa_flood_idx.xlsx\"\n",
    "flood_idx = pd.read_excel(flood_idx_path, header=0).values.astype('int')\n",
    "\n",
    "print(flood_idx)\n",
    "print(flood_idx[1, 0])\n",
    "print(flood_idx.shape[0])\n",
    "print(flood_idx[2:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004d66c-46cd-46e7-86a2-fc145f8a45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認用コード（後で消す）\n",
    "\n",
    "\n",
    "for i in range(flood_idx.shape[0]):\n",
    "    sIdx = flood_idx[i, 0] - 72 - 1 # pythonはindexの最初が0なので、1を引く\n",
    "    eIdx = flood_idx[i, 1] # pythonは終了インデックスを含まない\n",
    "\n",
    "    if i == 0:\n",
    "        flood_data = all_data[sIdx:eIdx, :]\n",
    "    else:\n",
    "        flood_data_temp = all_data[sIdx:eIdx, :]\n",
    "        flood_data = np.vstack((flood_data, flood_data_temp))\n",
    "\n",
    "    print(sIdx, eIdx)\n",
    "\n",
    "print(flood_data.shape[0])\n",
    "print(flood_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7f619-d599-413e-99e2-9a73b8c7d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(flood_data, axis=0)\n",
    "std = np.std(flood_data, axis=0)\n",
    "\n",
    "std_prms = np.vstack((mean, std))\n",
    "\n",
    "print(std_prms)\n",
    "\n",
    "print(std_prms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b8398-9c37-4586-9bc1-3f644e9ebc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_std = (all_data - mean) / std\n",
    "\n",
    "print(all_data_std[0:10,:])\n",
    "print(all_data_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d03f41-f6c3-4607-b4e0-b8b4c3a8d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std_prm = std_prms[:, [4, 8]]\n",
    "\n",
    "print(std_prms)\n",
    "print(x_std_prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7f31f-c20c-4b37-a00d-d784c7a8c12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b1993-d1fd-4ff3-af6a-fb3310ce59d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30cbaf-6cc1-4cf1-ae34-a885567d60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3],\n",
    "    [1, 3, 5],\n",
    "    [1, 5, 7],\n",
    "    [1, 7, 9]]\n",
    "\n",
    "mean = np.mean(a, axis=0)\n",
    "std = np.std(a, axis=0)\n",
    "\n",
    "standardized = (a - mean) / std\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "print(standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46810d-5e22-4f8a-b466-d3529cd2332f",
   "metadata": {},
   "source": [
    "# 書きかけコード（不採用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6de9e-8a26-4e76-9e2c-f8829650ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1. データセット定義 ====\n",
    "\n",
    "class FloodSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, data_path, flood_idx_path, xCol_1, xCol_2, yCol, x_std_prm_1, x_std_prm_2, y_std_prm, look_back=72, lead_time=240, phase=\"val\"):\n",
    "        '''\n",
    "        data_path: 全期間のデータ含むExcelファイル\n",
    "        flood_idx_path: 対象洪水の開始行番号、終了行番号を格納したExcelファイル\n",
    "        xCol_1: 入力値の列番号（エンコーダ）\n",
    "        xCol_2: 入力値の列番号（デコーダ）\n",
    "        yCol: 出力値の列番号\n",
    "        x_std_prm: 入力値の平均・標準偏差（1行目：平均、2行目：標準偏差）\n",
    "        y_std_prm: 出力値の平均・標準偏差（1行目：平均、2行目：標準偏差）\n",
    "        look_back: 予測のルックバック期間（hour）\n",
    "        lead_time: 予測のリードタイム（hour） \n",
    "        phase: phaseがtrainの時は、標準化パラメータを計算する\n",
    "        '''\n",
    "        # Excelデータ・対象洪水インデックスの読み込み\n",
    "        df = pd.read_excel(data_path, header=0)\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\")  # 数値以外は NaN にする\n",
    "        self.all_data_raw = df.to_numpy(dtype=np.float32)\n",
    "        \n",
    "        self.flood_idx = pd.read_excel(flood_idx_path, header=0).values.astype('int')\n",
    "        \n",
    "        self.xCol_1 = xCol_1\n",
    "        self.xCol_2 = xCol_2\n",
    "        self.yCol = yCol\n",
    "\n",
    "        self.look_back = look_back\n",
    "        self.lead_time = lead_time\n",
    "\n",
    "        if phase == 'train':\n",
    "            # 対象洪水期間のデータをすべて抽出・結合し、標準化パラメータを計算\n",
    "            for i in range(self.flood_idx.shape[0]):\n",
    "                sIdx = self.flood_idx[i, 0] - look_back - 1 # pythonはindexの最初が0なので、1を引く\n",
    "                eIdx = self.flood_idx[i, 1] # pythonは終了インデックスは含まない\n",
    "    \n",
    "                if i == 0:\n",
    "                    flood_all = self.all_data_raw[sIdx:eIdx, :]\n",
    "                else:\n",
    "                    flood_temp = self.all_data_raw[sIdx:eIdx, :]\n",
    "                    flood_all = np.vstack((flood_all, flood_temp))\n",
    "\n",
    "            mean = np.mean(flood_all, axis=0)\n",
    "            std = np.std(flood_all, axis=0)\n",
    "\n",
    "            self.all_data = (self.all_data_raw - mean) / std # 標準化\n",
    "\n",
    "            std_prm = np.vstack((mean, std))\n",
    "\n",
    "            self.x_std_prm_1 = std_prm(:, xCol_1)\n",
    "            self.x_std_prm_2 = std_prm(:, xCol_2)\n",
    "            self.y_std_prm = std_prm(:, yCol)\n",
    "            \n",
    "        else:\n",
    "            self.x_std_prm_1 = x_std_prm_1\n",
    "            self.x_std_prm_2 = x_std_prm_2\n",
    "            self.y_std_prm = y_std_prm\n",
    "            \n",
    "        \n",
    "\n",
    "        # 有効なサンプルインデックスのみを保持\n",
    "        self.valid_indices = []\n",
    "        for idx in self.flood_indices:\n",
    "            sample_start = idx - self.look_back\n",
    "            sample_end = idx + self.forecast_len\n",
    "\n",
    "            if sample_start < 0:\n",
    "                continue\n",
    "            if sample_end > len(self.enc_data) or sample_end > len(self.dec_data) or sample_end > len(self.label_data):\n",
    "                continue\n",
    "            self.valid_indices.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.valid_indices[index]\n",
    "\n",
    "        sample_start = idx - self.look_back\n",
    "        sample_end = idx + self.forecast_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185ddd9-a9c3-4549-9938-3042ac5b836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2. DataLoader作成 ====\n",
    "excel_file = \"timeseries_data.xlsx\"  # 読み込み元のExcel\n",
    "dataset = TimeSeriesDataset(excel_file, look_back=72, forecast_len=240)\n",
    "\n",
    "batch_size = 32\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d4d36-19ee-42e9-8469-baa514b38670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== モデル定義 =====\n",
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_enc, hidden_dec, output_size, num_layers_dec=2):\n",
    "        super().__init__()\n",
    "        # エンコーダ（1層）\n",
    "        self.encoder = nn.LSTM(input_size, hidden_enc, num_layers=1, batch_first=True)\n",
    "        # デコーダ（2層）\n",
    "        self.decoder = nn.LSTM(output_size, hidden_dec, num_layers=num_layers_dec, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dec, output_size)\n",
    "\n",
    "        # 隠れ層の次元が異なる場合、エンコーダ状態をデコーダ用に変換\n",
    "        if hidden_enc != hidden_dec:\n",
    "            self.enc_to_dec_h = nn.Linear(hidden_enc, hidden_dec)\n",
    "            self.enc_to_dec_c = nn.Linear(hidden_enc, hidden_dec)\n",
    "        else:\n",
    "            self.enc_to_dec_h = None\n",
    "            self.enc_to_dec_c = None\n",
    "\n",
    "    def forward(self, src, tgt_len):\n",
    "        \"\"\"\n",
    "        src: (batch, past_seq_len=72, input_size)\n",
    "        tgt_len: 予測する時間ステップ数（240）\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        device = src.device\n",
    "\n",
    "        # --- エンコーダ ---\n",
    "        _, (h, c) = self.encoder(src)  # h, c: (1, batch, hidden_enc)\n",
    "\n",
    "        # --- エンコーダ状態をデコーダ用に変換 ---\n",
    "        if self.enc_to_dec_h:\n",
    "            h = self.enc_to_dec_h(h.transpose(0,1)).transpose(0,1)\n",
    "            c = self.enc_to_dec_c(c.transpose(0,1)).transpose(0,1)\n",
    "\n",
    "        # デコーダの層数に合わせる（上層はゼロ初期化）\n",
    "        num_layers_dec = self.decoder.num_layers\n",
    "        h_dec = torch.zeros(num_layers_dec, batch_size, self.decoder.hidden_size, device=device)\n",
    "        c_dec = torch.zeros(num_layers_dec, batch_size, self.decoder.hidden_size, device=device)\n",
    "        h_dec[0] = h[0]\n",
    "        c_dec[0] = c[0]\n",
    "\n",
    "        # --- デコーダ ---\n",
    "        outputs = []\n",
    "        dec_input = torch.zeros(batch_size, 1, self.fc.out_features, device=device)  # 初期入力0\n",
    "\n",
    "        for _ in range(tgt_len):\n",
    "            out, (h_dec, c_dec) = self.decoder(dec_input, (h_dec, c_dec))\n",
    "            pred = self.fc(out)  # (batch, 1, output_size)\n",
    "            outputs.append(pred)\n",
    "            dec_input = pred  # 次のタイムステップの入力（teacher forcingしない場合）\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, tgt_len, output_size)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751eb017-d7ea-405b-80f2-79128cce8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 使用例 =====\n",
    "batch_size = 16\n",
    "input_size = 10    # 入力特徴数\n",
    "output_size = 1    # 出力特徴数\n",
    "hidden_enc = 64\n",
    "hidden_dec = 64\n",
    "look_back = 72\n",
    "forecast_len = 240\n",
    "\n",
    "model = Seq2SeqLSTM(input_size, hidden_enc, hidden_dec, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ダミーデータ\n",
    "src = torch.randn(batch_size, look_back, input_size)\n",
    "target = torch.randn(batch_size, forecast_len, output_size)\n",
    "\n",
    "# 学習ステップ例\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "pred = model(src, forecast_len)\n",
    "loss = criterion(pred, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf360c7-b504-452a-832f-8a96a2b8bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ループ\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(src, forecast_len)\n",
    "    loss = criterion(pred, target)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e81e08-f05b-4124-b80a-39732e34ea3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd078e0-e90a-4851-8365-bca42df0febd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
