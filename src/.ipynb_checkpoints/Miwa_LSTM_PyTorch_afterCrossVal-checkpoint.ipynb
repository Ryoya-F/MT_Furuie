{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dca737e-9bc0-45e1-941a-a64358a97480",
   "metadata": {},
   "source": [
    "### Cross Validation後にモデルを学習・保存する\n",
    "### テストデータで、モデルの精度を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9091fe2f-c27c-46b6-a766-6166c558b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import os, copy\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937600f8-c2f8-4dd0-b9e4-06c72b312983",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da89cb5-0107-44ab-a773-b3cc4b7e8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ユーザ設定 ======\n",
    "\n",
    "excel_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\CrossVal_1\\Miwa_hourlyAve_for_LSTM_CrossVal_1.xlsx\"\n",
    "flood_idx_path_train = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\CrossVal_1\\Miwa_flood_idx_train.xlsx\"\n",
    "flood_idx_path_test = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\data\\Miwa_LSTM_Data\\CrossVal_1\\Miwa_flood_idx_test.xlsx\"\n",
    "\n",
    "\n",
    "# 列番号（0始まり）で指定\n",
    "enc_cols   = [5, 3, 4]      # エンコーダ入力の列番号（例：3変数）\n",
    "dec_cols   = [5, 3]  # デコーダ入力の列番号（例：2変数）\n",
    "y_cols      = [4]          # 出力（目的変数）の列番号（例：1変数）\n",
    "\n",
    "Te = 72    # エンコーダのタイムステップ長\n",
    "Td = 240   # デコーダのタイムステップ長\n",
    "\n",
    "\n",
    "# 洪水区間（1始まり行番号で指定してOK。Python内部で0始まりに直す）\n",
    "df_ranges_train = pd.read_excel(flood_idx_path_train, header=0)\n",
    "flood_ranges_train_1based = [tuple(x) for x in df_ranges_train.to_numpy()]\n",
    "\n",
    "# 0-basedに変換（pandasは0-based）\n",
    "flood_ranges_train = [(s-1, e-1) for (s, e) in flood_ranges_train_1based]\n",
    "\n",
    "\n",
    "\n",
    "# ====== 読み込み ======\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "# 必要列だけ抽出（順番固定）\n",
    "use_cols = enc_cols + dec_cols + y_cols\n",
    "data = df.iloc[:, use_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edb06ac-6023-401c-85bd-4ebdccf7c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---平均（train）----\n",
      "CumRain_24h     11.538661\n",
      "Qin(m3/s)       35.832678\n",
      "Tur(ppm)       301.302578\n",
      "CumRain_24h     11.538661\n",
      "Qin(m3/s)       35.832678\n",
      "Tur(ppm)       301.302578\n",
      "dtype: float64\n",
      "----標準偏差（train）----\n",
      "CumRain_24h     23.530454\n",
      "Qin(m3/s)       36.695295\n",
      "Tur(ppm)       822.275976\n",
      "CumRain_24h     23.530454\n",
      "Qin(m3/s)       36.695295\n",
      "Tur(ppm)       822.275976\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ====== 標準化：train dataから平均・標準偏差を算出 ======\n",
    "\n",
    "flood_data_train_parts = [data.iloc[s:e+1, :] for (s, e) in flood_ranges_train]\n",
    "flood_data_train = pd.concat(flood_data_train_parts, axis=0)\n",
    "\n",
    "mean = flood_data_train.mean(numeric_only=True)\n",
    "std  = flood_data_train.std(numeric_only=True).replace(0, 1.0)\n",
    "data_norm = (data - mean) / std # 全期間のデータを標準化\n",
    "\n",
    "print('---平均（train）----')\n",
    "print(mean)\n",
    "\n",
    "print('----標準偏差（train）----')\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfdf953-dcc9-4127-b835-88e1bacfa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, triplets):\n",
    "        self.triplets = triplets  # list of (enc_X, dec_X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triplets[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    enc_seqs, dec_seqs, ys = zip(*batch)\n",
    "    # ここでは全サンプル同一長さ前提（Te/Td固定）なので単純stack\n",
    "    enc_x = torch.stack(enc_seqs, dim=0)  # [B, Te, Fe]\n",
    "    dec_x = torch.stack(dec_seqs, dim=0)  # [B, Td, Fd]\n",
    "    y     = torch.stack(ys,       dim=0)  # [B, Td, Fo]\n",
    "    \n",
    "    # マスク（将来可変長のときに使う）\n",
    "    B, Td, _ = y.shape\n",
    "    mask = torch.ones(B, Td, 1, dtype=torch.float32)\n",
    "    return enc_x, dec_x, y, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9d7bf4-e143-4b1c-a82b-f3e1eb110171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（train） ======\n",
    "\n",
    "samples_train = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_train:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_train.append((enc_X, dec_X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd238b74-fadb-4996-9fa5-c95d338e1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 洪水区間ごとにスライド窓でサンプル作成（test） ======\n",
    "\n",
    "df_ranges_test = pd.read_excel(flood_idx_path_test, header=0)\n",
    "flood_ranges_test_1based = [tuple(x) for x in df_ranges_test.to_numpy()]\n",
    "flood_ranges_test = [(s-1, e-1) for (s, e) in flood_ranges_test_1based]\n",
    "\n",
    "\n",
    "samples_test = []  # list of (enc_X: [Te, Fe], dec_X: [Td, Fd], y: [Td, Fo])\n",
    "Fe, Fd, Fo = len(enc_cols), len(dec_cols), len(y_cols)\n",
    "\n",
    "for (s, e) in flood_ranges_test:\n",
    "    seg = data_norm.iloc[s:e+1]  # 区間データ（両端含む）\n",
    "    n = len(seg)\n",
    "    if n < Te + Td: # 1サンプルは Te + Tdの長さが必要\n",
    "        continue\n",
    "        \n",
    "    for start in range(0, n - (Te + Td) + 1):\n",
    "        enc_window = seg.iloc[start : start + Te]\n",
    "        dec_window = seg.iloc[start + Te : start + Te + Td]\n",
    "        # テンソル化\n",
    "        enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))     # [Te, Fe]\n",
    "        dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))     # [Td, Fd]\n",
    "        y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))      # [Td, Fo]\n",
    "        samples_test.append((enc_X, dec_X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ea472-5810-4499-9fc8-c68929d31744",
   "metadata": {},
   "source": [
    "## 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5587eb-7a1f-4b36-8609-281d28dce28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    \"\"\"collate_fnの戻り値が (enc,dec,y) か (enc,dec,y,mask) のどちらでも対応\"\"\"\n",
    "    if len(batch) == 3:\n",
    "        enc_x, dec_x, y = batch\n",
    "        mask = torch.ones_like(y[..., :1])  # [B,Td,1]\n",
    "    elif len(batch) == 4:\n",
    "        enc_x, dec_x, y, mask = batch\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected batch format\")\n",
    "    return enc_x.to(device), dec_x.to(device), y.to(device), mask.to(device)\n",
    "\n",
    "def masked_mse(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1] (1=valid, 0=pad)\n",
    "    diff2 = (pred - target) ** 2\n",
    "    diff2 = diff2 * mask\n",
    "    denom = mask.sum(dim=(1,2)).clamp_min(1.0)  # per-sample\n",
    "    per_sample = diff2.sum(dim=(1,2)) / denom\n",
    "    return per_sample.mean()\n",
    "\n",
    "def masked_rmse(pred, target, mask):\n",
    "    return torch.sqrt(masked_mse(pred, target, mask))\n",
    "\n",
    "def masked_r2(pred, target, mask):\n",
    "    # R² = 1 - SSE/SST, マスク版\n",
    "    mean = (target * mask).sum(dim=(1,2), keepdim=True) / mask.sum(dim=(1,2), keepdim=True).clamp_min(1.0)\n",
    "    sse = ((pred - target) ** 2 * mask).sum(dim=(1,2))\n",
    "    sst = ((target - mean) ** 2 * mask).sum(dim=(1,2)).clamp_min(1e-12)\n",
    "    r2  = 1.0 - sse / sst\n",
    "    return r2.mean()\n",
    "\n",
    "def masked_corr(pred, target, mask):\n",
    "    # pred/target: [B,T,Out], mask: [B,T,1]\n",
    "    pred = pred * mask\n",
    "    target = target * mask\n",
    "    valid = mask.sum(dim=(1,2)).clamp_min(1.0)\n",
    "\n",
    "    # 平均\n",
    "    mean_pred = pred.sum(dim=(1,2)) / valid\n",
    "    mean_target = target.sum(dim=(1,2)) / valid\n",
    "\n",
    "    # 偏差\n",
    "    diff_pred = (pred - mean_pred.view(-1,1,1)) * mask\n",
    "    diff_target = (target - mean_target.view(-1,1,1)) * mask\n",
    "\n",
    "    # 共分散と分散\n",
    "    cov = (diff_pred * diff_target).sum(dim=(1,2)) / valid\n",
    "    var_pred = (diff_pred**2).sum(dim=(1,2)) / valid\n",
    "    var_target = (diff_target**2).sum(dim=(1,2)) / valid\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_pred * var_target) + 1e-12)\n",
    "    return corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed2a7c-8522-40ea-8d12-431bc6175104",
   "metadata": {},
   "source": [
    "## モデル定義（Seq2SeqLSTM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40758f9-0c2b-406c-a25d-d2abfe40ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateBridge(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoderの(h, c)をDecoder初期状態へ写像するブリッジ。\n",
    "    - 層数/隠れ次元が異なってもOK\n",
    "    - bridge_mode:\n",
    "        - \"zero_pad\":  層合わせ=0埋め or 切り落とし、隠れ次元は線形射影\n",
    "        - \"repeat_top\":層合わせ=最上層の繰り返し/切り落とし、隠れ次元は線形射影\n",
    "        - \"linear_stack\": [B, L_enc, H_enc] -> 線形で [B, L_dec, H_dec] へ（層方向も学習で混合）\n",
    "\n",
    "    - enc_layers: エンコーダの層の深さ\n",
    "    - dec_layers: デコーダの層の深さ\n",
    "    - enc_hidden: エンコーダのノード数\n",
    "    - dec_hidden: デコーダのノード数\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hidden, dec_hidden, mode=\"zero_pad\"):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.enc_hidden = enc_hidden\n",
    "        self.dec_hidden = dec_hidden\n",
    "        self.mode = mode\n",
    "\n",
    "        # 隠れ次元の変換（h/c共用）\n",
    "        if mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            self.proj = nn.Linear(enc_hidden, dec_hidden, bias=True)\n",
    "        elif mode == \"linear_stack\":\n",
    "            # 層方向もまとめて線形変換\n",
    "            self.proj_h = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "            self.proj_c = nn.Linear(enc_layers * enc_hidden, dec_layers * dec_hidden, bias=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bridge mode: {mode}\")\n",
    "\n",
    "    def _match_layers(self, x, how=\"zero_pad\"):\n",
    "        \"\"\"\n",
    "        x: [L_enc, B, H_enc] を層数だけ合わせる（隠れ次元は未変換）\n",
    "        return: [L_dec, B, H_enc]\n",
    "\n",
    "        B: バッチサイズ\n",
    "        \"\"\"\n",
    "        L_enc, B, H = x.shape\n",
    "        L_dec = self.dec_layers\n",
    "\n",
    "        if L_dec == L_enc:\n",
    "            return x\n",
    "\n",
    "        if L_dec < L_enc:\n",
    "            # 上位層を優先して切り落とす（直観的には最上層が一番抽象的）\n",
    "            return x[:L_dec, :, :]\n",
    "\n",
    "        # L_dec > L_enc の場合\n",
    "        pad_count = L_dec - L_enc\n",
    "        if how == \"repeat_top\":\n",
    "            top = x[-1:, :, :].expand(pad_count, B, H)  # 最上層を複製\n",
    "            return torch.cat([x, top], dim=0)\n",
    "        else:  # zero_pad\n",
    "            pad = x.new_zeros(pad_count, B, H)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        \"\"\"\n",
    "        h_enc, c_enc: [L_enc, B, H_enc]\n",
    "        返り値: (h0_dec, c0_dec) それぞれ [L_dec, B, H_dec]\n",
    "        \"\"\"\n",
    "        if self.mode in (\"zero_pad\", \"repeat_top\"):\n",
    "            # 層合わせ（まだ enc_hidden 次元のまま）\n",
    "            h = self._match_layers(h_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            c = self._match_layers(c_enc, \"repeat_top\" if self.mode==\"repeat_top\" else \"zero_pad\")\n",
    "            # 次元射影\n",
    "            L, B, H = h.shape\n",
    "            h = self.proj(h)  # broadcasting: [L,B,H_enc]->[L,B,H_dec]\n",
    "            c = self.proj(c)\n",
    "            return h, c\n",
    "\n",
    "        else:  # linear_stack\n",
    "            # [L_enc,B,H_enc] -> [B, L_enc*H_enc]\n",
    "            L_enc, B, H_enc = h_enc.shape\n",
    "            flat_h = h_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            flat_c = c_enc.transpose(0,1).reshape(B, L_enc*H_enc)\n",
    "            # 線形写像\n",
    "            out_h = self.proj_h(flat_h)  # [B, L_dec*H_dec]\n",
    "            out_c = self.proj_c(flat_c)\n",
    "            # [L_dec,B,H_dec] に戻す\n",
    "            L_dec, H_dec = self.dec_layers, self.dec_hidden\n",
    "            h = out_h.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            c = out_c.view(B, L_dec, H_dec).transpose(0,1).contiguous()\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2beb4d-b16f-45af-9da5-934293ce1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_enc: int, # エンコーダ入力変数の数\n",
    "        in_dec: int, # デコーダ入力変数の数\n",
    "        out_dim: int, # 出力変数の数\n",
    "        enc_hidden: int = 128,\n",
    "        dec_hidden: int = 128,\n",
    "        enc_layers: int = 2,\n",
    "        dec_layers: int = 3,\n",
    "        bridge_mode: str = \"zero_pad\",  # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "        dropout: float = 0.0, # LSTMの層間ドロップアウト率\n",
    "        bidirectional_enc: bool = False,  # エンコーダのみ双方向にするかどうか（必要ならEncoderを双方向にも）\n",
    "        head_activation=\"relu\", # 活性化関数\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,           # 時間方向のカーネル幅（奇数推奨）\n",
    "        conv_channels: int = None,      # 省略時は dec_hidden を維持\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional_enc = bidirectional_enc\n",
    "        enc_dir = 2 if bidirectional_enc else 1\n",
    "        enc_hidden_eff = enc_hidden * enc_dir  # 双方向なら出力次元が倍\n",
    "\n",
    "        self.use_conv = bool(use_conv)\n",
    "\n",
    "        self.enc = nn.LSTM(\n",
    "            input_size=in_enc,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if enc_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional_enc\n",
    "        )\n",
    "\n",
    "        self.dec = nn.LSTM(\n",
    "            input_size=in_dec,\n",
    "            hidden_size=dec_hidden,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if dec_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Encoderが双方向のときは、(h_fwd, h_bwd) を結合した次元 enc_hidden_eff を\n",
    "        # Decoder hidden 次元へ写像する必要がある\n",
    "        self.bridge = StateBridge(\n",
    "            enc_layers=enc_layers * enc_dir,\n",
    "            dec_layers=dec_layers,\n",
    "            enc_hidden=enc_hidden,\n",
    "            dec_hidden=dec_hidden,\n",
    "            mode=bridge_mode\n",
    "        ) if (enc_layers != dec_layers or enc_dir != 1 or enc_hidden != dec_hidden or bridge_mode==\"linear_stack\") else None\n",
    "\n",
    "        \n",
    "        # ---------- 中間層（1次元畳み込み） ----------\n",
    "        if conv_channels is None:\n",
    "            conv_channels = dec_hidden\n",
    "        self.conv_channels = conv_channels\n",
    "        if self.use_conv:\n",
    "            # Conv1dは [B, C=特徴, T=時間] を受け取るので後で転置する\n",
    "            padding = conv_kernel // 2  # SAME相当（奇数カーネル推奨）\n",
    "            self.conv1d = nn.Conv1d(\n",
    "                in_channels=dec_hidden,\n",
    "                out_channels=conv_channels,\n",
    "                kernel_size=conv_kernel,\n",
    "                padding=padding\n",
    "            )\n",
    "            self.conv_act = {\n",
    "                \"identity\": nn.Identity(),\n",
    "                \"relu\": nn.ReLU(),\n",
    "                \"tanh\": nn.Tanh(),\n",
    "                \"sigmoid\": nn.Sigmoid(),\n",
    "            }.get(head_activation, nn.ReLU())\n",
    "            self.conv_dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "            # 出力ヘッドは conv_channels → out_dim\n",
    "            self.head = nn.Linear(conv_channels, out_dim)\n",
    "            # ここでの self.act はヘッド直前では使わない（Conv後に適用済み）\n",
    "            self.act = nn.Identity()\n",
    "        else:\n",
    "            # 畳み込みを使わない場合は dec_hidden → out_dim\n",
    "            self.head = nn.Linear(dec_hidden, out_dim)\n",
    "            self.act = {\n",
    "                \"identity\": nn.Identity(),\n",
    "                \"relu\": nn.ReLU(),\n",
    "                \"tanh\": nn.Tanh(),\n",
    "                \"sigmoid\": nn.Sigmoid(),\n",
    "            }[head_activation]\n",
    "\n",
    "    def _extract_final_states(self, out, hc):\n",
    "        \"\"\"\n",
    "        LSTMの出力から (h_T, c_T) を取り出して成形。\n",
    "        双方向Encoderの場合は各層ごとに [fwd, bwd] を層方向に並べる。\n",
    "        \"\"\"\n",
    "        h, c = hc  # [num_layers * num_directions, B, H]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, enc_x, dec_x):\n",
    "        \"\"\"\n",
    "        enc_x: [B, Te, in_enc]\n",
    "        dec_x: [B, Td, in_dec]\n",
    "        return: yhat [B, Td, out_dim]\n",
    "        \"\"\"\n",
    "        # ----- Encoder -----\n",
    "        _, (h_T, c_T) = self.enc(enc_x)  # h_T,c_T: [L_enc * dir, B, H_enc]\n",
    "\n",
    "        # ----- Bridge -----\n",
    "        if self.bridge is not None:\n",
    "            h0_dec, c0_dec = self.bridge(h_T, c_T)  # [L_dec, B, H_dec]\n",
    "        else:\n",
    "            h0_dec, c0_dec = h_T, c_T\n",
    "\n",
    "        # ----- Decoder -----\n",
    "        dec_out, _ = self.dec(dec_x, (h0_dec, c0_dec))  # [B, Td, H_dec]\n",
    "\n",
    "        if self.use_conv:\n",
    "            # 時間方向のConv1d: [B, H_dec, Td] -> Conv -> [B, C, Td] -> [B, Td, C]\n",
    "            x = dec_out.transpose(1, 2)             # [B, H_dec, Td]\n",
    "            x = self.conv1d(x)                      # [B, conv_channels, Td]\n",
    "            x = self.conv_act(x)\n",
    "            x = self.conv_dropout(x)\n",
    "            x = x.transpose(1, 2)                   # [B, Td, conv_channels]\n",
    "            yhat = self.head(x)                     # [B, Td, out_dim]\n",
    "        else:\n",
    "            # 従来パス：活性化→線形\n",
    "            yhat = self.head(self.act(dec_out))     # [B, Td, out_dim]\n",
    "\n",
    "        return yhat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edde7056-145e-4a01-ba89-e5c27c9ce0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重み初期化用の関数\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # 例: Xavier（正規分布）\n",
    "        # init.xavier_normal_(m.weight)\n",
    "        # ReLU系のLinearならHeにしたい場合:\n",
    "        init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Conv1d):\n",
    "        # Conv1d も Linear と同様に初期化可能\n",
    "        # 例: Xavier（正規分布）\n",
    "        # init.xavier_normal_(m.weight)\n",
    "        # ReLU系のLinearならHeにしたい場合:\n",
    "        init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        # LSTM の場合は named_parameters() で内部ゲートを個別に初期化\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                # 入力→隠れ：Xavier が安定\n",
    "                with torch.no_grad():\n",
    "                    init.xavier_uniform_(param)\n",
    "            elif \"weight_hh\" in name:\n",
    "                # 隠れ→隠れ：Orthogonal が定番\n",
    "                with torch.no_grad():\n",
    "                    init.orthogonal_(param)\n",
    "            elif \"bias\" in name:\n",
    "                with torch.no_grad():\n",
    "                    init.zeros_(param)\n",
    "                    # 必要なら忘却ゲートバイアスを +1 初期化することも可能\n",
    "                    # hidden_size = param.shape[0] // 4\n",
    "                    # param[hidden_size:2*hidden_size] = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3408b-f127-4019-8c6d-b76c86109395",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定\n",
    "### ※保存Excelファイルのパスも設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0994e29f-978e-42b8-b677-a163f4e2adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg = {\n",
    "    # Model\n",
    "    \"in_enc\": 3,\n",
    "    \"in_dec\": 2,\n",
    "    \"out_dim\": 1,\n",
    "    \"enc_hidden\": 16, # 【要変更】\n",
    "    \"dec_hidden\": 16, # 【要変更】\n",
    "    \"enc_layers\": 1, # 【要変更】\n",
    "    \"dec_layers\": 1, # 【要変更】\n",
    "    \"bridge_mode\": \"zero_pad\",   # \"zero_pad\" | \"repeat_top\" | \"linear_stack\"\n",
    "    \"batch_size\": 256, # 【要変更】\n",
    "    \"dropout\": 0.1,\n",
    "    \"bidirectional_enc\": False,\n",
    "    \"head_activation\": \"relu\", # \"identity\", \"relu\", \"tanh\", \"sigmoid\" など 【要変更】\n",
    "    # Train\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-2,\n",
    "    \"weight_decay\": 0.0, # L2正規化係数。0なら無効\n",
    "    \"grad_clip\": 1.0, # 勾配クリッピングの閾値。０かNoneなら無効\n",
    "    \"print_every\": 1, # 学習の進捗を何エポックごとに出力するか\n",
    "    \"patience\": 5, # early stopping\n",
    "    \"use_conv\": True # 畳み込み層を使うかどうか【要変更】\n",
    "}\n",
    "\n",
    "save_dir = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\"\n",
    "save_path_excel = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\CrossVal_2_result_final.xlsx\" # 【要変更】\n",
    "# save_path_model = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2/CrossVal_2_result_final_model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0f506-bf20-4b7e-aa9b-8b16596c1663",
   "metadata": {},
   "source": [
    "## 学習関数・評価関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf43fea-db77-40f9-956b-d61648aa0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数・評価関数の定義\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if cfg[\"grad_clip\"]:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = enc_x.size(0) # バッチサイズ\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return total_loss / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0; total_rmse = 0.0; total_r2 = 0.0; total_corr = 0.0; n = 0\n",
    "    for batch in loader:\n",
    "        enc_x, dec_x, y, mask = split_batch(batch)\n",
    "        yhat = model(enc_x, dec_x)\n",
    "\n",
    "        loss = masked_mse(yhat, y, mask)\n",
    "        rmse = masked_rmse(yhat, y, mask)\n",
    "        r2   = masked_r2(yhat, y, mask)\n",
    "        corr = masked_corr(yhat, y, mask)\n",
    "\n",
    "        bs = enc_x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_rmse += rmse.item() * bs\n",
    "        total_r2   += r2.item() * bs\n",
    "        total_corr += corr.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / max(n,1),\n",
    "        \"rmse\": total_rmse / max(n,1),\n",
    "        \"r2\":   total_r2   / max(n,1),\n",
    "        \"corr\": total_corr / max(n,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab44b3b2-37dd-48f9-b88c-67e9f88ed16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize_y_by_index(y_std, mean, std, y_pos):\n",
    "    \"\"\"\n",
    "    y_std:  標準化スケールの出力テンソル [B, T, Fo]\n",
    "    mean, std: pandas.Series（学習時にfitしたもの。index=列名）\n",
    "    y_pos: 出力列の「列番号（位置）」リスト（例: [Fe+Fd, Fe+Fd+1, ...]）\n",
    "    return: 元スケールの y [B, T, Fo]\n",
    "    \"\"\"\n",
    "    m = torch.tensor(mean.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    s = torch.tensor(std.iloc[y_pos].to_numpy(dtype=float),\n",
    "                     dtype=y_std.dtype, device=y_std.device).view(1, 1, -1)\n",
    "    return y_std * s + m\n",
    "\n",
    "\n",
    "def masked_corr(pred, target, mask, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    マスク付きピアソン相関係数（バッチ平均）\n",
    "    pred/target: [B, T, Fo], mask: [B, T, 1]（1=有効, 0=無効）\n",
    "    返り値: スカラー（バッチ平均の相関）\n",
    "    \"\"\"\n",
    "    # 有効点数（サンプルごと）\n",
    "    valid = mask.sum(dim=(1, 2)).clamp_min(1.0)  # [B]\n",
    "\n",
    "    # 平均（サンプルごと）\n",
    "    mean_p = (pred * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "    mean_t = (target * mask).sum(dim=(1, 2), keepdim=True) / valid.view(-1, 1, 1)\n",
    "\n",
    "    # 偏差\n",
    "    dp = (pred - mean_p) * mask\n",
    "    dt = (target - mean_t) * mask\n",
    "\n",
    "    # 共分散・分散（サンプルごと）\n",
    "    cov = dp.mul(dt).sum(dim=(1, 2)) / valid        # [B]\n",
    "    var_p = dp.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "    var_t = dt.pow(2).sum(dim=(1, 2)) / valid       # [B]\n",
    "\n",
    "    corr = cov / (torch.sqrt(var_p * var_t) + eps)  # [B]\n",
    "    return corr.mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale_by_index(model, loader, mean, std, data_columns, y_pos):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 厳密集計用\n",
    "    total_sse = 0.0   # 全有効点での誤差二乗和\n",
    "    total_cnt = 0.0   # 全有効点数（マスク=1の総数）\n",
    "    total_r2  = 0.0   # R² のバッチ加重平均用\n",
    "    total_corr = 0.0  # 相関R のバッチ加重平均用\n",
    "    n = 0             # サンプル数（バッチ内のBの合計）\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 3:\n",
    "            enc_x, dec_x, y_std = batch\n",
    "            mask = torch.ones_like(y_std[..., :1])\n",
    "        elif len(batch) == 4:\n",
    "            enc_x, dec_x, y_std, mask = batch\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected batch format\")\n",
    "\n",
    "        # 統一デバイス・dtype\n",
    "        enc_x = enc_x.to(device=device, dtype=torch.float32)\n",
    "        dec_x = dec_x.to(device=device, dtype=torch.float32)\n",
    "        y_std = y_std.to(device=device, dtype=torch.float32)\n",
    "        mask  = mask.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # 予測（標準化スケール）\n",
    "        yhat_std = model(enc_x, dec_x)\n",
    "\n",
    "        # 出力だけ逆標準化\n",
    "        yhat = inverse_standardize_y_by_index(yhat_std, mean, std, y_pos)\n",
    "        y    = inverse_standardize_y_by_index(y_std,     mean, std, y_pos)\n",
    "\n",
    "        # 厳密RMSE用：SSEと有効点数を直接合算\n",
    "        sse_batch = ((yhat - y) ** 2 * mask).sum().item()\n",
    "        cnt_batch = mask.sum().item()\n",
    "        total_sse += sse_batch\n",
    "        total_cnt += max(cnt_batch, 1.0)\n",
    "\n",
    "        # R² と 相関R はサンプル数で加重平均\n",
    "        r2    = masked_r2(yhat, y, mask).item()\n",
    "        corr  = masked_corr(yhat, y, mask).item()\n",
    "        bs = enc_x.size(0)\n",
    "        total_r2   += r2   * bs\n",
    "        total_corr += corr * bs\n",
    "        n += bs\n",
    "\n",
    "    mse  = total_sse / max(total_cnt, 1.0)\n",
    "    rmse = mse ** 0.5\n",
    "    r2   = total_r2   / max(n, 1)\n",
    "    corr = total_corr / max(n, 1)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \"corr\": corr}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6d72d-79ff-4ea1-9312-8554f3f15aa2",
   "metadata": {},
   "source": [
    "## 学習（シード値を変えて5回学習。結果を保存する）\n",
    "### ※train期間のうちランダムに85%を学習、15%を検証に分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee1c488-6305-4c96-8f63-dd2dd6e519ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss=0.4924 | val_loss=0.3469 val_rmse=0.5890 val_r2=-67.2890val_corr=0.7633\n",
      "[2/100] train_loss=0.2912 | val_loss=0.2330 val_rmse=0.4827 val_r2=-8.9620val_corr=0.8313\n",
      "[3/100] train_loss=0.2044 | val_loss=0.1672 val_rmse=0.4090 val_r2=-21.8455val_corr=0.8611\n",
      "[4/100] train_loss=0.1584 | val_loss=0.1341 val_rmse=0.3662 val_r2=-1.9943val_corr=0.8814\n",
      "[5/100] train_loss=0.1384 | val_loss=0.1209 val_rmse=0.3476 val_r2=-3.4288val_corr=0.8799\n",
      "[6/100] train_loss=0.1299 | val_loss=0.1092 val_rmse=0.3304 val_r2=-1.8947val_corr=0.8830\n",
      "[7/100] train_loss=0.1230 | val_loss=0.1067 val_rmse=0.3266 val_r2=-1.2815val_corr=0.8857\n",
      "[8/100] train_loss=0.1164 | val_loss=0.1024 val_rmse=0.3200 val_r2=-1.0425val_corr=0.8897\n",
      "[9/100] train_loss=0.1093 | val_loss=0.0983 val_rmse=0.3135 val_r2=-0.9011val_corr=0.8927\n",
      "[10/100] train_loss=0.1037 | val_loss=0.0912 val_rmse=0.3021 val_r2=-1.0889val_corr=0.8988\n",
      "[11/100] train_loss=0.0980 | val_loss=0.0856 val_rmse=0.2925 val_r2=-0.9987val_corr=0.8987\n",
      "[12/100] train_loss=0.0901 | val_loss=0.0817 val_rmse=0.2857 val_r2=-1.2880val_corr=0.8793\n",
      "[13/100] train_loss=0.0854 | val_loss=0.0711 val_rmse=0.2666 val_r2=-1.7022val_corr=0.8789\n",
      "[14/100] train_loss=0.0790 | val_loss=0.0806 val_rmse=0.2839 val_r2=-1.8224val_corr=0.8715\n",
      "[15/100] train_loss=0.0821 | val_loss=0.0749 val_rmse=0.2737 val_r2=-2.8259val_corr=0.8798\n",
      "[16/100] train_loss=0.0787 | val_loss=0.0662 val_rmse=0.2572 val_r2=-1.7447val_corr=0.8877\n",
      "[17/100] train_loss=0.0734 | val_loss=0.0624 val_rmse=0.2498 val_r2=-1.3708val_corr=0.8797\n",
      "[18/100] train_loss=0.0689 | val_loss=0.0608 val_rmse=0.2467 val_r2=-0.8460val_corr=0.8836\n",
      "[19/100] train_loss=0.0677 | val_loss=0.0579 val_rmse=0.2407 val_r2=-0.5209val_corr=0.8866\n",
      "[20/100] train_loss=0.0658 | val_loss=0.0570 val_rmse=0.2387 val_r2=-0.3793val_corr=0.8884\n",
      "[21/100] train_loss=0.0630 | val_loss=0.0535 val_rmse=0.2312 val_r2=-0.3876val_corr=0.8892\n",
      "[22/100] train_loss=0.0620 | val_loss=0.0523 val_rmse=0.2286 val_r2=-0.1888val_corr=0.8899\n",
      "[23/100] train_loss=0.0624 | val_loss=0.0583 val_rmse=0.2415 val_r2=-0.0661val_corr=0.8886\n",
      "[24/100] train_loss=0.0613 | val_loss=0.0522 val_rmse=0.2285 val_r2=-0.1373val_corr=0.8896\n",
      "[25/100] train_loss=0.0596 | val_loss=0.0506 val_rmse=0.2248 val_r2=0.0003val_corr=0.8958\n",
      "[26/100] train_loss=0.0582 | val_loss=0.0490 val_rmse=0.2214 val_r2=-0.1253val_corr=0.8974\n",
      "[27/100] train_loss=0.0560 | val_loss=0.0504 val_rmse=0.2245 val_r2=-0.0230val_corr=0.8967\n",
      "[28/100] train_loss=0.0546 | val_loss=0.0444 val_rmse=0.2107 val_r2=-0.3377val_corr=0.8992\n",
      "[29/100] train_loss=0.0514 | val_loss=0.0417 val_rmse=0.2042 val_r2=-1.1197val_corr=0.9011\n",
      "[30/100] train_loss=0.0496 | val_loss=0.0390 val_rmse=0.1975 val_r2=-1.1258val_corr=0.9003\n",
      "[31/100] train_loss=0.0482 | val_loss=0.0392 val_rmse=0.1981 val_r2=-1.0913val_corr=0.9045\n",
      "[32/100] train_loss=0.0466 | val_loss=0.0364 val_rmse=0.1907 val_r2=-3.2457val_corr=0.8979\n",
      "[33/100] train_loss=0.0452 | val_loss=0.0363 val_rmse=0.1904 val_r2=-1.6861val_corr=0.9097\n",
      "[34/100] train_loss=0.0432 | val_loss=0.0333 val_rmse=0.1824 val_r2=-0.8113val_corr=0.9128\n",
      "[35/100] train_loss=0.0409 | val_loss=0.0315 val_rmse=0.1776 val_r2=-3.3048val_corr=0.9034\n",
      "[36/100] train_loss=0.0402 | val_loss=0.0341 val_rmse=0.1846 val_r2=-0.9798val_corr=0.9138\n",
      "[37/100] train_loss=0.0431 | val_loss=0.0348 val_rmse=0.1865 val_r2=-3.2049val_corr=0.9079\n",
      "[38/100] train_loss=0.0402 | val_loss=0.0340 val_rmse=0.1843 val_r2=-1.9099val_corr=0.9079\n",
      "[39/100] train_loss=0.0389 | val_loss=0.0313 val_rmse=0.1770 val_r2=-1.8146val_corr=0.9049\n",
      "[40/100] train_loss=0.0370 | val_loss=0.0264 val_rmse=0.1625 val_r2=-2.1258val_corr=0.9163\n",
      "[41/100] train_loss=0.0346 | val_loss=0.0239 val_rmse=0.1546 val_r2=-2.1216val_corr=0.9082\n",
      "[42/100] train_loss=0.0326 | val_loss=0.0219 val_rmse=0.1480 val_r2=-1.7056val_corr=0.9181\n",
      "[43/100] train_loss=0.0301 | val_loss=0.0193 val_rmse=0.1388 val_r2=-1.3159val_corr=0.9218\n",
      "[44/100] train_loss=0.0291 | val_loss=0.0189 val_rmse=0.1375 val_r2=-1.2441val_corr=0.9238\n",
      "[45/100] train_loss=0.0288 | val_loss=0.0183 val_rmse=0.1354 val_r2=-0.6340val_corr=0.9263\n",
      "[46/100] train_loss=0.0282 | val_loss=0.0218 val_rmse=0.1478 val_r2=-0.7337val_corr=0.9278\n",
      "[47/100] train_loss=0.0293 | val_loss=0.0201 val_rmse=0.1418 val_r2=-0.3672val_corr=0.9276\n",
      "[48/100] train_loss=0.0276 | val_loss=0.0170 val_rmse=0.1302 val_r2=-0.5226val_corr=0.9330\n",
      "[49/100] train_loss=0.0266 | val_loss=0.0172 val_rmse=0.1313 val_r2=-0.5916val_corr=0.9293\n",
      "[50/100] train_loss=0.0256 | val_loss=0.0154 val_rmse=0.1239 val_r2=-0.5970val_corr=0.9300\n",
      "[51/100] train_loss=0.0246 | val_loss=0.0153 val_rmse=0.1239 val_r2=-0.3809val_corr=0.9356\n",
      "[52/100] train_loss=0.0246 | val_loss=0.0153 val_rmse=0.1238 val_r2=-0.2955val_corr=0.9349\n",
      "[53/100] train_loss=0.0240 | val_loss=0.0148 val_rmse=0.1217 val_r2=-0.2066val_corr=0.9355\n",
      "[54/100] train_loss=0.0244 | val_loss=0.0145 val_rmse=0.1205 val_r2=-0.2646val_corr=0.9377\n",
      "[55/100] train_loss=0.0237 | val_loss=0.0142 val_rmse=0.1191 val_r2=-0.1129val_corr=0.9396\n",
      "[56/100] train_loss=0.0235 | val_loss=0.0137 val_rmse=0.1171 val_r2=-0.0737val_corr=0.9397\n",
      "[57/100] train_loss=0.0238 | val_loss=0.0137 val_rmse=0.1171 val_r2=-0.0294val_corr=0.9402\n",
      "[58/100] train_loss=0.0235 | val_loss=0.0135 val_rmse=0.1164 val_r2=0.0208val_corr=0.9401\n",
      "[59/100] train_loss=0.0232 | val_loss=0.0133 val_rmse=0.1154 val_r2=-0.1335val_corr=0.9387\n",
      "[60/100] train_loss=0.0231 | val_loss=0.0135 val_rmse=0.1162 val_r2=0.1675val_corr=0.9417\n",
      "[61/100] train_loss=0.0228 | val_loss=0.0135 val_rmse=0.1163 val_r2=0.0479val_corr=0.9399\n",
      "[62/100] train_loss=0.0226 | val_loss=0.0133 val_rmse=0.1154 val_r2=0.1612val_corr=0.9413\n",
      "[63/100] train_loss=0.0229 | val_loss=0.0130 val_rmse=0.1141 val_r2=0.0668val_corr=0.9403\n",
      "[64/100] train_loss=0.0223 | val_loss=0.0125 val_rmse=0.1118 val_r2=0.0773val_corr=0.9398\n",
      "[65/100] train_loss=0.0221 | val_loss=0.0125 val_rmse=0.1117 val_r2=0.0854val_corr=0.9398\n",
      "[66/100] train_loss=0.0220 | val_loss=0.0127 val_rmse=0.1127 val_r2=0.0974val_corr=0.9395\n",
      "[67/100] train_loss=0.0219 | val_loss=0.0129 val_rmse=0.1137 val_r2=0.1429val_corr=0.9406\n",
      "[68/100] train_loss=0.0217 | val_loss=0.0120 val_rmse=0.1094 val_r2=0.0420val_corr=0.9403\n",
      "[69/100] train_loss=0.0211 | val_loss=0.0122 val_rmse=0.1103 val_r2=0.0376val_corr=0.9403\n",
      "[70/100] train_loss=0.0211 | val_loss=0.0143 val_rmse=0.1196 val_r2=0.1403val_corr=0.9392\n",
      "[71/100] train_loss=0.0266 | val_loss=0.0193 val_rmse=0.1388 val_r2=0.1389val_corr=0.9333\n",
      "[72/100] train_loss=0.0244 | val_loss=0.0153 val_rmse=0.1239 val_r2=0.1172val_corr=0.9359\n",
      "[73/100] train_loss=0.0223 | val_loss=0.0125 val_rmse=0.1120 val_r2=0.3465val_corr=0.9403\n",
      "Early stopping at epoch 73 (best epoch=68, val_loss=0.0120)\n",
      "1 回目の学習が終了しました。ベストモデルを保存: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed0\n",
      "[1/100] train_loss=0.3861 | val_loss=0.2090 val_rmse=0.4572 val_r2=-12.4156val_corr=0.8316\n",
      "[2/100] train_loss=0.1969 | val_loss=0.1581 val_rmse=0.3976 val_r2=-5.0707val_corr=0.8740\n",
      "[3/100] train_loss=0.1675 | val_loss=0.1290 val_rmse=0.3592 val_r2=0.0626val_corr=0.8864\n",
      "[4/100] train_loss=0.1408 | val_loss=0.1215 val_rmse=0.3486 val_r2=-0.3425val_corr=0.8921\n",
      "[5/100] train_loss=0.1322 | val_loss=0.1170 val_rmse=0.3420 val_r2=-0.4671val_corr=0.8916\n",
      "[6/100] train_loss=0.1236 | val_loss=0.1135 val_rmse=0.3369 val_r2=-0.3671val_corr=0.8887\n",
      "[7/100] train_loss=0.1182 | val_loss=0.1082 val_rmse=0.3289 val_r2=-0.4602val_corr=0.8901\n",
      "[8/100] train_loss=0.1136 | val_loss=0.1056 val_rmse=0.3249 val_r2=-0.4300val_corr=0.8924\n",
      "[9/100] train_loss=0.1102 | val_loss=0.1025 val_rmse=0.3202 val_r2=-0.4846val_corr=0.8966\n",
      "[10/100] train_loss=0.1073 | val_loss=0.0988 val_rmse=0.3144 val_r2=-0.3746val_corr=0.9011\n",
      "[11/100] train_loss=0.1037 | val_loss=0.1004 val_rmse=0.3169 val_r2=-1.4021val_corr=0.9081\n",
      "[12/100] train_loss=0.0973 | val_loss=0.0962 val_rmse=0.3101 val_r2=-2.6272val_corr=0.9059\n",
      "[13/100] train_loss=0.0942 | val_loss=0.0893 val_rmse=0.2988 val_r2=-1.2751val_corr=0.9080\n",
      "[14/100] train_loss=0.0883 | val_loss=0.0812 val_rmse=0.2850 val_r2=-0.6475val_corr=0.8995\n",
      "[15/100] train_loss=0.0844 | val_loss=0.0767 val_rmse=0.2769 val_r2=-0.2331val_corr=0.8852\n",
      "[16/100] train_loss=0.0797 | val_loss=0.0768 val_rmse=0.2771 val_r2=-0.7668val_corr=0.8858\n",
      "[17/100] train_loss=0.0762 | val_loss=0.0697 val_rmse=0.2640 val_r2=-0.3757val_corr=0.8869\n",
      "[18/100] train_loss=0.0751 | val_loss=0.0682 val_rmse=0.2611 val_r2=-0.2258val_corr=0.8914\n",
      "[19/100] train_loss=0.0720 | val_loss=0.0650 val_rmse=0.2550 val_r2=-0.2106val_corr=0.8886\n",
      "[20/100] train_loss=0.0698 | val_loss=0.0648 val_rmse=0.2545 val_r2=-0.3524val_corr=0.8913\n",
      "[21/100] train_loss=0.0661 | val_loss=0.0580 val_rmse=0.2408 val_r2=-0.3997val_corr=0.8897\n",
      "[22/100] train_loss=0.0651 | val_loss=0.0601 val_rmse=0.2451 val_r2=-0.3592val_corr=0.8912\n",
      "[23/100] train_loss=0.0643 | val_loss=0.0573 val_rmse=0.2393 val_r2=-0.2816val_corr=0.8990\n",
      "[24/100] train_loss=0.0600 | val_loss=0.0519 val_rmse=0.2278 val_r2=-0.0170val_corr=0.9033\n",
      "[25/100] train_loss=0.0574 | val_loss=0.0489 val_rmse=0.2211 val_r2=-0.1219val_corr=0.9027\n",
      "[26/100] train_loss=0.0562 | val_loss=0.0477 val_rmse=0.2184 val_r2=-0.0294val_corr=0.9055\n",
      "[27/100] train_loss=0.0543 | val_loss=0.0459 val_rmse=0.2143 val_r2=-0.2950val_corr=0.9051\n",
      "[28/100] train_loss=0.0529 | val_loss=0.0440 val_rmse=0.2098 val_r2=-0.6112val_corr=0.9038\n",
      "[29/100] train_loss=0.0510 | val_loss=0.0447 val_rmse=0.2115 val_r2=-0.1735val_corr=0.9090\n",
      "[30/100] train_loss=0.0509 | val_loss=0.0413 val_rmse=0.2033 val_r2=-0.1928val_corr=0.9125\n",
      "[31/100] train_loss=0.0486 | val_loss=0.0406 val_rmse=0.2015 val_r2=-0.3061val_corr=0.9100\n",
      "[32/100] train_loss=0.0458 | val_loss=0.0372 val_rmse=0.1928 val_r2=-1.3864val_corr=0.9081\n",
      "[33/100] train_loss=0.0436 | val_loss=0.0341 val_rmse=0.1847 val_r2=-0.9391val_corr=0.9125\n",
      "[34/100] train_loss=0.0415 | val_loss=0.0315 val_rmse=0.1776 val_r2=-0.4496val_corr=0.9177\n",
      "[35/100] train_loss=0.0430 | val_loss=0.0354 val_rmse=0.1882 val_r2=0.1310val_corr=0.9281\n",
      "[36/100] train_loss=0.0411 | val_loss=0.0304 val_rmse=0.1743 val_r2=-0.0376val_corr=0.9230\n",
      "[37/100] train_loss=0.0370 | val_loss=0.0256 val_rmse=0.1601 val_r2=-0.1779val_corr=0.9224\n",
      "[38/100] train_loss=0.0344 | val_loss=0.0255 val_rmse=0.1598 val_r2=0.1424val_corr=0.9285\n",
      "[39/100] train_loss=0.0338 | val_loss=0.0258 val_rmse=0.1607 val_r2=0.1982val_corr=0.9296\n",
      "[40/100] train_loss=0.0333 | val_loss=0.0234 val_rmse=0.1529 val_r2=0.3586val_corr=0.9355\n",
      "[41/100] train_loss=0.0325 | val_loss=0.0259 val_rmse=0.1609 val_r2=0.3940val_corr=0.9343\n",
      "[42/100] train_loss=0.0323 | val_loss=0.0236 val_rmse=0.1536 val_r2=0.3279val_corr=0.9364\n",
      "[43/100] train_loss=0.0312 | val_loss=0.0218 val_rmse=0.1476 val_r2=-0.0730val_corr=0.9333\n",
      "[44/100] train_loss=0.0302 | val_loss=0.0231 val_rmse=0.1519 val_r2=-0.0255val_corr=0.9356\n",
      "[45/100] train_loss=0.0298 | val_loss=0.0210 val_rmse=0.1449 val_r2=-0.0155val_corr=0.9353\n",
      "[46/100] train_loss=0.0291 | val_loss=0.0207 val_rmse=0.1438 val_r2=0.2857val_corr=0.9408\n",
      "[47/100] train_loss=0.0284 | val_loss=0.0192 val_rmse=0.1387 val_r2=0.3471val_corr=0.9387\n",
      "[48/100] train_loss=0.0280 | val_loss=0.0193 val_rmse=0.1388 val_r2=0.3326val_corr=0.9404\n",
      "[49/100] train_loss=0.0274 | val_loss=0.0182 val_rmse=0.1351 val_r2=0.3977val_corr=0.9390\n",
      "[50/100] train_loss=0.0268 | val_loss=0.0200 val_rmse=0.1414 val_r2=0.4439val_corr=0.9407\n",
      "[51/100] train_loss=0.0277 | val_loss=0.0179 val_rmse=0.1336 val_r2=0.4449val_corr=0.9405\n",
      "[52/100] train_loss=0.0262 | val_loss=0.0172 val_rmse=0.1313 val_r2=0.4086val_corr=0.9414\n",
      "[53/100] train_loss=0.0259 | val_loss=0.0168 val_rmse=0.1297 val_r2=0.4221val_corr=0.9403\n",
      "[54/100] train_loss=0.0253 | val_loss=0.0163 val_rmse=0.1275 val_r2=0.4339val_corr=0.9407\n",
      "[55/100] train_loss=0.0253 | val_loss=0.0169 val_rmse=0.1301 val_r2=0.4189val_corr=0.9404\n",
      "[56/100] train_loss=0.0271 | val_loss=0.0281 val_rmse=0.1677 val_r2=0.4008val_corr=0.9335\n",
      "[57/100] train_loss=0.0329 | val_loss=0.0239 val_rmse=0.1548 val_r2=-0.1008val_corr=0.9271\n",
      "[58/100] train_loss=0.0328 | val_loss=0.0246 val_rmse=0.1570 val_r2=-0.0233val_corr=0.9257\n",
      "[59/100] train_loss=0.0297 | val_loss=0.0194 val_rmse=0.1392 val_r2=0.1119val_corr=0.9335\n",
      "Early stopping at epoch 59 (best epoch=54, val_loss=0.0163)\n",
      "2 回目の学習が終了しました。ベストモデルを保存: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed1\n",
      "[1/100] train_loss=0.5111 | val_loss=0.3479 val_rmse=0.5899 val_r2=-54.4084val_corr=0.7501\n",
      "[2/100] train_loss=0.2991 | val_loss=0.2468 val_rmse=0.4968 val_r2=-6.0986val_corr=0.8466\n",
      "[3/100] train_loss=0.2136 | val_loss=0.1715 val_rmse=0.4141 val_r2=-5.9580val_corr=0.8755\n",
      "[4/100] train_loss=0.1699 | val_loss=0.1303 val_rmse=0.3610 val_r2=-1.9164val_corr=0.8903\n",
      "[5/100] train_loss=0.1411 | val_loss=0.1179 val_rmse=0.3434 val_r2=-1.9382val_corr=0.8912\n",
      "[6/100] train_loss=0.1355 | val_loss=0.1075 val_rmse=0.3278 val_r2=-1.3444val_corr=0.8933\n",
      "[7/100] train_loss=0.1293 | val_loss=0.1065 val_rmse=0.3264 val_r2=-2.0464val_corr=0.8977\n",
      "[8/100] train_loss=0.1231 | val_loss=0.1008 val_rmse=0.3175 val_r2=-0.4719val_corr=0.9020\n",
      "[9/100] train_loss=0.1177 | val_loss=0.0933 val_rmse=0.3054 val_r2=-0.8266val_corr=0.9092\n",
      "[10/100] train_loss=0.1136 | val_loss=0.0912 val_rmse=0.3021 val_r2=-1.1405val_corr=0.9095\n",
      "[11/100] train_loss=0.1088 | val_loss=0.0859 val_rmse=0.2931 val_r2=-2.3432val_corr=0.9054\n",
      "[12/100] train_loss=0.1022 | val_loss=0.0790 val_rmse=0.2810 val_r2=-1.3867val_corr=0.8920\n",
      "[13/100] train_loss=0.0973 | val_loss=0.0771 val_rmse=0.2777 val_r2=-3.0369val_corr=0.8909\n",
      "[14/100] train_loss=0.0935 | val_loss=0.0735 val_rmse=0.2711 val_r2=-1.7364val_corr=0.8823\n",
      "[15/100] train_loss=0.0892 | val_loss=0.0744 val_rmse=0.2727 val_r2=-1.2806val_corr=0.8780\n",
      "[16/100] train_loss=0.0877 | val_loss=0.0690 val_rmse=0.2627 val_r2=-1.2872val_corr=0.8838\n",
      "[17/100] train_loss=0.0850 | val_loss=0.0652 val_rmse=0.2554 val_r2=-0.9758val_corr=0.8823\n",
      "[18/100] train_loss=0.0845 | val_loss=0.0726 val_rmse=0.2695 val_r2=-0.7205val_corr=0.8829\n",
      "[19/100] train_loss=0.0843 | val_loss=0.0620 val_rmse=0.2489 val_r2=-0.6751val_corr=0.8901\n",
      "[20/100] train_loss=0.0814 | val_loss=0.0616 val_rmse=0.2483 val_r2=-0.2587val_corr=0.8892\n",
      "[21/100] train_loss=0.0780 | val_loss=0.0602 val_rmse=0.2454 val_r2=-0.3378val_corr=0.8838\n",
      "[22/100] train_loss=0.0761 | val_loss=0.0621 val_rmse=0.2492 val_r2=-0.0133val_corr=0.8835\n",
      "[23/100] train_loss=0.0727 | val_loss=0.0615 val_rmse=0.2480 val_r2=-0.0012val_corr=0.8843\n",
      "[24/100] train_loss=0.0704 | val_loss=0.0505 val_rmse=0.2247 val_r2=-0.0945val_corr=0.8898\n",
      "[25/100] train_loss=0.0661 | val_loss=0.0473 val_rmse=0.2176 val_r2=-0.2998val_corr=0.8931\n",
      "[26/100] train_loss=0.0631 | val_loss=0.0494 val_rmse=0.2222 val_r2=-0.7380val_corr=0.8920\n",
      "[27/100] train_loss=0.0625 | val_loss=0.0488 val_rmse=0.2210 val_r2=-0.7678val_corr=0.8920\n",
      "[28/100] train_loss=0.0605 | val_loss=0.0455 val_rmse=0.2134 val_r2=-1.0463val_corr=0.8918\n",
      "[29/100] train_loss=0.0608 | val_loss=0.0466 val_rmse=0.2158 val_r2=-0.5358val_corr=0.8935\n",
      "[30/100] train_loss=0.0598 | val_loss=0.0416 val_rmse=0.2040 val_r2=-0.4550val_corr=0.9005\n",
      "[31/100] train_loss=0.0588 | val_loss=0.0406 val_rmse=0.2015 val_r2=-0.3610val_corr=0.8985\n",
      "[32/100] train_loss=0.0563 | val_loss=0.0401 val_rmse=0.2004 val_r2=-0.2517val_corr=0.8956\n",
      "[33/100] train_loss=0.0537 | val_loss=0.0385 val_rmse=0.1962 val_r2=-0.9301val_corr=0.8966\n",
      "[34/100] train_loss=0.0514 | val_loss=0.0355 val_rmse=0.1885 val_r2=-0.8625val_corr=0.8953\n",
      "[35/100] train_loss=0.0495 | val_loss=0.0345 val_rmse=0.1856 val_r2=-0.4998val_corr=0.8996\n",
      "[36/100] train_loss=0.0501 | val_loss=0.0378 val_rmse=0.1945 val_r2=-0.5378val_corr=0.8911\n",
      "[37/100] train_loss=0.0500 | val_loss=0.0335 val_rmse=0.1829 val_r2=-0.3895val_corr=0.9144\n",
      "[38/100] train_loss=0.0477 | val_loss=0.0319 val_rmse=0.1786 val_r2=-0.0526val_corr=0.9072\n",
      "[39/100] train_loss=0.0455 | val_loss=0.0301 val_rmse=0.1736 val_r2=-0.0378val_corr=0.9162\n",
      "[40/100] train_loss=0.0426 | val_loss=0.0291 val_rmse=0.1707 val_r2=-0.3512val_corr=0.9191\n",
      "[41/100] train_loss=0.0403 | val_loss=0.0272 val_rmse=0.1649 val_r2=-0.6429val_corr=0.9116\n",
      "[42/100] train_loss=0.0391 | val_loss=0.0241 val_rmse=0.1553 val_r2=-0.4782val_corr=0.9168\n",
      "[43/100] train_loss=0.0369 | val_loss=0.0223 val_rmse=0.1493 val_r2=-1.1956val_corr=0.9155\n",
      "[44/100] train_loss=0.0356 | val_loss=0.0219 val_rmse=0.1479 val_r2=-0.4699val_corr=0.9236\n",
      "[45/100] train_loss=0.0338 | val_loss=0.0201 val_rmse=0.1419 val_r2=-1.0659val_corr=0.9207\n",
      "[46/100] train_loss=0.0326 | val_loss=0.0200 val_rmse=0.1414 val_r2=-0.3398val_corr=0.9268\n",
      "[47/100] train_loss=0.0320 | val_loss=0.0186 val_rmse=0.1364 val_r2=-1.1977val_corr=0.9218\n",
      "[48/100] train_loss=0.0309 | val_loss=0.0188 val_rmse=0.1370 val_r2=-0.7398val_corr=0.9250\n",
      "[49/100] train_loss=0.0300 | val_loss=0.0180 val_rmse=0.1343 val_r2=-0.6390val_corr=0.9267\n",
      "[50/100] train_loss=0.0295 | val_loss=0.0167 val_rmse=0.1294 val_r2=-0.5983val_corr=0.9274\n",
      "[51/100] train_loss=0.0288 | val_loss=0.0174 val_rmse=0.1319 val_r2=-0.1458val_corr=0.9298\n",
      "[52/100] train_loss=0.0288 | val_loss=0.0162 val_rmse=0.1273 val_r2=-0.2077val_corr=0.9302\n",
      "[53/100] train_loss=0.0286 | val_loss=0.0153 val_rmse=0.1238 val_r2=-0.4820val_corr=0.9284\n",
      "[54/100] train_loss=0.0278 | val_loss=0.0178 val_rmse=0.1334 val_r2=-0.1214val_corr=0.9310\n",
      "[55/100] train_loss=0.0280 | val_loss=0.0178 val_rmse=0.1336 val_r2=-0.3482val_corr=0.9283\n",
      "[56/100] train_loss=0.0292 | val_loss=0.0214 val_rmse=0.1464 val_r2=-0.0993val_corr=0.9311\n",
      "[57/100] train_loss=0.0290 | val_loss=0.0150 val_rmse=0.1225 val_r2=-0.3368val_corr=0.9298\n",
      "[58/100] train_loss=0.0288 | val_loss=0.0151 val_rmse=0.1230 val_r2=-0.1408val_corr=0.9325\n",
      "[59/100] train_loss=0.0269 | val_loss=0.0157 val_rmse=0.1254 val_r2=-0.6398val_corr=0.9297\n",
      "[60/100] train_loss=0.0262 | val_loss=0.0132 val_rmse=0.1150 val_r2=-0.2600val_corr=0.9300\n",
      "[61/100] train_loss=0.0253 | val_loss=0.0127 val_rmse=0.1125 val_r2=-0.4502val_corr=0.9318\n",
      "[62/100] train_loss=0.0246 | val_loss=0.0139 val_rmse=0.1178 val_r2=-0.2944val_corr=0.9336\n",
      "[63/100] train_loss=0.0288 | val_loss=0.0198 val_rmse=0.1408 val_r2=-0.9437val_corr=0.9297\n",
      "[64/100] train_loss=0.0309 | val_loss=0.0177 val_rmse=0.1332 val_r2=-0.0442val_corr=0.9313\n",
      "[65/100] train_loss=0.0296 | val_loss=0.0167 val_rmse=0.1291 val_r2=-0.1025val_corr=0.9307\n",
      "[66/100] train_loss=0.0281 | val_loss=0.0156 val_rmse=0.1247 val_r2=-0.1101val_corr=0.9266\n",
      "Early stopping at epoch 66 (best epoch=61, val_loss=0.0127)\n",
      "3 回目の学習が終了しました。ベストモデルを保存: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed2\n",
      "[1/100] train_loss=0.6878 | val_loss=0.5239 val_rmse=0.7238 val_r2=-20.0379val_corr=0.7460\n",
      "[2/100] train_loss=0.4074 | val_loss=0.3198 val_rmse=0.5655 val_r2=-40.4853val_corr=0.7863\n",
      "[3/100] train_loss=0.2762 | val_loss=0.2256 val_rmse=0.4750 val_r2=-2.3072val_corr=0.8566\n",
      "[4/100] train_loss=0.2048 | val_loss=0.1680 val_rmse=0.4099 val_r2=-6.3334val_corr=0.8724\n",
      "[5/100] train_loss=0.1668 | val_loss=0.1423 val_rmse=0.3773 val_r2=-1.9680val_corr=0.8917\n",
      "[6/100] train_loss=0.1420 | val_loss=0.1244 val_rmse=0.3527 val_r2=-3.9139val_corr=0.8940\n",
      "[7/100] train_loss=0.1315 | val_loss=0.1211 val_rmse=0.3480 val_r2=-3.4098val_corr=0.8924\n",
      "[8/100] train_loss=0.1254 | val_loss=0.1163 val_rmse=0.3411 val_r2=-3.1847val_corr=0.8946\n",
      "[9/100] train_loss=0.1181 | val_loss=0.1060 val_rmse=0.3256 val_r2=-2.5203val_corr=0.9011\n",
      "[10/100] train_loss=0.1111 | val_loss=0.0950 val_rmse=0.3081 val_r2=-2.6347val_corr=0.9061\n",
      "[11/100] train_loss=0.1041 | val_loss=0.0910 val_rmse=0.3016 val_r2=-3.5566val_corr=0.8981\n",
      "[12/100] train_loss=0.0987 | val_loss=0.0896 val_rmse=0.2994 val_r2=-2.6624val_corr=0.8848\n",
      "[13/100] train_loss=0.0930 | val_loss=0.0815 val_rmse=0.2855 val_r2=-9.6014val_corr=0.8905\n",
      "[14/100] train_loss=0.0918 | val_loss=0.0760 val_rmse=0.2756 val_r2=-4.0143val_corr=0.8982\n",
      "[15/100] train_loss=0.0880 | val_loss=0.0788 val_rmse=0.2807 val_r2=-3.4565val_corr=0.8881\n",
      "[16/100] train_loss=0.0856 | val_loss=0.0689 val_rmse=0.2625 val_r2=-2.1827val_corr=0.8963\n",
      "[17/100] train_loss=0.0825 | val_loss=0.0681 val_rmse=0.2609 val_r2=-2.7247val_corr=0.8881\n",
      "[18/100] train_loss=0.0788 | val_loss=0.0675 val_rmse=0.2598 val_r2=-2.2547val_corr=0.8900\n",
      "[19/100] train_loss=0.0759 | val_loss=0.0625 val_rmse=0.2500 val_r2=-1.7694val_corr=0.8974\n",
      "[20/100] train_loss=0.0722 | val_loss=0.0602 val_rmse=0.2454 val_r2=-2.0364val_corr=0.8928\n",
      "[21/100] train_loss=0.0714 | val_loss=0.0652 val_rmse=0.2554 val_r2=-1.0785val_corr=0.8940\n",
      "[22/100] train_loss=0.0713 | val_loss=0.0601 val_rmse=0.2452 val_r2=-1.2327val_corr=0.8996\n",
      "[23/100] train_loss=0.0707 | val_loss=0.0598 val_rmse=0.2446 val_r2=-1.2099val_corr=0.8920\n",
      "[24/100] train_loss=0.0686 | val_loss=0.0534 val_rmse=0.2311 val_r2=-0.9304val_corr=0.9033\n",
      "[25/100] train_loss=0.0665 | val_loss=0.0516 val_rmse=0.2272 val_r2=-1.1348val_corr=0.8988\n",
      "[26/100] train_loss=0.0636 | val_loss=0.0509 val_rmse=0.2256 val_r2=-0.9175val_corr=0.9008\n",
      "[27/100] train_loss=0.0608 | val_loss=0.0484 val_rmse=0.2199 val_r2=-0.4481val_corr=0.9031\n",
      "[28/100] train_loss=0.0600 | val_loss=0.0480 val_rmse=0.2191 val_r2=-0.4693val_corr=0.9022\n",
      "[29/100] train_loss=0.0587 | val_loss=0.0462 val_rmse=0.2150 val_r2=-0.9240val_corr=0.8995\n",
      "[30/100] train_loss=0.0574 | val_loss=0.0447 val_rmse=0.2115 val_r2=-0.7764val_corr=0.9056\n",
      "[31/100] train_loss=0.0563 | val_loss=0.0455 val_rmse=0.2134 val_r2=-0.7301val_corr=0.9021\n",
      "[32/100] train_loss=0.0548 | val_loss=0.0424 val_rmse=0.2058 val_r2=-0.8873val_corr=0.9068\n",
      "[33/100] train_loss=0.0546 | val_loss=0.0413 val_rmse=0.2033 val_r2=-1.2807val_corr=0.9073\n",
      "[34/100] train_loss=0.0537 | val_loss=0.0458 val_rmse=0.2140 val_r2=-0.8488val_corr=0.8978\n",
      "[35/100] train_loss=0.0536 | val_loss=0.0395 val_rmse=0.1988 val_r2=-1.4306val_corr=0.9102\n",
      "[36/100] train_loss=0.0513 | val_loss=0.0384 val_rmse=0.1959 val_r2=-1.0670val_corr=0.9060\n",
      "[37/100] train_loss=0.0497 | val_loss=0.0361 val_rmse=0.1899 val_r2=-1.1215val_corr=0.9111\n",
      "[38/100] train_loss=0.0479 | val_loss=0.0387 val_rmse=0.1968 val_r2=-0.9531val_corr=0.9033\n",
      "[39/100] train_loss=0.0470 | val_loss=0.0333 val_rmse=0.1824 val_r2=-1.4768val_corr=0.9115\n",
      "[40/100] train_loss=0.0447 | val_loss=0.0322 val_rmse=0.1795 val_r2=-3.1498val_corr=0.9132\n",
      "[41/100] train_loss=0.0437 | val_loss=0.0305 val_rmse=0.1746 val_r2=-1.4567val_corr=0.9159\n",
      "[42/100] train_loss=0.0410 | val_loss=0.0270 val_rmse=0.1644 val_r2=-3.2246val_corr=0.9172\n",
      "[43/100] train_loss=0.0392 | val_loss=0.0243 val_rmse=0.1560 val_r2=-3.5610val_corr=0.9206\n",
      "[44/100] train_loss=0.0362 | val_loss=0.0233 val_rmse=0.1525 val_r2=-3.7233val_corr=0.9225\n",
      "[45/100] train_loss=0.0341 | val_loss=0.0200 val_rmse=0.1414 val_r2=-2.5143val_corr=0.9295\n",
      "[46/100] train_loss=0.0320 | val_loss=0.0199 val_rmse=0.1411 val_r2=-1.5161val_corr=0.9309\n",
      "[47/100] train_loss=0.0328 | val_loss=0.0213 val_rmse=0.1460 val_r2=-1.7362val_corr=0.9322\n",
      "[48/100] train_loss=0.0325 | val_loss=0.0196 val_rmse=0.1399 val_r2=-1.1247val_corr=0.9354\n",
      "[49/100] train_loss=0.0309 | val_loss=0.0175 val_rmse=0.1323 val_r2=-0.6444val_corr=0.9350\n",
      "[50/100] train_loss=0.0296 | val_loss=0.0177 val_rmse=0.1329 val_r2=-0.7484val_corr=0.9398\n",
      "[51/100] train_loss=0.0290 | val_loss=0.0157 val_rmse=0.1254 val_r2=-0.5393val_corr=0.9394\n",
      "[52/100] train_loss=0.0282 | val_loss=0.0156 val_rmse=0.1250 val_r2=-0.4896val_corr=0.9399\n",
      "[53/100] train_loss=0.0277 | val_loss=0.0145 val_rmse=0.1203 val_r2=-0.6677val_corr=0.9416\n",
      "[54/100] train_loss=0.0263 | val_loss=0.0141 val_rmse=0.1189 val_r2=-0.3453val_corr=0.9418\n",
      "[55/100] train_loss=0.0263 | val_loss=0.0144 val_rmse=0.1198 val_r2=-0.3021val_corr=0.9426\n",
      "[56/100] train_loss=0.0257 | val_loss=0.0136 val_rmse=0.1168 val_r2=-0.2571val_corr=0.9416\n",
      "[57/100] train_loss=0.0257 | val_loss=0.0145 val_rmse=0.1203 val_r2=-0.1624val_corr=0.9413\n",
      "[58/100] train_loss=0.0263 | val_loss=0.0143 val_rmse=0.1197 val_r2=-0.1583val_corr=0.9402\n",
      "[59/100] train_loss=0.0260 | val_loss=0.0143 val_rmse=0.1194 val_r2=-0.3066val_corr=0.9404\n",
      "[60/100] train_loss=0.0254 | val_loss=0.0128 val_rmse=0.1131 val_r2=-0.1158val_corr=0.9424\n",
      "[61/100] train_loss=0.0244 | val_loss=0.0134 val_rmse=0.1158 val_r2=-0.0390val_corr=0.9414\n",
      "[62/100] train_loss=0.0245 | val_loss=0.0128 val_rmse=0.1131 val_r2=-0.0800val_corr=0.9427\n",
      "[63/100] train_loss=0.0241 | val_loss=0.0122 val_rmse=0.1106 val_r2=-0.0305val_corr=0.9427\n",
      "[64/100] train_loss=0.0244 | val_loss=0.0132 val_rmse=0.1150 val_r2=0.0270val_corr=0.9419\n",
      "[65/100] train_loss=0.0235 | val_loss=0.0128 val_rmse=0.1132 val_r2=0.0520val_corr=0.9431\n",
      "[66/100] train_loss=0.0246 | val_loss=0.0122 val_rmse=0.1105 val_r2=-0.0260val_corr=0.9427\n",
      "[67/100] train_loss=0.0233 | val_loss=0.0117 val_rmse=0.1082 val_r2=0.0728val_corr=0.9437\n",
      "[68/100] train_loss=0.0233 | val_loss=0.0134 val_rmse=0.1157 val_r2=-0.0271val_corr=0.9419\n",
      "[69/100] train_loss=0.0237 | val_loss=0.0135 val_rmse=0.1163 val_r2=-0.1030val_corr=0.9422\n",
      "[70/100] train_loss=0.0280 | val_loss=0.0180 val_rmse=0.1341 val_r2=-0.8145val_corr=0.9352\n",
      "[71/100] train_loss=0.0272 | val_loss=0.0139 val_rmse=0.1179 val_r2=-0.5501val_corr=0.9414\n",
      "[72/100] train_loss=0.0248 | val_loss=0.0145 val_rmse=0.1204 val_r2=-0.0673val_corr=0.9415\n",
      "Early stopping at epoch 72 (best epoch=67, val_loss=0.0117)\n",
      "4 回目の学習が終了しました。ベストモデルを保存: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed3\n",
      "[1/100] train_loss=0.4238 | val_loss=0.3111 val_rmse=0.5578 val_r2=-64.4408val_corr=0.8025\n",
      "[2/100] train_loss=0.2403 | val_loss=0.1992 val_rmse=0.4463 val_r2=-22.8952val_corr=0.8738\n",
      "[3/100] train_loss=0.1812 | val_loss=0.1486 val_rmse=0.3855 val_r2=-1.9899val_corr=0.8829\n",
      "[4/100] train_loss=0.1490 | val_loss=0.1250 val_rmse=0.3535 val_r2=-2.5616val_corr=0.8948\n",
      "[5/100] train_loss=0.1285 | val_loss=0.1152 val_rmse=0.3394 val_r2=-1.5850val_corr=0.8967\n",
      "[6/100] train_loss=0.1210 | val_loss=0.1077 val_rmse=0.3281 val_r2=-1.5758val_corr=0.9015\n",
      "[7/100] train_loss=0.1162 | val_loss=0.1033 val_rmse=0.3214 val_r2=-2.0395val_corr=0.9055\n",
      "[8/100] train_loss=0.1091 | val_loss=0.0970 val_rmse=0.3114 val_r2=-2.2865val_corr=0.9105\n",
      "[9/100] train_loss=0.1041 | val_loss=0.0927 val_rmse=0.3045 val_r2=-2.1767val_corr=0.9141\n",
      "[10/100] train_loss=0.0993 | val_loss=0.0874 val_rmse=0.2956 val_r2=-1.2237val_corr=0.9184\n",
      "[11/100] train_loss=0.0948 | val_loss=0.0816 val_rmse=0.2857 val_r2=-1.9677val_corr=0.9184\n",
      "[12/100] train_loss=0.0888 | val_loss=0.0797 val_rmse=0.2823 val_r2=-3.3093val_corr=0.9119\n",
      "[13/100] train_loss=0.0869 | val_loss=0.0768 val_rmse=0.2771 val_r2=-3.5194val_corr=0.9017\n",
      "[14/100] train_loss=0.0862 | val_loss=0.0786 val_rmse=0.2803 val_r2=-1.0814val_corr=0.8976\n",
      "[15/100] train_loss=0.0830 | val_loss=0.0716 val_rmse=0.2676 val_r2=-1.8693val_corr=0.9080\n",
      "[16/100] train_loss=0.0800 | val_loss=0.0740 val_rmse=0.2720 val_r2=-1.3124val_corr=0.9068\n",
      "[17/100] train_loss=0.0773 | val_loss=0.0675 val_rmse=0.2598 val_r2=-1.0576val_corr=0.9022\n",
      "[18/100] train_loss=0.0764 | val_loss=0.0690 val_rmse=0.2628 val_r2=-0.5893val_corr=0.8993\n",
      "[19/100] train_loss=0.0752 | val_loss=0.0657 val_rmse=0.2563 val_r2=-1.0555val_corr=0.9022\n",
      "[20/100] train_loss=0.0727 | val_loss=0.0651 val_rmse=0.2552 val_r2=-1.3641val_corr=0.9049\n",
      "[21/100] train_loss=0.0713 | val_loss=0.0638 val_rmse=0.2526 val_r2=-0.4844val_corr=0.9001\n",
      "[22/100] train_loss=0.0708 | val_loss=0.0629 val_rmse=0.2508 val_r2=-0.4440val_corr=0.8984\n",
      "[23/100] train_loss=0.0676 | val_loss=0.0615 val_rmse=0.2479 val_r2=-0.6756val_corr=0.9015\n",
      "[24/100] train_loss=0.0668 | val_loss=0.0561 val_rmse=0.2368 val_r2=-0.3451val_corr=0.9039\n",
      "[25/100] train_loss=0.0617 | val_loss=0.0535 val_rmse=0.2313 val_r2=-0.2800val_corr=0.9022\n",
      "[26/100] train_loss=0.0609 | val_loss=0.0512 val_rmse=0.2262 val_r2=-0.2661val_corr=0.9026\n",
      "[27/100] train_loss=0.0599 | val_loss=0.0541 val_rmse=0.2325 val_r2=-0.6451val_corr=0.9045\n",
      "[28/100] train_loss=0.0585 | val_loss=0.0502 val_rmse=0.2240 val_r2=-0.3703val_corr=0.9070\n",
      "[29/100] train_loss=0.0563 | val_loss=0.0478 val_rmse=0.2185 val_r2=-0.6093val_corr=0.9057\n",
      "[30/100] train_loss=0.0558 | val_loss=0.0440 val_rmse=0.2098 val_r2=-1.2201val_corr=0.9086\n",
      "[31/100] train_loss=0.0522 | val_loss=0.0414 val_rmse=0.2035 val_r2=-2.0353val_corr=0.9068\n",
      "[32/100] train_loss=0.0489 | val_loss=0.0397 val_rmse=0.1993 val_r2=-2.0406val_corr=0.9094\n",
      "[33/100] train_loss=0.0471 | val_loss=0.0372 val_rmse=0.1928 val_r2=-2.0157val_corr=0.9091\n",
      "[34/100] train_loss=0.0452 | val_loss=0.0348 val_rmse=0.1865 val_r2=-2.3981val_corr=0.9111\n",
      "[35/100] train_loss=0.0425 | val_loss=0.0316 val_rmse=0.1779 val_r2=-2.2560val_corr=0.9161\n",
      "[36/100] train_loss=0.0401 | val_loss=0.0293 val_rmse=0.1711 val_r2=-2.1259val_corr=0.9213\n",
      "[37/100] train_loss=0.0388 | val_loss=0.0278 val_rmse=0.1668 val_r2=-2.6152val_corr=0.9263\n",
      "[38/100] train_loss=0.0362 | val_loss=0.0241 val_rmse=0.1553 val_r2=-1.5613val_corr=0.9304\n",
      "[39/100] train_loss=0.0340 | val_loss=0.0220 val_rmse=0.1484 val_r2=-2.6665val_corr=0.9335\n",
      "[40/100] train_loss=0.0324 | val_loss=0.0203 val_rmse=0.1425 val_r2=-1.5467val_corr=0.9388\n",
      "[41/100] train_loss=0.0307 | val_loss=0.0196 val_rmse=0.1399 val_r2=-1.6267val_corr=0.9419\n",
      "[42/100] train_loss=0.0299 | val_loss=0.0192 val_rmse=0.1384 val_r2=-1.4060val_corr=0.9434\n",
      "[43/100] train_loss=0.0293 | val_loss=0.0187 val_rmse=0.1368 val_r2=-0.8160val_corr=0.9466\n",
      "[44/100] train_loss=0.0291 | val_loss=0.0186 val_rmse=0.1364 val_r2=-0.4559val_corr=0.9474\n",
      "[45/100] train_loss=0.0296 | val_loss=0.0203 val_rmse=0.1423 val_r2=-0.3954val_corr=0.9481\n",
      "[46/100] train_loss=0.0295 | val_loss=0.0200 val_rmse=0.1416 val_r2=-0.3733val_corr=0.9494\n",
      "[47/100] train_loss=0.0288 | val_loss=0.0182 val_rmse=0.1348 val_r2=-1.5489val_corr=0.9447\n",
      "[48/100] train_loss=0.0288 | val_loss=0.0174 val_rmse=0.1319 val_r2=-0.7514val_corr=0.9489\n",
      "[49/100] train_loss=0.0286 | val_loss=0.0163 val_rmse=0.1277 val_r2=-0.5767val_corr=0.9485\n",
      "[50/100] train_loss=0.0277 | val_loss=0.0182 val_rmse=0.1347 val_r2=-0.6123val_corr=0.9487\n",
      "[51/100] train_loss=0.0275 | val_loss=0.0165 val_rmse=0.1285 val_r2=-0.3074val_corr=0.9499\n",
      "[52/100] train_loss=0.0269 | val_loss=0.0160 val_rmse=0.1264 val_r2=-0.7431val_corr=0.9496\n",
      "[53/100] train_loss=0.0263 | val_loss=0.0153 val_rmse=0.1237 val_r2=-0.2656val_corr=0.9516\n",
      "[54/100] train_loss=0.0263 | val_loss=0.0155 val_rmse=0.1247 val_r2=-0.2516val_corr=0.9516\n",
      "[55/100] train_loss=0.0258 | val_loss=0.0152 val_rmse=0.1234 val_r2=-0.2127val_corr=0.9522\n",
      "[56/100] train_loss=0.0254 | val_loss=0.0149 val_rmse=0.1222 val_r2=-0.3476val_corr=0.9521\n",
      "[57/100] train_loss=0.0256 | val_loss=0.0160 val_rmse=0.1264 val_r2=-0.3962val_corr=0.9522\n",
      "[58/100] train_loss=0.0256 | val_loss=0.0163 val_rmse=0.1277 val_r2=-0.3946val_corr=0.9522\n",
      "[59/100] train_loss=0.0255 | val_loss=0.0159 val_rmse=0.1261 val_r2=-0.4043val_corr=0.9534\n",
      "[60/100] train_loss=0.0253 | val_loss=0.0143 val_rmse=0.1195 val_r2=-0.2814val_corr=0.9535\n",
      "[61/100] train_loss=0.0246 | val_loss=0.0138 val_rmse=0.1173 val_r2=-0.2390val_corr=0.9527\n",
      "[62/100] train_loss=0.0246 | val_loss=0.0143 val_rmse=0.1194 val_r2=-0.2674val_corr=0.9537\n",
      "[63/100] train_loss=0.0244 | val_loss=0.0138 val_rmse=0.1173 val_r2=-0.3610val_corr=0.9536\n",
      "[64/100] train_loss=0.0245 | val_loss=0.0148 val_rmse=0.1217 val_r2=-0.3306val_corr=0.9524\n",
      "[65/100] train_loss=0.0259 | val_loss=0.0157 val_rmse=0.1252 val_r2=-1.0567val_corr=0.9530\n",
      "[66/100] train_loss=0.0275 | val_loss=0.0269 val_rmse=0.1640 val_r2=-1.0628val_corr=0.9507\n",
      "Early stopping at epoch 66 (best epoch=61, val_loss=0.0138)\n",
      "5 回目の学習が終了しました。ベストモデルを保存: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed4\n",
      "すべての学習が終了しました。\n",
      "【全seedで最良】seed=3, best_epoch=67, val_loss=0.011701\n",
      "→ パス: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed3\n"
     ]
    }
   ],
   "source": [
    "seeds = [0, 1, 2, 3, 4]               # モデルの初期値を決める際のシード値\n",
    "y_pos = [Fe+Fd]\n",
    "global_best_val = float(\"inf\")\n",
    "\n",
    "rmse_list = np.zeros((5, 2))\n",
    "r2_list = np.zeros((5, 2))\n",
    "\n",
    "for s_id, seed in enumerate(seeds):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # DataLoaderの作成\n",
    "    random.shuffle(samples_train) # ランダムに並び替え\n",
    "    train_val_Dataset = FloodSeq2SeqDataset(samples_train)\n",
    "\n",
    "    n_total = len(train_val_Dataset)\n",
    "    n_train = int(n_total*0.85)\n",
    "    n_val = n_total - n_train\n",
    "    trainDataset, valDataset = random_split(train_val_Dataset, [n_train, n_val])\n",
    "\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=cfg[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "    valLoader = DataLoader(valDataset, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    \n",
    "    # モデルの初期化\n",
    "    model = Seq2SeqLSTM(in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "                        enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "                        enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "                        bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "                        bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "                        head_activation=cfg[\"head_activation\"],\n",
    "                        use_conv=cfg[\"use_conv\"]\n",
    "                       ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    best_opt_state = None\n",
    "    best_val_metrics = None\n",
    "\n",
    "    patience = cfg[\"patience\"]\n",
    "    min_delta = 1e-4\n",
    "\n",
    "    # 学習ループ（early stoppingあり）\n",
    "    for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- 1. 学習 ----\n",
    "        train_loss = train_one_epoch(model, trainLoader, optimizer)\n",
    "\n",
    "        # ---- 2. 検証 ----\n",
    "        val_metrics = evaluate(model, valLoader)\n",
    "        val_loss = float(val_metrics[\"loss\"])\n",
    "\n",
    "        # ---- 3. ログ出力 ----\n",
    "        if epoch % cfg[\"print_every\"] == 0:\n",
    "            print(f\"[{epoch}/{cfg['epochs']}] \"\n",
    "                  f\"train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} \"\n",
    "                  f\"val_rmse={val_metrics['rmse']:.4f} \"\n",
    "                  f\"val_r2={val_metrics['r2']:.4f}\"\n",
    "                  f\"val_corr={val_metrics['corr']:.4f}\")\n",
    "\n",
    "        # ---- 4. 改善チェック ----\n",
    "        if best_val - val_loss > min_delta:\n",
    "            best_val = val_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # ★ モデル重みをcloneして保持\n",
    "            best_model_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "            # ★ Optimizerの状態もcloneして保持（必要に応じて）\n",
    "            best_opt_state = {\n",
    "                \"state\": {\n",
    "                    k: {kk: (vv.detach().clone() if torch.is_tensor(vv) else vv)\n",
    "                        for kk, vv in v.items()}\n",
    "                    for k, v in optimizer.state_dict()[\"state\"].items()\n",
    "                },\n",
    "                \"param_groups\": [dict(g) for g in optimizer.state_dict()[\"param_groups\"]],\n",
    "            }\n",
    "    \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # ---- 5. Early Stopping 発動 ----\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch} \"\n",
    "                  f\"(best epoch={best_epoch}, val_loss={best_val:.4f})\")\n",
    "            break\n",
    "\n",
    "    assert best_model_state is not None, \"best_model_state が None です。学習が行われていない可能性があります。\"\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "\n",
    "    # 学習終了後に、実スケールでの標準化パラメータを記録\n",
    "    metrics = evaluate_original_scale_by_index(model, valLoader, mean, std, data.columns, y_pos)\n",
    "    metrics_train = evaluate_original_scale_by_index(model, trainLoader, mean, std, data.columns, y_pos)\n",
    "    \n",
    "    rmse_list[s_id, 1] = metrics[\"rmse\"]\n",
    "    r2_list[s_id, 1] = metrics[\"r2\"]\n",
    "    rmse_list[s_id, 0] = metrics_train[\"rmse\"]\n",
    "    r2_list[s_id, 0] = metrics_train[\"r2\"]\n",
    "\n",
    "    ckpt_name = f\"seed{seed}\"\n",
    "    save_path_temp = os.path.join(save_dir, ckpt_name)\n",
    "\n",
    "    torch.save({\n",
    "        \"model_state\": best_model_state,          # ★ベスト重み\n",
    "        \"optimizer_state\": best_opt_state,        # 再開したい場合に使用\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_val_loss\": best_val,\n",
    "        \"best_val_metrics\": best_val_metrics,     # スケール前の検証指標（任意）\n",
    "        \"val_metrics_original_scale\": metrics,    # 実スケール評価\n",
    "        \"cfg\": cfg,\n",
    "        \"seed\": seed,\n",
    "        \"scaler\": {\n",
    "            \"mean\": mean,                        # pandas.Series を含むなら必要に応じて .to_dict() でもOK\n",
    "            \"std\":  std,\n",
    "            \"data_columns\": list(data.columns),\n",
    "            \"y_pos\": y_pos,\n",
    "        }\n",
    "    }, save_path_temp)\n",
    "\n",
    "    print(f\"{s_id+1} 回目の学習が終了しました。ベストモデルを保存: {save_path_temp}\")\n",
    "\n",
    "    if best_val < global_best_val:\n",
    "        global_best_val = best_val\n",
    "        global_best_info = (seed, save_path_temp, best_epoch, best_val)\n",
    "\n",
    "\n",
    "print(\"すべての学習が終了しました。\")\n",
    "\n",
    "if global_best_info is not None:\n",
    "    g_seed, g_path, g_epoch, g_loss = global_best_info\n",
    "    print(f\"【全seedで最良】seed={g_seed}, best_epoch={g_epoch}, val_loss={g_loss:.6f}\")\n",
    "    print(f\"→ パス: {g_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d67165f-1ef2-4859-af01-4e44b45ed3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90.3800862   89.95779716]\n",
      " [ 97.30871624 104.85133965]\n",
      " [ 93.25708526  92.51300233]\n",
      " [ 90.35522206  88.94596367]\n",
      " [ 94.7335238   96.45618992]]\n",
      "[[ 0.29200417  0.04200354]\n",
      " [ 0.15574285  0.43391749]\n",
      " [-1.06391228 -0.45023715]\n",
      " [ 0.13368271  0.07284214]\n",
      " [ 0.09233596 -0.23899217]]\n",
      "結果をExcelファイルに保存しました。\n"
     ]
    }
   ],
   "source": [
    "# 結果をエクセルに保存\n",
    "print(rmse_list)\n",
    "print(r2_list)\n",
    "\n",
    "with pd.ExcelWriter(save_path_excel, engine=\"openpyxl\") as writer:\n",
    "    pd.DataFrame(rmse_list).to_excel(writer, sheet_name=\"rmse_list\", index=False, header=False)\n",
    "    pd.DataFrame(r2_list).to_excel(writer, sheet_name=\"r2_list\", index=False, header=False)\n",
    "\n",
    "print(\"結果をExcelファイルに保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45e28f-d575-4980-b328-70f1645fd386",
   "metadata": {},
   "source": [
    "## 最も良いモデルをロードし、テストデータで評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cefc937-e2a5-4304-8532-371309cb8711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryoya\\AppData\\Local\\Temp\\ipykernel_6056\\888373476.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(best_model_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 最も良かったモデルのパスを指定\n",
    "best_model_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\seed3\"\n",
    "\n",
    "ckpt = torch.load(best_model_path, map_location=\"cpu\")\n",
    "\n",
    "# モデルの再構築\n",
    "cfg = ckpt[\"cfg\"]\n",
    "model = Seq2SeqLSTM(in_enc=cfg[\"in_enc\"], in_dec=cfg[\"in_dec\"], out_dim=cfg[\"out_dim\"],\n",
    "                    enc_hidden=cfg[\"enc_hidden\"], dec_hidden=cfg[\"dec_hidden\"],\n",
    "                    enc_layers=cfg[\"enc_layers\"], dec_layers=cfg[\"dec_layers\"],\n",
    "                    bridge_mode=cfg[\"bridge_mode\"], dropout=cfg[\"dropout\"],\n",
    "                    bidirectional_enc=cfg[\"bidirectional_enc\"],\n",
    "                    head_activation=cfg[\"head_activation\"],\n",
    "                    use_conv=cfg[\"use_conv\"]\n",
    "                   ).to(device)\n",
    "\n",
    "# パラメータをロード\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval() # 評価モードに切り替え\n",
    "\n",
    "# 標準化パラメータの取り出し\n",
    "scaler = ckpt[\"scaler\"]\n",
    "mean = scaler[\"mean\"]                # pandas.Series\n",
    "std  = scaler[\"std\"]                 # pandas.Series\n",
    "data_columns = scaler[\"data_columns\"]  # 列名リスト\n",
    "y_pos = scaler[\"y_pos\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91238f8a-d619-4836-9e3e-bcb76da11da0",
   "metadata": {},
   "source": [
    "## testLoaderを作成し、モデルの精度を評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8dae3c-db91-47eb-9d49-7c648593b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 1272545.01339675, 'rmse': 1128.071368928735, 'r2': -3.6111868801709446, 'corr': 0.684816130418131}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testDataset = FloodSeq2SeqDataset(samples_test)\n",
    "testLoader = DataLoader(testDataset, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "metrics_test = evaluate_original_scale_by_index(model, testLoader, mean, std, data_columns, y_pos)\n",
    "\n",
    "print(metrics_test)\n",
    "\n",
    "test_save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\CrossVal_2_result_test.xlsx\"\n",
    "\n",
    "# 辞書をDataFrameに変換\n",
    "df_metrics_test = pd.DataFrame([metrics_test])   # []で囲むと1行の表になる\n",
    "\n",
    "# Excelに出力\n",
    "df_metrics_test.to_excel(test_save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ca029e-24fa-4ac8-b52a-d146aff5c80b",
   "metadata": {},
   "source": [
    "## 任意の時刻における予測をエクセルファイルに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "793795fe-9679-4166-b854-e9b1759efe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelに保存しました: C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\CrossVal_2_pred_2025_06_08.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 出力したい部分の開始行番号を指定（0はじまり）\n",
    "s = 56400\n",
    "pred_save_path = r\"C:\\Users\\ryoya\\MasterThesis\\MT_Furuie\\results\\Miwa_LSTM\\CrossVal_2\\model\\CrossVal_2_pred_2025_06_08.xlsx\"\n",
    "\n",
    "# エンコーダ開始時刻（予測期間は3日後から）\n",
    "# (4320: 2019_06_30), (38664: 2023_05_31), (38760: 2024_06_04), (13032: 2020_06_27), (13176: 2020_07_03), (48048: 2024_06_25), (56400: 2025_06_08)\n",
    "\n",
    "\n",
    "Fe, Fd, Fo = cfg[\"in_enc\"], cfg[\"in_dec\"], cfg[\"out_dim\"]\n",
    "\n",
    "enc_window = data_norm.iloc[s : s + Te]\n",
    "dec_window = data_norm.iloc[s + Te : s + Te + Td]\n",
    "# テンソル化\n",
    "enc_X = torch.tensor(enc_window.iloc[:, 0:Fe].to_numpy(dtype=np.float32))\n",
    "dec_X = torch.tensor(dec_window.iloc[:, Fe:Fe+Fd].to_numpy(dtype=np.float32))\n",
    "y     = torch.tensor(dec_window.iloc[:, Fe+Fd:Fe+Fd+Fo].to_numpy(dtype=np.float32))\n",
    "\n",
    "# モデルに入力できる形へ変形\n",
    "enc_in = enc_X.unsqueeze(0).to(device)\n",
    "dec_in = dec_X.unsqueeze(0).to(device)\n",
    "\n",
    "# デコーダに対応する時刻、実測のYを抽出\n",
    "dec_T = df.iloc[s+Te:s+Te+Td, 0:2]\n",
    "obs_Y = df.iloc[s+Te:s+Te+Td, y_cols]\n",
    "\n",
    "# モデルから予測\n",
    "pred_Y_norm = model(enc_in, dec_in)\n",
    "pred_Y_norm = pred_Y_norm.squeeze(0)\n",
    "\n",
    "# 逆標準化\n",
    "ymean = mean.iloc[y_pos]\n",
    "ystd = std.iloc[y_pos]\n",
    "ymean_t = torch.tensor(ymean.values, dtype=torch.float32, device=pred_Y_norm.device).view(1, -1)\n",
    "ystd_t  = torch.tensor(ystd.values,  dtype=torch.float32, device=pred_Y_norm.device).view(1, -1)\n",
    "pred_Y = pred_Y_norm * ystd_t + ymean_t\n",
    "\n",
    "\n",
    "# 1. pandas Series → DataFrame\n",
    "dec_T_df = pd.DataFrame(dec_T).reset_index(drop=True)\n",
    "obs_Y_df  = pd.DataFrame(obs_Y).reset_index(drop=True)\n",
    "\n",
    "# 2. Tensor → NumPy → DataFrame\n",
    "pred_Y_df = pd.DataFrame(pred_Y.detach().cpu().numpy())\n",
    "dec_X_df  = pd.DataFrame(dec_X.detach().cpu().numpy())\n",
    "\n",
    "# 3. 横方向に結合\n",
    "out_df = pd.concat([dec_T_df, obs_Y_df, pred_Y_df, dec_X_df], axis=1)\n",
    "\n",
    "\n",
    "out_df.to_excel(pred_save_path, index=False)\n",
    "\n",
    "print(\"Excelに保存しました:\", pred_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6385c0-9dc0-4b1b-b1c3-5e0085273d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74824b-ef67-45a7-a5d2-50d581ab1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94826a-ba06-4c98-9ee0-999ab9ef1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e56f78-e62e-4dce-84ae-2dbecb3b49ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a13189-5184-46d4-a992-8ece87b8e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ec6f4-81fe-43b2-9831-d51c7e729237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ca8b3-0091-407b-80c2-d81e91f69a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6ca05-0e6f-43c7-8321-920491342e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d1949-b573-4106-baa9-01250cfb9296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfdcfd-9b87-4608-9e44-bb4ce565f40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
